<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lecture 10 - Complete Slideshow</title>
    <link rel="stylesheet" href="../assets/slideshow.css">
</head>
<body>
    <!-- Progress bar -->
    <div class="progress-bar">
        <div class="progress-fill" id="progressFill"></div>
    </div>

    <!-- Keyboard hint -->
    <div class="keyboard-hint">
        Use <span class="key">←</span> <span class="key">→</span> or <span class="key">Space</span> to navigate
    </div>

    <!-- Slide title -->
    <div class="slide-title" id="slideTitle">Loading...</div>

    <!-- Menu and fullscreen buttons -->
    <button class="menu-btn" onclick="toggleMenu()">☰ Menu</button>
    <button class="fullscreen-btn" onclick="toggleFullscreen()">⛶ Fullscreen</button>

    <!-- Slide list -->
    <div class="slide-list" id="slideList"></div>

    <!-- Slideshow container -->
    <div class="slideshow-container">
        <div id="slideContainer"></div>
    </div>

    <!-- Navigation controls -->
    <div class="nav-controls">
        <button class="nav-button" id="homeBtn" onclick="window.location.href='../index.html'" aria-label="Back to index" title="Back to index">⌂</button>
        <button class="nav-button" id="prevBtn" onclick="changeSlide(-1)" aria-label="Previous slide" title="Previous slide">◄</button>
        <div class="slide-counter">
            <span id="currentSlide">1</span> / <span id="totalSlides">31</span>
        </div>
        <button class="nav-button" id="nextBtn" onclick="changeSlide(1)" aria-label="Next slide" title="Next slide">►</button>
    </div>

    <script>
        const slides = [
            { title: "Deep Neural Networks and Architecture Patterns", file: "Lecture10_01_Lecture 10 Deep Neural Networks and Architecture Patterns.html", part: null },
            { title: "Lecture Contents", file: "Lecture10_02_Lecture Contents.html", part: null },

            // Part 1
            { title: "The Need for Deep Neural Networks", file: "Lecture10_03_Part 1_3 The Need for Deep Neural Networks.html", part: "1/3" },
            { title: "Limitations of Shallow Networks", file: "Lecture10_04_Limitations of Shallow Networks.html", part: "1/3" },
            { title: "The Power of Depth - Hierarchical Representations", file: "Lecture10_05_The Power of Depth - Hierarchical Representations.html", part: "1/3" },
            { title: "Feature Reuse and Composition", file: "Lecture10_06_Feature Reuse and Composition.html", part: "1/3" },
            { title: "Parameter Efficiency", file: "Lecture10_07_Parameter Efficiency.html", part: "1/3" },
            { title: "Challenges of Deep Networks", file: "Lecture10_08_Challenges of Deep Networks.html", part: "1/3" },
            { title: "Vanishing Gradient Problem", file: "Lecture10_09_Vanishing Gradient Problem.html", part: "1/3" },
            { title: "Exploding Gradient Problem", file: "Lecture10_10_Exploding Gradient Problem.html", part: "1/3" },
            { title: "Overview of Solutions", file: "Lecture10_11_Overview of Solutions.html", part: "1/3" },

            // Part 2
            { title: "Modern Activation Functions", file: "Lecture10_12_Part 2_3 Modern Activation Functions.html", part: "2/3" },
            { title: "The ReLU Revolution", file: "Lecture10_13_The ReLU Revolution.html", part: "2/3" },
            { title: "Leaky ReLU, PReLU", file: "Lecture10_14_Leaky ReLU, PReLU.html", part: "2/3" },
            { title: "ELU, SELU", file: "Lecture10_15_ELU, SELU.html", part: "2/3" },
            { title: "Swish, GELU", file: "Lecture10_16_Swish, GELU.html", part: "2/3" },
            { title: "Activation Function Selection Guide", file: "Lecture10_17_Activation Function Selection Guide.html", part: "2/3" },
            { title: "Dead ReLU Problem", file: "Lecture10_18_Dead ReLU Problem.html", part: "2/3" },
            { title: "Mish Activation Function", file: "Lecture10_18a_Mish Activation Function.html", part: "2/3" },
            { title: "Gradient Flow Analysis", file: "Lecture10_19_Gradient Flow Analysis.html", part: "2/3" },
            { title: "Layer-wise Activation Patterns", file: "Lecture10_20_Layer-wise Activation Patterns.html", part: "2/3" },
            { title: "Attention in CNN", file: "Lecture10_20a_Attention in CNN.html", part: "2/3" },

            // Part 3
            { title: "Advanced Architecture Patterns", file: "Lecture10_21_Part 3_3 Advanced Architecture Patterns.html", part: "3/3" },
            { title: "Skip Connection (ResNet)", file: "Lecture10_22_Skip Connection (ResNet).html", part: "3/3" },
            { title: "Vision Transformer (ViT)", file: "Lecture10_22a_Vision Transformer (ViT).html", part: "3/3" },
            { title: "ConvNeXt - Modern CNN", file: "Lecture10_22b_ConvNeXt - Modern CNN.html", part: "3/3" },
            { title: "Dense Connection (DenseNet)", file: "Lecture10_23_Dense Connection (DenseNet).html", part: "3/3" },
            { title: "Bottleneck Architecture", file: "Lecture10_24_Bottleneck Architecture.html", part: "3/3" },
            { title: "The Role of 1x1 Convolution", file: "Lecture10_25_The Role of 1x1 Convolution.html", part: "3/3" },
            { title: "Inception Module", file: "Lecture10_26_Inception Module.html", part: "3/3" },
            { title: "Depthwise Separable Convolution", file: "Lecture10_27_Depthwise Separable Convolution.html", part: "3/3" },
            { title: "Neural Architecture Search", file: "Lecture10_28_Neural Architecture Search.html", part: "3/3" },
            { title: "Model Compression Techniques", file: "Lecture10_29_Model Compression Techniques.html", part: "3/3" },
            { title: "Practical Design Guidelines", file: "Lecture10_30_Practical Design Guidelines.html", part: "3/3" },

            // Ending
            { title: "Thank You", file: "Lecture10_31_Thank you.html", part: null }
        ];
    </script>
    <script src="../assets/slideshow.js"></script>
</body>
</html>
