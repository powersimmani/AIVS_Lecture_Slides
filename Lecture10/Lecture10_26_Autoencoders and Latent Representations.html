<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autoencoders and Latent Representations</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Aptos', 'Segoe UI', sans-serif;
            background: white;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            width: 960px;
            min-height: 540px;
            position: relative;
            padding: 30px;
        }
        
        .title {
            font-size: 26px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 18px;
            text-align: center;
        }
        
        .intro-box {
            background: #F0F6FF;
            border-left: 4px solid #1E64C8;
            padding: 12px 20px;
            margin-bottom: 20px;
            font-size: 17px;
            color: #333;
            font-weight: 500;
        }
        
        .architecture-section {
            background: white;
            border: 2px solid #1E64C8;
            border-radius: 10px;
            padding: 18px 20px;
            margin-bottom: 18px;
        }
        
        .arch-title {
            font-size: 18px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 14px;
            text-align: center;
        }
        
        .autoencoder-flow {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 15px;
        }
        
        .component-box {
            background: white;
            border: 2px solid #1E64C8;
            border-radius: 10px;
            padding: 18px 20px;
            text-align: center;
            min-width: 140px;
        }
        
        .component-icon {
            font-size: 28px;
            margin-bottom: 8px;
        }
        
        .component-label {
            font-size: 17px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 6px;
        }
        
        .component-desc {
            font-size: 15px;
            color: #333;
            line-height: 1.4;
        }
        
        .latent-box {
            background: #1E64C8;
            color: white;
            border-radius: 10px;
            padding: 20px 18px;
            text-align: center;
            min-width: 160px;
        }
        
        .latent-icon {
            font-size: 32px;
            margin-bottom: 8px;
        }
        
        .latent-label {
            font-size: 18px;
            font-weight: 600;
            margin-bottom: 6px;
        }
        
        .latent-desc {
            font-size: 15px;
            opacity: 0.95;
        }
        
        .arrow {
            color: #1E64C8;
            font-size: 28px;
            font-weight: bold;
        }
        
        .bottleneck-note {
            background: #F0F6FF;
            padding: 10px 14px;
            border-radius: 6px;
            text-align: center;
            font-size: 15px;
            color: #333;
            margin-top: 12px;
        }
        
        .variants-section {
            background: white;
            border: 2px solid #1E64C8;
            border-radius: 10px;
            padding: 14px 18px;
            margin-bottom: 15px;
        }
        
        .variants-title {
            font-size: 17px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 8px;
        }
        
        .variants-content {
            font-size: 16px;
            color: #333;
            line-height: 1.5;
        }
        
        .history-section {
            background: #FFF9E6;
            border: 2px solid #FFA500;
            border-radius: 10px;
            padding: 14px 18px;
            margin-bottom: 15px;
        }
        
        .history-title {
            font-size: 17px;
            font-weight: 600;
            color: #CC8400;
            margin-bottom: 8px;
        }
        
        .history-content {
            font-size: 15px;
            color: #333;
            line-height: 1.6;
        }
        
        .structure-section {
            background: white;
            border: 2px solid #1E64C8;
            border-radius: 10px;
            padding: 14px 18px;
            margin-bottom: 15px;
        }
        
        .structure-title {
            font-size: 17px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 10px;
        }
        
        .structure-content {
            font-size: 15px;
            color: #333;
            line-height: 1.6;
        }
        
        .math-example {
            background: #F0F6FF;
            border-left: 3px solid #1E64C8;
            padding: 12px 16px;
            margin-top: 10px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.6;
        }
        
        .applications-section {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 12px;
        }
        
        .app-card {
            background: #F0F6FF;
            border: 2px solid #1E64C8;
            border-radius: 8px;
            padding: 12px 14px;
            text-align: center;
        }
        
        .app-icon {
            font-size: 24px;
            margin-bottom: 6px;
        }
        
        .app-name {
            font-size: 16px;
            font-weight: 600;
            color: #1E64C8;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="title">Autoencoders and Latent Representations</div>
        
        <div class="intro-box">
            Unsupervised learning of compressed data representations
        </div>
        
        <div class="architecture-section">
            <div class="arch-title">Autoencoder Architecture</div>
            <div class="autoencoder-flow">
                <div class="component-box">
                    <div class="component-icon">üì•</div>
                    <div class="component-label">Input</div>
                    <div class="component-desc">Original Data</div>
                </div>
                
                <div class="arrow">‚Üí</div>
                
                <div class="component-box">
                    <div class="component-icon">üîΩ</div>
                    <div class="component-label">Encoder</div>
                    <div class="component-desc">Maps to latent space</div>
                </div>
                
                <div class="arrow">‚Üí</div>
                
                <div class="latent-box">
                    <div class="latent-icon">üíé</div>
                    <div class="latent-label">Latent Space</div>
                    <div class="latent-desc">Low-dimensional<br>representation</div>
                </div>
                
                <div class="arrow">‚Üí</div>
                
                <div class="component-box">
                    <div class="component-icon">üîº</div>
                    <div class="component-label">Decoder</div>
                    <div class="component-desc">Reconstructs input</div>
                </div>
                
                <div class="arrow">‚Üí</div>
                
                <div class="component-box">
                    <div class="component-icon">üì§</div>
                    <div class="component-label">Output</div>
                    <div class="component-desc">Reconstructed Data</div>
                </div>
            </div>
            <div class="bottleneck-note">
                ‚öôÔ∏è Bottleneck forces learning of essential features
            </div>
        </div>
        
        <div class="history-section">
            <div class="history-title">üìö Historical Context</div>
            <div class="history-content">
                <strong>1980s:</strong> Hinton and Rumelhart pioneered dimensionality reduction using backpropagation<br>
                <strong>2006:</strong> Hinton's Deep Belief Networks marked the dawn of the deep learning era<br>
                <strong>2013:</strong> Kingma and Welling proposed the Variational Autoencoder (VAE)<br>
                <strong>Present:</strong> Evolved into a core technology for generative models, anomaly detection, and representation learning
            </div>
        </div>
        
        <div class="structure-section">
            <div class="structure-title">üî¨ Structural Details</div>
            <div class="structure-content">
                <strong>Encoder:</strong> x ‚Üí z = f_enc(x; Œ∏_enc)<br>
                ‚Ä¢ Compresses input dimension n to latent dimension d (d ‚â™ n)<br>
                ‚Ä¢ Composed of multiple neural network layers (e.g., FC layers, CNNs)<br><br>
                
                <strong>Decoder:</strong> z ‚Üí xÃÇ = f_dec(z; Œ∏_dec)<br>
                ‚Ä¢ Reconstructs original input from latent representation z<br>
                ‚Ä¢ Can be symmetric or independent from encoder architecture<br><br>
                
                <strong>Loss Function:</strong> L = ||x - xÃÇ||¬≤ (reconstruction error)
            </div>
        </div>
        
        <div class="structure-section">
            <div class="structure-title">üßÆ Vector Operation Example</div>
            <div class="structure-content">
                <strong>Simple Example:</strong> 784-dimensional MNIST image ‚Üí 2-dimensional latent space
            </div>
            <div class="math-example">
Input vector: x ‚àà ‚Ñù^784 (28√ó28 image flattened)<br>
e.g., x = [0.1, 0.0, 0.8, ..., 0.3]<br><br>

Encoder operations:<br>
  h‚ÇÅ = ReLU(W‚ÇÅx + b‚ÇÅ)    # W‚ÇÅ ‚àà ‚Ñù^(128√ó784)<br>
  h‚ÇÇ = ReLU(W‚ÇÇh‚ÇÅ + b‚ÇÇ)   # W‚ÇÇ ‚àà ‚Ñù^(64√ó128)<br>
  z = W‚ÇÉh‚ÇÇ + b‚ÇÉ          # W‚ÇÉ ‚àà ‚Ñù^(2√ó64), z ‚àà ‚Ñù^2<br>
  ‚Üí z = [1.2, -0.5]      # 2D latent vector<br><br>

Decoder operations:<br>
  h‚ÇÉ = ReLU(W‚ÇÑz + b‚ÇÑ)    # W‚ÇÑ ‚àà ‚Ñù^(64√ó2)<br>
  h‚ÇÑ = ReLU(W‚ÇÖh‚ÇÉ + b‚ÇÖ)   # W‚ÇÖ ‚àà ‚Ñù^(128√ó64)<br>
  xÃÇ = œÉ(W‚ÇÜh‚ÇÑ + b‚ÇÜ)       # W‚ÇÜ ‚àà ‚Ñù^(784√ó128)<br>
  ‚Üí xÃÇ = [0.09, 0.02, 0.79, ..., 0.31]<br><br>

Loss: MSE = (1/784) Œ£(x·µ¢ - xÃÇ·µ¢)¬≤ = 0.003
            </div>
        </div>
        
        <div class="variants-section">
            <div class="variants-title">üé≤ Variational Autoencoders (VAE)</div>
            <div class="variants-content">
                Learn probabilistic latent distributions for generation and sampling<br>
                ‚Ä¢ Models latent space as probability distribution in the form z ~ N(Œº, œÉ¬≤)<br>
                ‚Ä¢ Learns regularized latent space with additional KL divergence
            </div>
        </div>
        
        <div class="applications-section">
            <div class="app-card">
                <div class="app-icon">üìâ</div>
                <div class="app-name">Dimensionality<br>Reduction</div>
            </div>
            <div class="app-card">
                <div class="app-icon">üîß</div>
                <div class="app-name">Denoising</div>
            </div>
            <div class="app-card">
                <div class="app-icon">‚ú®</div>
                <div class="app-name">Generation</div>
            </div>
        </div>
    </div>
</body>
</html>