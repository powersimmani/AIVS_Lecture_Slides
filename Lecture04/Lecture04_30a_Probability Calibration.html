<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probability Calibration</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: Aptos, 'Segoe UI', sans-serif; background: #FFFFFF; display: flex; justify-content: center; align-items: center; min-height: 100vh; padding: 20px; }
        .container { width: 960px; height: 540px; padding: 25px 35px; display: flex; flex-direction: column; }
        .title-section { text-align: center; margin-bottom: 15px; }
        .main-title { font-size: 26px; font-weight: 600; color: #1E64C8; margin-bottom: 4px; }
        .subtitle { font-size: 14px; color: #666; }
        .content-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; flex: 1; }
        .card { background: white; border: 2.5px solid #1E64C8; border-radius: 12px; padding: 14px; display: flex; flex-direction: column; }
        .card.concept { border-color: #FF9800; }
        .card.practice { border-color: #4CAF50; }
        .card-title { font-size: 16px; font-weight: 700; margin-bottom: 10px; }
        .concept .card-title { color: #FF9800; }
        .practice .card-title { color: #4CAF50; }
        .problem-box { background: #FFEBEE; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .problem-title { font-size: 12px; font-weight: 700; color: #C62828; margin-bottom: 6px; }
        .problem-content { font-size: 11px; color: #333; line-height: 1.5; }
        .concept-box { background: #FFF3E0; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .concept-title { font-size: 12px; font-weight: 700; color: #E65100; margin-bottom: 6px; }
        .concept-content { font-size: 11px; color: #333; line-height: 1.5; }
        .method-box { background: #E8F5E9; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .method-title { font-size: 12px; font-weight: 700; color: #2E7D32; margin-bottom: 6px; }
        .method-item { font-size: 11px; color: #333; margin-bottom: 4px; line-height: 1.4; }
        .code-box { background: #2d2d2d; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .code-content { font-family: 'Courier New', monospace; font-size: 9px; color: #d4d4d4; line-height: 1.4; }
        .code-comment { color: #6a9955; }
        .comparison-table { width: 100%; font-size: 10px; border-collapse: collapse; margin-bottom: 10px; }
        .comparison-table th { background: #FF9800; color: white; padding: 5px; }
        .comparison-table td { padding: 5px; text-align: center; border-bottom: 1px solid #e0e0e0; }
        .good { color: #4CAF50; font-weight: 600; }
        .bad { color: #F44336; font-weight: 600; }
        .note-box { background: #E3F2FD; border-radius: 8px; padding: 10px; margin-top: auto; }
        .note-content { font-size: 11px; color: #333; line-height: 1.4; }
    </style>
</head>
<body>
    <div class="container">
        <div class="title-section">
            <div class="main-title">Probability Calibration</div>
            <div class="subtitle">Are your model's probability outputs trustworthy?</div>
        </div>
        <div class="content-grid">
            <div class="card concept">
                <div class="card-title">Why Calibration Matters</div>
                <div class="problem-box">
                    <div class="problem-title">The Problem</div>
                    <div class="problem-content">
                        Model says P(disease) = 0.8<br>
                        Does this mean 80% of similar cases are positive?<br><br>
                        <strong>Not necessarily!</strong> Many models output uncalibrated scores.
                    </div>
                </div>
                <div class="concept-box">
                    <div class="concept-title">What is Calibration?</div>
                    <div class="concept-content">
                        A model is <strong>well-calibrated</strong> if:<br>
                        Among all predictions with P = 0.8,<br>
                        approximately 80% should be positive.<br><br>
                        <strong>Reliability Diagram:</strong> Plot predicted prob vs actual frequency
                    </div>
                </div>
                <table class="comparison-table">
                    <tr><th>Model</th><th>Typically Calibrated?</th></tr>
                    <tr><td>Logistic Regression</td><td class="good">Yes (by design)</td></tr>
                    <tr><td>Naive Bayes</td><td class="bad">No (extreme probs)</td></tr>
                    <tr><td>Random Forest</td><td class="bad">No (biased to 0.5)</td></tr>
                    <tr><td>SVM</td><td class="bad">No (not probabilistic)</td></tr>
                    <tr><td>Neural Networks</td><td class="bad">Often overconfident</td></tr>
                </table>
                <div class="note-box">
                    <div class="note-content">
                        <strong>Critical domains:</strong> Medical diagnosis, credit scoring, autonomous driving - where probability interpretation matters!
                    </div>
                </div>
            </div>
            <div class="card practice">
                <div class="card-title">Calibration Methods</div>
                <div class="method-box">
                    <div class="method-title">1. Platt Scaling</div>
                    <div class="method-item">Fit sigmoid to model outputs</div>
                    <div class="method-item">P(y=1|f) = 1 / (1 + exp(Af + B))</div>
                    <div class="method-item">Best for: binary classification, smaller datasets</div>
                </div>
                <div class="method-box">
                    <div class="method-title">2. Isotonic Regression</div>
                    <div class="method-item">Non-parametric monotonic function</div>
                    <div class="method-item">More flexible, needs more data</div>
                    <div class="method-item">Best for: larger datasets, complex miscalibration</div>
                </div>
                <div class="code-box">
                    <div class="code-content">
                        <span class="code-comment"># Check calibration</span><br>
                        from sklearn.calibration import calibration_curve<br>
                        prob_true, prob_pred = calibration_curve(<br>
                        &nbsp;&nbsp;y_test, y_prob, n_bins=10<br>
                        )<br><br>
                        <span class="code-comment"># Apply calibration</span><br>
                        from sklearn.calibration import CalibratedClassifierCV<br><br>
                        calibrated = CalibratedClassifierCV(<br>
                        &nbsp;&nbsp;model,<br>
                        &nbsp;&nbsp;method='isotonic',  <span class="code-comment"># or 'sigmoid'</span><br>
                        &nbsp;&nbsp;cv=5<br>
                        )<br>
                        calibrated.fit(X_train, y_train)<br>
                        probs = calibrated.predict_proba(X_test)
                    </div>
                </div>
                <div class="method-box">
                    <div class="method-title">Evaluation: Brier Score</div>
                    <div class="method-item">BS = (1/n) * sum(p_i - y_i)Â²</div>
                    <div class="method-item">Lower is better (0 = perfect)</div>
                    <div class="method-item">Captures both calibration AND discrimination</div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
