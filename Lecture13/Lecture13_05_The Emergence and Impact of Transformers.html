<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer Impact Diagram</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Aptos, 'Segoe UI', sans-serif;
            background: white;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }
        
        .container {
            width: 960px;
            padding: 30px;
            background: white;
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        
        .header {
            text-align: center;
            background: #1E64C8;
            color: white;
            padding: 16px;
            border-radius: 8px;
        }
        
        .header-title {
            font-size: 20px;
            font-weight: 600;
            margin-bottom: 4px;
        }
        
        .header-subtitle {
            font-size: 16px;
            opacity: 0.95;
        }
        
        .main-content {
            display: flex;
            gap: 20px;
            flex: 1;
        }
        
        .core-innovation {
            flex: 1;
            background: #f0f7ff;
            border: 2px solid #1E64C8;
            border-radius: 8px;
            padding: 20px;
            display: flex;
            flex-direction: column;
            gap: 14px;
        }
        
        .section-title {
            font-size: 18px;
            font-weight: 600;
            color: #1E64C8;
            border-bottom: 2px solid #1E64C8;
            padding-bottom: 8px;
        }
        
        .innovation-item {
            display: flex;
            align-items: start;
            gap: 10px;
        }
        
        .icon {
            font-size: 18px;
            margin-top: 2px;
        }
        
        .innovation-text {
            font-size: 16px;
            color: #333;
            line-height: 1.4;
        }
        
        .impact-section {
            flex: 1.2;
            display: flex;
            flex-direction: column;
            gap: 12px;
        }
        
        .impact-box {
            background: white;
            border: 2px solid #1E64C8;
            border-radius: 8px;
            padding: 14px 16px;
            flex: 1;
        }
        
        .impact-title {
            font-size: 17px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 6px;
        }
        
        .impact-list {
            font-size: 15px;
            color: #555;
            line-height: 1.5;
        }
        
        .foundation-box {
            background: #fff8e6;
            border-color: #ffa500;
        }
        
        .foundation-box .impact-title {
            color: #d97700;
        }
        
        .nlp-box {
            background: #f0f7ff;
        }
        
        .beyond-box {
            background: #f5f0ff;
            border-color: #7c3aed;
        }
        
        .beyond-box .impact-title {
            color: #7c3aed;
        }
        
        .performance-box {
            background: #f0fdf4;
            border-color: #16a34a;
        }
        
        .performance-box .impact-title {
            color: #16a34a;
        }

        /* Architecture Section Styles */
        .architecture-header {
            text-align: center;
            background: #2d3748;
            color: white;
            padding: 16px;
            border-radius: 8px;
            margin-top: 20px;
        }

        .architecture-content {
            display: flex;
            gap: 20px;
            margin-top: 20px;
        }

        .arch-diagram {
            flex: 1;
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .encoder-decoder-wrapper {
            display: flex;
            gap: 12px;
            position: relative;
        }

        .encoder-side, .decoder-side {
            flex: 1;
            display: flex;
            flex-direction: column;
            gap: 8px;
        }

        .arch-label {
            text-align: center;
            font-weight: 600;
            font-size: 16px;
            color: #1E64C8;
            padding: 8px;
            background: #e8f4fd;
            border-radius: 6px;
            border: 2px solid #1E64C8;
        }

        .decoder-label {
            color: #7c3aed;
            background: #f5f0ff;
            border-color: #7c3aed;
        }

        .arch-block {
            padding: 12px 16px;
            border-radius: 8px;
            text-align: center;
            font-size: 13px;
            font-weight: 500;
            position: relative;
        }

        .input-block {
            background: #e2e8f0;
            border: 2px solid #64748b;
            color: #334155;
        }

        .positional-block {
            background: #fef3c7;
            border: 2px solid #f59e0b;
            color: #92400e;
        }

        .attention-block {
            background: #dbeafe;
            border: 2px solid #3b82f6;
            color: #1e40af;
        }

        .masked-attention-block {
            background: #ede9fe;
            border: 2px solid #8b5cf6;
            color: #5b21b6;
        }

        .cross-attention-block {
            background: #fce7f3;
            border: 2px solid #ec4899;
            color: #9d174d;
        }

        .ffn-block {
            background: #d1fae5;
            border: 2px solid #10b981;
            color: #065f46;
        }

        .norm-block {
            background: #f1f5f9;
            border: 2px dashed #94a3b8;
            color: #475569;
            font-size: 11px;
            padding: 6px 10px;
        }

        .output-block {
            background: #fee2e2;
            border: 2px solid #ef4444;
            color: #991b1b;
        }

        .arrow-down {
            text-align: center;
            color: #94a3b8;
            font-size: 18px;
        }

        /* Components Description */
        .components-grid {
            flex: 1.2;
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 12px;
        }

        .component-card {
            padding: 14px;
            border-radius: 8px;
            border: 2px solid;
        }

        .component-title {
            font-size: 14px;
            font-weight: 600;
            margin-bottom: 6px;
            display: flex;
            align-items: center;
            gap: 6px;
        }

        .component-desc {
            font-size: 12px;
            color: #555;
            line-height: 1.4;
        }

        .comp-attention {
            background: #eff6ff;
            border-color: #3b82f6;
        }
        .comp-attention .component-title { color: #1e40af; }

        .comp-positional {
            background: #fffbeb;
            border-color: #f59e0b;
        }
        .comp-positional .component-title { color: #92400e; }

        .comp-ffn {
            background: #ecfdf5;
            border-color: #10b981;
        }
        .comp-ffn .component-title { color: #065f46; }

        .comp-multihead {
            background: #fdf4ff;
            border-color: #d946ef;
        }
        .comp-multihead .component-title { color: #a21caf; }

        .comp-norm {
            background: #f8fafc;
            border-color: #94a3b8;
        }
        .comp-norm .component-title { color: #475569; }

        .comp-encoder {
            background: #fdf2f8;
            border-color: #ec4899;
        }
        .comp-encoder .component-title { color: #9d174d; }

        .nx-badge {
            position: absolute;
            right: 8px;
            top: 8px;
            background: #1E64C8;
            color: white;
            font-size: 10px;
            padding: 2px 6px;
            border-radius: 4px;
        }

        .encoder-stack, .decoder-stack {
            border: 2px solid #cbd5e1;
            border-radius: 8px;
            padding: 12px;
            background: #fafafa;
            position: relative;
        }

        .decoder-stack {
            border-color: #c4b5fd;
            background: #faf5ff;
        }

        .stack-content {
            display: flex;
            flex-direction: column;
            gap: 6px;
        }

        .encoder-output {
            background: #dbeafe;
            border: 2px solid #3b82f6;
            color: #1e40af;
            padding: 8px;
            border-radius: 6px;
            text-align: center;
            font-size: 12px;
            font-weight: 500;
        }

        .kv-label {
            font-size: 10px;
            color: #ec4899;
            font-weight: 600;
            text-align: center;
            margin-top: 4px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="header-title">"Attention Is All You Need" (Vaswani et al., 2017)</div>
            <div class="header-subtitle">Revolutionary Architecture for Deep Learning</div>
        </div>
        
        <div class="main-content">
            <div class="core-innovation">
                <div class="section-title">Core Innovation</div>
                
                <div class="innovation-item">
                    <span class="icon">‚ö°</span>
                    <div class="innovation-text">
                        <strong>Eliminated recurrence entirely</strong><br>
                        Enabled full parallelization
                    </div>
                </div>
                
                <div class="innovation-item">
                    <span class="icon">üìà</span>
                    <div class="innovation-text">
                        <strong>Massive dataset training</strong><br>
                        Efficient at scale
                    </div>
                </div>
                
                <div class="innovation-item">
                    <span class="icon">üéØ</span>
                    <div class="innovation-text">
                        <strong>State-of-the-art performance</strong><br>
                        Across multiple benchmarks
                    </div>
                </div>
            </div>
            
            <div class="impact-section">
                <div class="impact-box foundation-box">
                    <div class="impact-title">üèóÔ∏è Foundation Models</div>
                    <div class="impact-list">
                        GPT, BERT, and modern LLMs
                    </div>
                </div>
                
                <div class="impact-box nlp-box">
                    <div class="impact-title">üí¨ NLP Revolution</div>
                    <div class="impact-list">
                        Translation ‚Ä¢ Summarization<br>
                        Question Answering ‚Ä¢ Generation
                    </div>
                </div>
                
                <div class="impact-box beyond-box">
                    <div class="impact-title">üåê Beyond NLP</div>
                    <div class="impact-list">
                        Vision Transformers (ViT)<br>
                        Audio Processing ‚Ä¢ Multimodal AI
                    </div>
                </div>
                
                <div class="impact-box performance-box">
                    <div class="impact-title">‚ú® Impact</div>
                    <div class="impact-list">
                        New era of AI capabilities<br>
                        Industry-wide transformation
                    </div>
                </div>
            </div>
        </div>

        <!-- Transformer Architecture Section -->
        <div class="architecture-header">
            <div class="header-title">Transformer Architecture</div>
            <div class="header-subtitle">Key Components & Structure</div>
        </div>

        <div class="architecture-content">
            <div class="arch-diagram">
                <div class="encoder-decoder-wrapper">
                    <!-- Encoder Side -->
                    <div class="encoder-side">
                        <div class="arch-label">Encoder</div>
                        <div class="arch-block input-block">Input Embedding</div>
                        <div class="arrow-down">‚Üì</div>
                        <div class="arch-block positional-block">+ Positional Encoding</div>
                        <div class="arrow-down">‚Üì</div>
                        <div class="encoder-stack">
                            <span class="nx-badge">√ó N</span>
                            <div class="stack-content">
                                <div class="arch-block attention-block">Multi-Head Self-Attention</div>
                                <div class="arch-block norm-block">Add & Layer Norm</div>
                                <div class="arch-block ffn-block">Feed-Forward Network</div>
                                <div class="arch-block norm-block">Add & Layer Norm</div>
                            </div>
                        </div>
                        <div class="arrow-down">‚Üì</div>
                        <div class="encoder-output">Encoder Output</div>
                        <div class="kv-label">K, V ‚Üí</div>
                    </div>

                    <!-- Decoder Side -->
                    <div class="decoder-side">
                        <div class="arch-label decoder-label">Decoder</div>
                        <div class="arch-block input-block">Output Embedding</div>
                        <div class="arrow-down">‚Üì</div>
                        <div class="arch-block positional-block">+ Positional Encoding</div>
                        <div class="arrow-down">‚Üì</div>
                        <div class="decoder-stack">
                            <span class="nx-badge">√ó N</span>
                            <div class="stack-content">
                                <div class="arch-block masked-attention-block">Masked Self-Attention</div>
                                <div class="arch-block norm-block">Add & Layer Norm</div>
                                <div class="arch-block cross-attention-block">Cross-Attention<br><small>(Q: Decoder, K/V: Encoder)</small></div>
                                <div class="arch-block norm-block">Add & Layer Norm</div>
                                <div class="arch-block ffn-block">Feed-Forward Network</div>
                                <div class="arch-block norm-block">Add & Layer Norm</div>
                            </div>
                        </div>
                        <div class="arrow-down">‚Üì</div>
                        <div class="arch-block output-block">Linear + Softmax ‚Üí Output</div>
                    </div>
                </div>
            </div>

            <!-- Components Description -->
            <div class="components-grid">
                <div class="component-card comp-attention">
                    <div class="component-title">üîç Self-Attention</div>
                    <div class="component-desc">
                        Each position attends to all positions, capturing contextual relationships
                    </div>
                </div>

                <div class="component-card comp-multihead">
                    <div class="component-title">üîÄ Multi-Head</div>
                    <div class="component-desc">
                        Parallel attention heads learn diverse representations
                    </div>
                </div>

                <div class="component-card comp-positional">
                    <div class="component-title">üìç Positional Encoding</div>
                    <div class="component-desc">
                        Injects sequence order using sinusoidal functions
                    </div>
                </div>

                <div class="component-card comp-ffn">
                    <div class="component-title">‚öôÔ∏è Feed-Forward</div>
                    <div class="component-desc">
                        Position-wise MLP with two linear layers + ReLU
                    </div>
                </div>

                <div class="component-card comp-norm">
                    <div class="component-title">‚ûï Add & Norm</div>
                    <div class="component-desc">
                        Residual connections + Layer Normalization for stable training
                    </div>
                </div>

                <div class="component-card comp-encoder">
                    <div class="component-title">üîÑ Cross-Attention</div>
                    <div class="component-desc">
                        Decoder queries (Q) attend to Encoder's keys (K) and values (V)
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>