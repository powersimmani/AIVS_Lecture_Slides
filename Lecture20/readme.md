# Lecture 20: Model Explainability - SHAP and Deep Learning XAI

## ğŸ“‹ Overview

**Instructor:** Ho-min Park  
**Email:** homin.park@ghent.ac.kr | powersimmani@gmail.com

This lecture covers advanced XAI techniques including SHAP and GradCAM, and deep learning model interpretation.

---

## ğŸ¯ Learning Objectives

1. Understand Shapley Values theory
2. Implement SHAP variants (KernelSHAP, TreeSHAP, DeepSHAP)
3. Visualize CNNs with GradCAM
4. Apply Integrated Gradients
5. Interpret Attention weights

---

## ğŸ“š Key Topics

**Shapley Values**: Game theory, fair contribution
**SHAP**: KernelSHAP, TreeSHAP, DeepSHAP, GradientSHAP
**GradCAM**: CNN visualization, Class Activation Map
**Integrated Gradients**: Path integration, attribution analysis
**Attention Visualization**: Transformer interpretation

---

## ğŸ’¡ Key Concepts

- Shapley Values are theoretically robust
- SHAP is model-agnostic
- GradCAM visualizes CNN decision regions
- Integrated Gradients are gradient-based
- Attention shows model focus areas

---

## ğŸ› ï¸ Prerequisites

- Basic Python programming
- Understanding of previous lecture content
- Basic machine learning concepts

---

## ğŸ“– Additional Resources

For detailed code examples, practice materials, and slides, please refer to the original lecture files.
Lecture materials: HTML-based interactive slides provided
