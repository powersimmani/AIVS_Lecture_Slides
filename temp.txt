OS 볼륨에 대한 폴더 경로의 목록입니다.
볼륨 일련 번호는 8E11-5C60입니다.
C:.
│  index.html
│  README.md
│  showcase.html
│  temp.txt
│  
├─Lecture01
│      Lecture 1_ Computer Structure and Networks for ML.html
│      Lecture01_01_Lecture 1 Computer Structure and Networks for ML.html
│      Lecture01_02_Lecture Contents.html
│      Lecture01_03_Part 1 Data Representation and ML Hardware Fundamentals.html
│      Lecture01_04_Lecture Introduction - ML Workflow and Computer Architecture.html
│      Lecture01_05_Bits and Bytes - Understanding ML Data Types.html
│      Lecture01_06_Number Representation Methods - Fixed Point vs. Floating Point.html
│      Lecture01_07_Quantization Principles and Memory Efficiency.html
│      Lecture01_08_CPU vs. GPU - Architectural Comparison.html
│      Lecture01_09_GPU Cores and CUDA - Understanding Parallel Processing.html
│      Lecture01_10_FLOPS and ML Model Performance Metrics.html
│      Lecture01_11_Tensor Operations and Hardware Optimization.html
│      Lecture01_12_Part 2 Memory and ML Model Execution.html
│      Lecture01_13_Memory Hierarchy - RAM, VRAM, Cache.html
│      Lecture01_14_ML Models Loading and Memory Management.html
│      Lecture01_15_Batch Size and Memory Usage Calculation.html
│      Lecture01_16_Python Bytecode and ML Frameworks.html
│      Lecture01_17_Memory Layout of NumPyPyTorch Tensors.html
│      Lecture01_18_GPU Memory Management.html
│      Lecture01_19_Mixed Precision Training - FP16 and FP32.html
│      Lecture01_20_Hands-on Resource Monitoring Tools.html
│      Lecture01_21_Part 3 Network and Distributed ML.html
│      Lecture01_22_IP Addresses and Ports - Server Connection Basics.html
│      Lecture01_23_SSH and Remote Server Connection Practice.html
│      Lecture01_24_File Transfer - Using SCP and SFTP.html
│      Lecture01_25_HTTP API and Model Serving.html
│      Lecture01_26_Distributed Training Overview.html
│      Lecture01_27_Network Bandwidth and Learning Speed.html
│      Lecture01_28_Docker Basics - ML Environment Containerization.html
│      Lecture01_29_Leveraging Cloud GPUs.html
│      Lecture01_30_Hands-on Project - Training ML Models on Remote Server.html
│      Lecture01_31_Thank you.html
│      lecture01_slideshow.html
│      
├─Lecture02
│      Lecture02_01_Lecture 2 Data Visualization.html
│      Lecture02_02_Lecture Contents.html
│      Lecture02_03_Part 1_3 Visualization Fundamentals.html
│      Lecture02_04_Importance and Goals of Data Visualization.html
│      Lecture02_05_Visual Encoding Principles.html
│      Lecture02_06_Gestalt Principles and Perception.html
│      Lecture02_07_Color Theory and Color Blindness Accessibility.html
│      Lecture02_08_Typography and Layout.html
│      Lecture02_09_Information Density and Data-Ink Ratio.html
│      Lecture02_10_Grammar of Graphics.html
│      Lecture02_11_Good vs Bad Visualization Examples.html
│      Lecture02_12_Part 2_3 Mastering Basic Charts.html
│      Lecture02_13_1D Data - Histogram, KDE.html
│      Lecture02_14_2D Relationships - Scatter Plot, Bubble Chart.html
│      Lecture02_15_Categorical Data - Bar Chart, Pie Chart.html
│      Lecture02_16_Distribution Comparison - Boxplot, Violin Plot.html
│      Lecture02_17_Time Series - Line Graph, Area Chart.html
│      Lecture02_18_Correlation - Heatmap, Correlation Matrix.html
│      Lecture02_19_Multidimensional - Parallel Coordinates, Radar Chart.html
│      Lecture02_20_Geographic Data - Choropleth, Bubble Map.html
│      Lecture02_21_Part 3_3 Advanced Visualization for ML.html
│      Lecture02_22_Visualization Strategy for EDA.html
│      Lecture02_23_Feature Distribution and Outlier Detection.html
│      Lecture02_24_Visualizing Feature Interactions.html
│      Lecture02_25_Dimensionality Reduction Visualization (PCA, t-SNE, UMAP).html
│      Lecture02_26_Model Performance Visualization - Learning Curves.html
│      Lecture02_27_Classification Model Evaluation - Confusion Matrix, ROC, PR.html
│      Lecture02_28_Regression Model Evaluation - Residuals, QQ Plot.html
│      Lecture02_29_Model Interpretation - SHAP, LIME, Attention.html
│      Lecture02_30_Dashboard Design and Storytelling.html
│      Lecture02_31_Thank you.html
│      lecture02_slideshow.html
│      
├─Lecture03
│      Lecture03_01_Lecture 3 From Set to Linear Regression.html
│      Lecture03_02_Lecture Contents.html
│      Lecture03_03_Part 1_3 Mathematical Foundations.html
│      Lecture03_04_Course Overview - From Sets to Regression.html
│      Lecture03_05_Set Theory Basics and Notation.html
│      Lecture03_06_Functions and Mapping Concepts.html
│      Lecture03_07_Vector Spaces and Basis.html
│      Lecture03_08_Inner Product and Orthogonality.html
│      Lecture03_09_Matrix Operations and Properties.html
│      Lecture03_10_Inverse Matrices and Determinants.html
│      Lecture03_11_Eigenvalues and Eigenvectors.html
│      Lecture03_12_Differentiation and Partial Derivatives.html
│      Lecture03_13_Part 2_3 Probability and Statistics Fundamentals.html
│      Lecture03_14_Probability Spaces and Random Variables.html
│      Lecture03_15_Probability Distributions - Discrete and Continuous.html
│      Lecture03_16_Expectation, Variance, and Covariance.html
│      Lecture03_17_Conditional Probability and Bayes_ Theorem.html
│      Lecture03_18_Central Limit Theorem and Law of Large Numbers.html
│      Lecture03_19_Parameter Estimation - MLE and MAP.html
│      Lecture03_20_Hypothesis Testing and Confidence Intervals.html
│      Lecture03_21_Correlation vs Causation.html
│      Lecture03_22_Part 3_3 Linear Regression Model.html
│      Lecture03_23_Linear Regression Problem Definition.html
│      Lecture03_24_Simple Linear Regression Model.html
│      Lecture03_25_Deriving the Least Squares Method.html
│      Lecture03_26_Normal Equation Solution.html
│      Lecture03_27_Geometric Interpretation.html
│      Lecture03_28_Multiple Linear Regression Extension.html
│      Lecture03_29_Model Assumptions and Diagnostics.html
│      Lecture03_30_Python Implementation and Practice.html
│      Lecture03_31_Thank you.html
│      lecture03_slideshow.html
│      
├─Lecture04
│      Lecture04_01_Lecture_4_From_Linear_to_Logistic_Regression.html
│      Lecture04_02_Lecture_Contents.html
│      Lecture04_03_Part_1_3_Advanced_Linear_Regression.html
│      Lecture04_04_Review and Connection to Previous Lecture.html
│      Lecture04_05_Revisiting Linear Regression Assumptions.html
│      Lecture04_06_Polynomial Regression and Basis Expansion.html
│      Lecture04_07_Ridge Regression (L2 Regularization).html
│      Lecture04_08_Lasso Regression (L1 Regularization).html
│      Lecture04_09_Elastic Net.html
│      Lecture04_10_Feature Selection and Importance.html
│      Lecture04_11_Limitations of Linear Regression.html
│      Lecture04_12_Part_2_3_Transition_to_Classification.html
│      Lecture04_13_Regression vs Classification Problems.html
│      Lecture04_14_Linear Classifier Concepts.html
│      Lecture04_15_Perceptron Algorithm.html
│      Lecture04_16_Decision Boundaries and Linear Separability.html
│      Lecture04_17_Why Linear Regression Fails for Classification.html
│      Lecture04_18_Odds and Log Odds.html
│      Lecture04_19_Introduction to Sigmoid Function.html
│      Lecture04_20_Properties of Logistic Function.html
│      Lecture04_21_Part_3_3_Completing_Logistic_Regression.html
│      Lecture04_22_Defining the Logistic Regression Model.html
│      Lecture04_23_Maximum Likelihood Estimation (MLE).html
│      Lecture04_24_Binary Cross-Entropy Loss.html
│      Lecture04_25_Applying Gradient Descent.html
│      Lecture04_26_Multiclass - One-vs-Rest Strategy.html
│      Lecture04_27_Softmax Regression.html
│      Lecture04_28_Categorical Cross-Entropy.html
│      Lecture04_29_Regularized Logistic Regression.html
│      Lecture04_30_Real-World Cases and Implementation.html
│      Lecture04_31_Thank_you.html
│      Lecture04_slideshow.html
│      
├─Lecture05
│      Lecture 5_ From Logistic Regression to Multi-layer Perceptrons.html
│      Lecture05_01_Lecture 5 From Logistic Regression to Multi-layer Perceptrons.html
│      Lecture05_02_Lecture Contents.html
│      Lecture05_03_Part 1_3 Neural Network Motivation.html
│      Lecture05_04_Limitations of Logistic Regression.html
│      Lecture05_05_XOR Problem - Linear Inseparability.html
│      Lecture05_06_Need for Feature Space Transformation.html
│      Lecture05_07_The Idea of Multi-layer Structure.html
│      Lecture05_08_Biological Neuron vs Artificial Neuron.html
│      Lecture05_09_Role of Activation Functions.html
│      Lecture05_10_Universal Approximation Theorem.html
│      Lecture05_11_Expressiveness and Depth.html
│      Lecture05_12_Part 2_3 MLP Structure and Forward Propagation.html
│      Lecture05_13_Single-layer Perceptron Review.html
│      Lecture05_14_Multi-layer Perceptron Architecture.html
│      Lecture05_15_Weights and Biases.html
│      Lecture05_16_Forward Propagation Algorithm.html
│      Lecture05_17_Activation Functions - Sigmoid, Tanh.html
│      Lecture05_18_ReLU and Its Variants.html
│      Lecture05_19_Output Layer Design (Regression vs Classification).html
│      Lecture05_20_Network Capacity and Complexity.html
│      Lecture05_21_Part 3_3 Backpropagation and Learning.html
│      Lecture05_22_Loss Function Definition.html
│      Lecture05_23_Chain Rule.html
│      Lecture05_24_Backpropagation Algorithm Derivation.html
│      Lecture05_25_Computational Graph.html
│      Lecture05_26_Gradient Calculation Example.html
│      Lecture05_27_Automatic Differentiation (Autograd).html
│      Lecture05_28_Mini-batch Gradient Descent.html
│      Lecture05_29_Implementation Tips and Debugging.html
│      Lecture05_30_PyTorchTensorFlow Hands-on.html
│      Lecture05_31_Thank you.html
│      lecture05_slideshow.html
│      
├─Lecture06
│      Lecture06_01_Lecture 6 Supervised Learning Evaluation.html
│      Lecture06_02_Lecture Contents.html
│      Lecture06_03_Part 1_4 Importance and Fundamentals of Evaluation.html
│      Lecture06_04_Why is Evaluation Important.html
│      Lecture06_05_Train vs Validation vs Test.html
│      Lecture06_06_Overfitting and Underfitting.html
│      Lecture06_07_Bias-Variance Tradeoff.html
│      Lecture06_08_Data Splitting Strategies.html
│      Lecture06_09_Stratified Sampling.html
│      Lecture06_10_Time Series Data Splitting.html
│      Lecture06_11_Preventing Data Leakage.html
│      Lecture06_12_Part 2_4 Regression Evaluation Metrics.html
│      Lecture06_13_MSE, RMSE, MAE.html
│      Lecture06_14_R², Adjusted R².html
│      Lecture06_15_MAPE, SMAPE.html
│      Lecture06_16_Residual Analysis and Diagnostics.html
│      Lecture06_17_Part 3_4 Classification Evaluation Metrics.html
│      Lecture06_18_Confusion Matrix.html
│      Lecture06_19_Accuracy and Its Limitations.html
│      Lecture06_20_Precision and Recall.html
│      Lecture06_21_F1 Score and Fβ.html
│      Lecture06_22_ROC Curve and AUC.html
│      Lecture06_23_Precision-Recall Curve.html
│      Lecture06_24_Multi-class Metrics.html
│      Lecture06_25_Part 4_4 Model Validation Techniques.html
│      Lecture06_26_K-fold Cross Validation.html
│      Lecture06_27_Stratified K-fold.html
│      Lecture06_28_Leave-One-Out CV.html
│      Lecture06_29_Bootstrapping.html
│      Lecture06_30_Hyperparameter Tuning.html
│      Lecture06_31_Model_Selection_Strategy.html
│      Lecture06_32_Thank you.html
│      lecture06_slideshow.html
│      
├─Lecture07
│      Lecture07_01_Lecture 7 From Logistic Regression to Multi-layer Perceptrons.html
│      Lecture07_02_Lecture Contents.html
│      Lecture07_03_Part 1_3 The Need for Deep Neural Networks.html
│      Lecture07_04_Limitations of Shallow Networks.html
│      Lecture07_05_The Power of Depth - Hierarchical Representations.html
│      Lecture07_06_Feature Reuse and Composition.html
│      Lecture07_07_Parameter Efficiency.html
│      Lecture07_08_Challenges of Deep Networks.html
│      Lecture07_09_Vanishing Gradient Problem.html
│      Lecture07_10_Exploding Gradient Problem.html
│      Lecture07_11_Overview of Solutions.html
│      Lecture07_12_Part 2_3 Modern Activation Functions.html
│      Lecture07_13_The ReLU Revolution.html
│      Lecture07_14_Leaky ReLU, PReLU.html
│      Lecture07_15_ELU, SELU.html
│      Lecture07_16_Swish, GELU.html
│      Lecture07_17_Activation Function Selection Guide.html
│      Lecture07_18_Dead ReLU Problem.html
│      Lecture07_19_Gradient Flow Analysis.html
│      Lecture07_20_Layer-wise Activation Patterns.html
│      Lecture07_21_Part 3_3 Advanced Architecture Patterns.html
│      Lecture07_22_Skip Connection (ResNet).html
│      Lecture07_23_Dense Connection (DenseNet).html
│      Lecture07_24_Bottleneck Architecture.html
│      Lecture07_25_The Role of 1x1 Convolution.html
│      Lecture07_26_Inception Module.html
│      Lecture07_27_Depthwise Separable Convolution.html
│      Lecture07_28_Neural Architecture Search.html
│      Lecture07_29_Model Compression Techniques.html
│      Lecture07_30_Practical Design Guidelines.html
│      Lecture07_31_Thank you.html
│      lecture07_slideshow.html
│      
├─Lecture08
│      Lecture08_01_Lecture 8 Loss, Optimization and Scheduling.html
│      Lecture08_02_Lecture Contents.html
│      Lecture08_03_Part 1_3 Loss Function Design.html
│      Lecture08_04_Role and Importance of Loss Functions.html
│      Lecture08_05_Regression Losses - MSE, MAE, Huber.html
│      Lecture08_06_Classification Loss - Cross-Entropy.html
│      Lecture08_07_Hinge Loss and SVM.html
│      Lecture08_08_Focal Loss - Class Imbalance.html
│      Lecture08_09_Contrastive Loss.html
│      Lecture08_10_Triplet Loss.html
│      Lecture08_11_Regularization Terms (L1, L2, L1+L2).html
│      Lecture08_12_Custom Loss Function Design.html
│      Lecture08_13_Part 2_3 Optimization Algorithms.html
│      Lecture08_14_Gradient Descent Review.html
│      Lecture08_15_Batch vs Mini-Batch vs Stochastic.html
│      Lecture08_16_Momentum Method.html
│      Lecture08_17_Nesterov Accelerated Gradient.html
│      Lecture08_18_AdaGrad.html
│      Lecture08_19_RMSprop.html
│      Lecture08_20_Adam and AdamW.html
│      Lecture08_21_Second-Order Optimization - L-BFGS.html
│      Lecture08_22_Comparison of Optimization Algorithms.html
│      Lecture08_23_Part 3_3 Learning Rate Scheduling.html
│      Lecture08_24_Importance of Learning Rate.html
│      Lecture08_25_Fixed vs Adaptive Learning Rate.html
│      Lecture08_26_Step Decay.html
│      Lecture08_27_Exponential Decay.html
│      Lecture08_28_Cosine Annealing.html
│      Lecture08_29_Warm-up and Linear Schedule.html
│      Lecture08_30_Cyclical Learning Rates.html
│      Lecture08_31_Thank you.html
│      lecture08_slideshow.html
│      
├─Lecture09
│      Lecture 9_ Initialization and Normalization.html
│      Lecture09_01_Lecture 9 Initialization and Normalization.html
│      Lecture09_02_Lecture Contents.html
│      Lecture09_03_Part 1_3 Initialization Strategies.html
│      Lecture09_04_Why is Initialization Important.html
│      Lecture09_05_Problems with Zero Initialization.html
│      Lecture09_06_Random Initialization and Breaking Symmetry.html
│      Lecture09_07_Gradient VanishingExploding.html
│      Lecture09_08_XavierGlorot Initialization.html
│      Lecture09_09_He Initialization (for ReLU).html
│      Lecture09_10_LSUV Initialization.html
│      Lecture09_11_Leveraging Pre-trained Weights.html
│      Lecture09_12_Comparison of Initialization Strategies.html
│      Lecture09_13_Part 2_3 Normalization Techniques.html
│      Lecture09_14_Internal Covariate Shift.html
│      Lecture09_15_Batch Normalization (Batch Norm).html
│      Lecture09_16_Layer Normalization (Layer Norm).html
│      Lecture09_17_Instance Normalization.html
│      Lecture09_18_Group Normalization.html
│      Lecture09_19_Weight Normalization.html
│      Lecture09_20_Spectral Normalization.html
│      Lecture09_21_Comparison of Normalization Techniques.html
│      Lecture09_22_When to Use Which Normalization.html
│      Lecture09_23_Part 3_3 Normalization and Generalization.html
│      Lecture09_24_Principles of Dropout.html
│      Lecture09_25_Dropout Variants (DropConnect, DropBlock).html
│      Lecture09_26_Stochastic Depth.html
│      Lecture09_27_Data Augmentation Strategies.html
│      Lecture09_28_Mixup and CutMix.html
│      Lecture09_29_Early Stopping.html
│      Lecture09_30_Ensemble Methods.html
│      Lecture09_31_Thank you.html
│      lecture09_slideshow.html
│      
├─Lecture10
│      Lecture10_01_Lecture 10 Data Modality and Feature Extraction.html
│      Lecture10_02_Lecture Contents.html
│      Lecture10_03_Part 1_3 Understanding Data Modalities.html
│      Lecture10_04_Overview of Data Modalities.html
│      Lecture10_05_Structured vs Unstructured Data.html
│      Lecture10_06_Text Data Characteristics.html
│      Lecture10_07_Image Data Characteristics.html
│      Lecture10_08_AudioSpeech Data Characteristics.html
│      Lecture10_09_Video Data Characteristics.html
│      Lecture10_10_GraphNetwork Data.html
│      Lecture10_11_Multimodal Data.html
│      Lecture10_12_Part 2_3 Traditional Feature Extraction.html
│      Lecture10_13_Feature Engineering Principles.html
│      Lecture10_14_Text - BoW, TF-IDF.html
│      Lecture10_15_Text - N-gram, POS.html
│      Lecture10_16_Image - Edge, Corner Detection.html
│      Lecture10_17_Image - SIFT, SURF, HOG.html
│      Lecture10_18_Audio - FFT, Spectrogram.html
│      Lecture10_19_Audio - MFCC, Chroma.html
│      Lecture10_20_Time Series - Statistical Features.html
│      Lecture10_21_Part 3_3 Learning-based Representations.html
│      Lecture10_22_Concept of Representation Learning.html
│      Lecture10_23_Word Embeddings (Word2Vec, GloVe).html
│      Lecture10_24_CNN-based Image Features.html
│      Lecture10_25_RNN-based Sequence Features.html
│      Lecture10_26_Autoencoders and Latent Representations.html
│      Lecture10_27_Transfer Learning Strategies.html
│      Lecture10_28_Fine-tuning vs Feature Extraction.html
│      Lecture10_29_Domain Adaptation.html
│      Lecture10_30_Multimodal Fusion.html
│      Lecture10_31_Thank you.html
│      lecture10_slideshow.html
│      
├─Lecture11
│      Lecture11_01_Lecture 11 Sequence Models.html
│      Lecture11_02_Lecture Contents.html
│      Lecture11_03_Part 1_5 Sequence Modeling.html
│      Lecture11_04_What is sequence data.html
│      Lecture11_05_Why Special Modeling Is Needed.html
│      Lecture11_06_Features of Sequences.html
│      Lecture11_07_Feature Engineering for Sequences.html
│      Lecture11_08_Part 2 5 Types of Sequence Data.html
│      Lecture11_08_Part 2_5 Types of Sequence Data.html
│      Lecture11_09_Time Series Data.html
│      Lecture11_10_Text Data.html
│      Lecture11_11_SpeechAudio Data & Other Sequences.html
│      Lecture11_12_Part 3_5 Statistical Approaches.html
│      Lecture11_13_Moving Average (MA).html
│      Lecture11_14_Autoregressive (AR).html
│      Lecture11_15_ARMA & ARIMA.html
│      Lecture11_16_Regression-Based Extensions.html
│      Lecture11_17_Limitations of Traditional Methods.html
│      Lecture11_18_Part 4_5 Deep Learning for Sequences.html
│      Lecture11_19_High-Dimensional Sequences Challenge.html
│      Lecture11_20_CNN for Sequences.html
│      Lecture11_21_RNN (Recurrent Neural Network).html
│      Lecture11_22_LSTM (Long Short-Term Memory).html
│      Lecture11_23_GRU (Gated Recurrent Unit).html
│      Lecture11_24_Bidirectional RNNs.html
│      Lecture11_25_Part 5_5 Advanced Topics.html
│      Lecture11_26_Sequence-to-Sequence Models.html
│      Lecture11_27_Encoder-Decoder Architecture.html
│      Lecture11_28_Teacher Forcing.html
│      Lecture11_29_Beam Search.html
│      Lecture11_30_CTC Loss.html
│      Lecture11_31_Practical Implementation Tips.html
│      Lecture11_32_Applications and Next Steps.html
│      Lecture11_33_Thank you.html
│      Lecture11_Slideshow.html
│      
├─Lecture12
│      Lecture12_01_Title.html
│      Lecture12_02_Contents.html
│      Lecture12_03_Part1_Intro.html
│      Lecture12_04_Review_of_Last_Lesson.html
│      Lecture12_05_Today_s Learning Objectives.html
│      Lecture12_06_Exploring the Limitations of RNNs.html
│      Lecture12_07_Part2_Intro.html
│      Lecture12_08_Why Bidirectional.html
│      Lecture12_09_Bidirectional RNN Architecture.html
│      Lecture12_10_BiRNN_Formulas_and_Operations.html
│      Lecture12_11_BiRNN Pros and Cons & Applications.html
│      Lecture12_12_Part3_Intro.html
│      Lecture12_13_The Need for Seq2Seq.html
│      Lecture12_14_Encoder-Decoder Architecture.html
│      Lecture12_15_Encoder Details.html
│      Lecture12_16_Decoder Details.html
│      Lecture12_17_Overall Seq2Seq Process.html
│      Lecture12_18_Part4_Intro.html
│      Lecture12_19_What is Teacher Forcing.html
│      Lecture12_20_Teacher Forcing vs. Autoregressive.html
│      Lecture12_21_Teacher Forcing Problems and Solutions.html
│      Lecture12_22_Part5_Intro.html
│      Lecture12_23_Limitations of Seq2Seq.html
│      Lecture12_24_Core Ideas of Attention.html
│      Lecture12_25_Attention Mechanism Structure.html
│      Lecture12_26_Attention Formula.html
│      Lecture12_27_Effects of Attention.html
│      Lecture12_28_Part6_Intro.html
│      Lecture12_29_Batching.html
│      Lecture12_30_Masking.html
│      Lecture12_31_Practical Checklist.html
│      Lecture12_32_Part7_Intro.html
│      Lecture12_33_Summary and Preview of Next Lecture.html
│      Lecture12_34_Thank_You.html
│      lecture12_slideshow.html
│      
├─Lecture13
│      Lecture13_01_Lecture 13 Transformer Architecture.html
│      Lecture13_02_Lecture Contents.html
│      Lecture13_03_Part 1_7 Introduction & Motivation.html
│      Lecture13_04_Review of Last Lesson.html
│      Lecture13_05_The Emergence and Impact of Transformers.html
│      Lecture13_06_Part 2_7 Self-Attention Mechanism.html
│      Lecture13_07_RNN Attention vs. Self-Attention.html
│      Lecture13_08_Query, Key, and Value Concepts.html
│      Lecture13_09_Self-Attention Computation Process (1-2).html
│      Lecture13_10_Self-Attention Computation Process (2-2).html
│      Lecture13_11_Self-Attention Matrix Operations.html
│      Lecture13_12_Part 3_7 Multi-Head Attention.html
│      Lecture13_13_Why is Multi-Head Necessary.html
│      Lecture13_14_Multi-Head Attention Architecture.html
│      Lecture13_15_Multi-Head Operation Example.html
│      Lecture13_16_Multi-Head Attention Implementation Points.html
│      Lecture13_17_Part 4_7 Positional Encoding.html
│      Lecture13_18_The Need for Positional Information.html
│      Lecture13_19_Positional Encoding Methods.html
│      Lecture13_20_Positional Encoding Visualization.html
│      Lecture13_21_Part 5_7 Transformer Architecture.html
│      Lecture13_22_Overall Transformer Structure.html
│      Lecture13_23_Detailed Analysis of the Encoder.html
│      Lecture13_24_Detailed Analysis of the Decoder.html
│      Lecture13_25_Feed-Forward Network & Layer Normalization.html
│      Lecture13_26_Training vs. Inference.html
│      Lecture13_27_Part 6_7 Implementation Tips.html
│      Lecture13_28_Masking Implementation.html
│      Lecture13_29_Learning Stabilization Techniques.html
│      Lecture13_30_Hyperparameter Guide.html
│      Lecture13_31_Part 7_7 Applications & Next Steps.html
│      Lecture13_32_Transformer Applications.html
│      Lecture13_33_Summary and Next Steps.html
│      Lecture13_34_Thank you.html
│      Lecture13_slideshow.html
│      
├─Lecture14
│      Lecture14_01_Lecture 14 Pre-trained Language Models & LLM Era.html
│      Lecture14_02_Lecture Contents.html
│      Lecture14_03_Part 1_9 Introduction & Paradigm Shift.html
│      Lecture14_04_Review of Previous Lessons.html
│      Lecture14_05_Paradigm Shift in AI.html
│      Lecture14_06_Part 2_9 Pre-training Concepts.html
│      Lecture14_07_What is Pre-training.html
│      Lecture14_08_Language Modeling Objective Function.html
│      Lecture14_09_The Importance of Scale.html
│      Lecture14_10_Part 3_9 BERT - Encoder-based Models.html
│      Lecture14_11_Introduction to BERT.html
│      Lecture14_12_BERT Pre-training.html
│      Lecture14_13_BERT Fine-tuning.html
│      Lecture14_14_BERT Family Models.html
│      Lecture14_15_Part 4_9 GPT - Decoder-based Models.html
│      Lecture14_16_Introduction to the GPT Series.html
│      Lecture14_17_GPT Pre-training.html
│      Lecture14_18_GPT-3 and Few-shot Learning.html
│      Lecture14_19_GPT Family Development.html
│      Lecture14_20_Part 5_9 Encoder-Decoder Models.html
│      Lecture14_21_T5 - Text-to-Text Framework.html
│      Lecture14_22_BART and Other Models.html
│      Lecture14_23_Part 6_9 Fine-tuning Strategies.html
│      Lecture14_24_Full Fine-tuning vs. Transfer Learning.html
│      Lecture14_25_Parameter-Efficient Fine-tuning.html
│      Lecture14_26_Fine-tuning Practical Tips.html
│      Lecture14_27_Part 7_9 Prompting & In-Context Learning.html
│      Lecture14_28_Prompt Engineering Basics.html
│      Lecture14_29_Advanced Prompting Techniques.html
│      Lecture14_30_Fine-tuning vs. Prompting.html
│      Lecture14_31_Part 8_9 Current Trends.html
│      Lecture14_32_RLHF and Instruction Tuning.html
│      Lecture14_33_Present and Future.html
│      Lecture14_34_Part 9_9 Ethics and Practice.html
│      Lecture14_35_Summary and Practical Considerations.html
│      Lecture14_36_Thank you.html
│      lecture14_slideshow.html
│      
├─Lecture15
│      Lecture15_01_Lecture 15 Generative Models - GAN.html
│      Lecture15_02_Lecture Contents.html
│      Lecture15_03_Part 1_6 Introduction & Motivation.html
│      Lecture15_04_Review of Generative Models.html
│      Lecture15_05_Why GANs.html
│      Lecture15_06_Intuitive Understanding - Counterfeiter Analogy.html
│      Lecture15_07_Part 2_6 Mathematical Foundations.html
│      Lecture15_08_Probability Distribution Perspective.html
│      Lecture15_09_Mathematical Definition of GAN.html
│      Lecture15_10_Value Function Analysis.html
│      Lecture15_11_Deriving Optimal Discriminator.html
│      Lecture15_12_Global Optimum.html
│      Lecture15_13_Part 3_6 Training Algorithm.html
│      Lecture15_14_Training Process Overview.html
│      Lecture15_15_Detailed Algorithm.html
│      Lecture15_16_Gradient Flow.html
│      Lecture15_17_Non-Saturating Loss.html
│      Lecture15_18_Practical Tips.html
│      Lecture15_19_Part 4_6 Key Challenges.html
│      Lecture15_20_Mode Collapse.html
│      Lecture15_21_Training Instability.html
│      Lecture15_22_Evaluation Difficulties.html
│      Lecture15_23_Vanishing Gradient Details.html
│      Lecture15_24_Common Failure Patterns.html
│      Lecture15_25_Part 5 6 Improvement Techniques.html
│      Lecture15_25_Part 5_6 Improvement Techniques.html
│      Lecture15_26_DCGAN (2015).html
│      Lecture15_27_Conditional GAN (cGAN).html
│      Lecture15_28_Wasserstein GAN (WGAN).html
│      Lecture15_29_Other Improvements.html
│      Lecture15_30_Part 6_6 Hands-on & Applications.html
│      Lecture15_33_Thank you.html
│      lecture15_slideshow.html
│      
├─Lecture16
│      Lecture16_01_Lecture 16 Generative Models - Diffusion.html
│      Lecture16_02_Lecture Contents.html
│      Lecture16_03_Part 1_7 Introduction & Motivation.html
│      Lecture16_04_Evolution of Generative Models.html
│      Lecture16_05_Intuitive Understanding.html
│      Lecture16_06_Comparison with GANs.html
│      Lecture16_07_Part 2_7 Forward Process.html
│      Lecture16_08_Forward Process Definition.html
│      Lecture16_09_Cumulative Effect.html
│      Lecture16_10_Mathematical Properties.html
│      Lecture16_11_Forward Process Visualization.html
│      Lecture16_12_Why is this Process Necessary.html
│      Lecture16_13_Part 3_7 Reverse Process.html
│      Lecture16_14_Reverse Process Goal.html
│      Lecture16_15_Neural Network Parameterization.html
│      Lecture16_16_Deep Dive into Score Function.html
│      Lecture16_17_Denoising Objective Function.html
│      Lecture16_18_Training Algorithm.html
│      Lecture16_19_Part 4_7 Sampling.html
│      Lecture16_20_DDPM Sampling.html
│      Lecture16_21_DDIM - Fast Sampling.html
│      Lecture16_22_Conditional Generation.html
│      Lecture16_23_Classifier-Free Guidance.html
│      Lecture16_24_Part 5_7 Architecture.html
│      Lecture16_25_U-Net Structure.html
│      Lecture16_26_Attention Mechanism.html
│      Lecture16_27_Condition Injection Methods.html
│      Lecture16_28_Part 6_7 Advanced Techniques.html
│      Lecture16_29_Latent Diffusion (Stable Diffusion).html
│      Lecture16_30_Noise Schedule Improvements.html
│      Lecture16_31_Other Improvement Techniques.html
│      Lecture16_32_Part 7_7 Applications and Extensions.html
│      Lecture16_33_Applications and Conclusion.html
│      Lecture16_34_Thank you.html
│      Lecture16_slideshow.html
│      
├─Lecture17
│      Lecture 17_ Clustering and Unsupervised Learning Fundamentals.html
│      Lecture17_01_Lecture 17 Clustering and Unsupervised Learning Fundamentals.html
│      Lecture17_02_Lecture Contents.html
│      Lecture17_03_Part 1_4 Unsupervised Learning Overview.html
│      Lecture17_04_What is Unsupervised Learning.html
│      Lecture17_05_Supervised vs Unsupervised vs Semi-supervised.html
│      Lecture17_06_Applications of Unsupervised Learning.html
│      Lecture17_07_Key Challenges and Evaluation Methods.html
│      Lecture17_08_Data Preprocessing and Scaling.html
│      Lecture17_09_Part 2_4 Clustering Algorithms.html
│      Lecture17_10_Clustering Problem Definition.html
│      Lecture17_11_K-Means Algorithm.html
│      Lecture17_12_K-Means++ Initialization.html
│      Lecture17_13_Hierarchical Clustering.html
│      Lecture17_14_DBSCAN - Density-Based.html
│      Lecture17_15_Mean Shift.html
│      Lecture17_16_Gaussian Mixture Models.html
│      Lecture17_17_Cluster Evaluation Metrics.html
│      Lecture17_18_Part 3_4 Dimensionality Reduction.html
│      Lecture17_19_Curse of Dimensionality.html
│      Lecture17_20_PCA Principles and Implementation.html
│      Lecture17_21_Kernel PCA.html
│      Lecture17_22_t-SNE Algorithm.html
│      Lecture17_23_UMAP.html
│      Lecture17_24_Autoencoder Dimensionality Reduction.html
│      Lecture17_25_VAE Basics.html
│      Lecture17_26_Part 4_4 Basic Anomaly Detection.html
│      Lecture17_27_Anomaly Detection Overview.html
│      Lecture17_28_Statistical Methods.html
│      Lecture17_29_Isolation Forest.html
│      Lecture17_30_Hands-on Implementation with scikit-learn.html
│      Lecture17_31_Summary and Next Lecture Preview.html
│      Lecture17_32_Thank you.html
│      lecture17_slideshow.html
│      
├─Lecture18
│      Lecture18_01_Lecture 18 Advanced Unsupervised Learning.html
│      Lecture18_02_Lecture Contents.html
│      Lecture18_03_Part 1_4 Self-Supervised Learning.html
│      Lecture18_04_Lecture Overview and Recap.html
│      Lecture18_05_What is Self-Supervised Learning.html
│      Lecture18_06_Contrastive Learning Principles.html
│      Lecture18_07_SimCLR Algorithm.html
│      Lecture18_08_MoCo and BYOL.html
│      Lecture18_09_Self-Supervised Pretraining.html
│      Lecture18_10_Hands-on Image Representation Learning.html
│      Lecture18_11_Part 2_4 Time Series Clustering.html
│      Lecture18_12_Characteristics of Time Series Data.html
│      Lecture18_13_DTW (Dynamic Time Warping) Principles.html
│      Lecture18_14_DTW-based Clustering.html
│      Lecture18_15_K-Shape Algorithm.html
│      Lecture18_16_Subsequence Clustering.html
│      Lecture18_17_Hands-on StockSensor Data Clustering.html
│      Lecture18_18_Part 3_4 Graph Clustering.html
│      Lecture18_19_Introduction to Graph Data.html
│      Lecture18_20_Spectral Clustering.html
│      Lecture18_21_Community Detection (Louvain).html
│      Lecture18_22_GNN Fundamentals.html
│      Lecture18_23_Clustering with GCN.html
│      Lecture18_24_Deep Graph Infomax.html
│      Lecture18_25_Hands-on Social Network Analysis.html
│      Lecture18_26_Part 4_4 Advanced Topics and Applications.html
│      Lecture18_27_Deep Clustering (DeepCluster, SwAV).html
│      Lecture18_28_Multi-modal Clustering.html
│      Lecture18_29_Large-Scale Clustering.html
│      Lecture18_30_Real-world Applications (by Industry).html
│      Lecture18_32_Thank you.html
│      lecture18_slideshow.html
│      
├─Lecture19
│      Lecture 19_ Model Explainability - XAI Fundamentals and Traditional Methods.html
│      Lecture19_01_Lecture 19 Model Explainability - XAI Fundamentals and Traditional Methods.html
│      Lecture19_02_Lecture Contents.html
│      Lecture19_03_Part 1_4 Introduction to XAI and Its Importance.html
│      Lecture19_04_Course Introduction - The Era of Explainable AI.html
│      Lecture19_05_Model Complexity vs Interpretability Trade-off.html
│      Lecture19_06_Core Concepts and Terminology in XAI.html
│      Lecture19_07_Why Explainability is Necessary.html
│      Lecture19_08_XAI Classification Framework.html
│      Lecture19_09_XAI Applications by Industry.html
│      Lecture19_10_XAI Evaluation Criteria.html
│      Lecture19_11_Part 2_4 Intrinsically Interpretable Models.html
│      Lecture19_12_Interpreting Linear Models.html
│      Lecture19_13_Transparency of Decision Trees.html
│      Lecture19_14_Generalized Additive Models (GAM).html
│      Lecture19_15_Rule-Based Models.html
│      Lecture19_16_Monotonic Constraint Models.html
│      Lecture19_17_Sparse Linear Models.html
│      Lecture19_18_Hands-on Building Interpretable Models with scikit-learn.html
│      Lecture19_19_Part 3_4 Feature Importance Methodologies.html
│      Lecture19_20_Permutation Importance.html
│      Lecture19_21_Drop-Column Importance.html
│      Lecture19_22_Partial Dependence Plots (PDP) (1).html
│      Lecture19_22_Partial Dependence Plots (PDP).html
│      Lecture19_23_Individual Conditional Expectation (ICE).html
│      Lecture19_24_Accumulated Local Effects (ALE).html
│      Lecture19_25_Feature Interaction Analysis.html
│      Lecture19_26_Part 4_4 Model-Agnostic Methods.html
│      Lecture19_27_Surrogate Models.html
│      Lecture19_28_Introduction to LIME.html
│      Lecture19_29_LIME Advanced Topics.html
│      Lecture19_30_Anchor Explanations.html
│      Lecture19_31_Practical Guidelines and Best Practices.html
│      Lecture19_32_Thank you.html
│      lecture19_slideshow.html
│      
├─Lecture20
│      Lecture20_01_Lecture 20 Model Explainability - SHAP and Deep Learning XAI.html
│      Lecture20_02_Lecture Contents.html
│      Lecture20_03_Part 1_4 SHAP Theory and Fundamentals.html
│      Lecture20_04_Course Introduction - Game Theory-Based Explainability.html
│      Lecture20_05_Cooperative Game Theory Basics.html
│      Lecture20_06_Shapley Values Mathematical Definition.html
│      Lecture20_07_Core Ideas of SHAP.html
│      Lecture20_08_SHAP vs LIME Comparison.html
│      Lecture20_09_Interpreting SHAP Values.html
│      Lecture20_10_Mathematical Properties of SHAP.html
│      Lecture20_11_Hands-on First SHAP Analysis.html
│      Lecture20_12_Part 2_4 SHAP Implementation Methods.html
│      Lecture20_13_KernelSHAP.html
│      Lecture20_14_TreeSHAP.html
│      Lecture20_15_DeepSHAP (DeepLIFT + SHAP).html
│      Lecture20_16_GradientSHAP.html
│      Lecture20_17_SHAP Approximation Techniques.html
│      Lecture20_18_SHAP Interaction Values.html
│      Lecture20_19_Hands-on Comparing Different SHAP Explainers.html
│      Lecture20_20_Part 3_4 SHAP Visualization and Analysis.html
│      Lecture20_21_Waterfall Plot.html
│      Lecture20_22_Force Plot and Decision Plot.html
│      Lecture20_23_Summary Plot and Dependence Plot.html
│      Lecture20_24_SHAP for Time Series.html
│      Lecture20_25_SHAP for Text and Images.html
│      Lecture20_26_Part 4_4 Advanced Deep Learning XAI Techniques.html
│      Lecture20_27_Attention Mechanisms as Explanations.html
│      Lecture20_28_Gradient-based Methods.html
│      Lecture20_29_CAM-family Methods.html
│      Lecture20_30_Concept-based Explanations.html
│      Lecture20_31_Future of XAI and Challenges.html
│      Lecture20_32_Thank you.html
│      lecture20_slideshow.html
│      
└─Practical sessions
        Lecture_10_Data_Modality_and_Feature_Extraction.ipynb
        Lecture_11_Sequence_Models.ipynb
        Lecture_12_Advanced_Sequence_Models.ipynb
        Lecture_13_Transformer_Architecture.ipynb
        Lecture_14_Pre-trained_Language_Models_and_LLM_Era.ipynb
        Lecture_15_Generative_Models-GAN.ipynb
        Lecture_16_Generative_Models-Diffusion.ipynb
        Lecture_17_Clustering_and_Unsupervised_Learning.ipynb
        Lecture_18_Advanced_Unsupervised_Learning.ipynb
        Lecture_19_Model_Explainability-XAI_Fundamentals_and_Traditional_Methods.ipynb
        Lecture_20_Model_Explainability-SHAP_and_Deep_Learning_XAI.ipynb
        Lecture_2_Data_Visualization.ipynb
        Lecture_3_From_Set_Theory_to_Linear_Regression.ipynb
        Lecture_4_From_Linear_to_Logistic_Regression.ipynb
        Lecture_5_From_Logistic_Regression_to_Multi-layer_Perceptrons.ipynb
        Lecture_6_Supervised_Learning_Evaluation.ipynb
        Lecture_7_Deep_Learning.ipynb
        Lecture_8_Loss,_Optimization,_and_Scheduling.ipynb
        Lecture_9_Initialization_and_Normalization.ipynb
        
