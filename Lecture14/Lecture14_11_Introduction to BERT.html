<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to BERT</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Aptos, 'Segoe UI', sans-serif;
            background: #f5f5f5;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
            padding: 30px 20px;
            gap: 30px;
        }
        
        .container {
            width: 960px;
            min-height: 540px;
            position: relative;
            background: #ffffff;
            padding: 25px 40px;
            border-radius: 12px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        .title {
            font-size: 26px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 10px;
            text-align: center;
        }
        
        .subtitle {
            font-size: 18px;
            color: #666666;
            margin-bottom: 20px;
            text-align: center;
        }
        
        .main-layout {
            display: grid;
            grid-template-columns: 1fr 1.1fr;
            gap: 25px;
            min-height: 410px;
        }
        
        /* Architecture Section */
        .architecture-section {
            display: flex;
            flex-direction: column;
            gap: 15px;
        }
        
        .architecture-box {
            background: #F8F9FA;
            border: 3px solid #1E64C8;
            border-radius: 12px;
            padding: 20px;
            flex: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        
        .encoder-stack {
            display: flex;
            flex-direction: column-reverse;
            gap: 8px;
            margin: 15px 0;
        }
        
        .encoder-layer {
            background: #1E64C8;
            border: 2px solid #1557A8;
            border-radius: 8px;
            padding: 12px 20px;
            text-align: center;
            color: white;
            font-size: 16px;
            font-weight: 600;
            position: relative;
        }
        
        .encoder-layer.highlight {
            background: #2E7FD8;
            box-shadow: 0 0 15px rgba(30, 100, 200, 0.5);
        }
        
        .bidirectional-arrows {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 10px 0;
        }
        
        .arrow-group {
            display: flex;
            align-items: center;
            gap: 5px;
            font-size: 20px;
            color: #1E64C8;
            font-weight: 600;
        }
        
        .input-tokens {
            display: flex;
            gap: 8px;
            justify-content: center;
            margin-top: 10px;
        }
        
        .token {
            background: #E8F4F8;
            border: 2px solid #1E64C8;
            border-radius: 6px;
            padding: 6px 12px;
            font-size: 14px;
            font-weight: 500;
            color: #1E64C8;
        }
        
        .specs-box {
            background: #E8F4F8;
            border: 2px solid #1E64C8;
            border-radius: 8px;
            padding: 12px 15px;
        }
        
        .specs-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
        }
        
        .spec-item {
            font-size: 16px;
            color: #333333;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .spec-label {
            font-weight: 600;
            color: #1E64C8;
        }
        
        /* Features Section */
        .features-section {
            display: flex;
            flex-direction: column;
            gap: 12px;
        }
        
        .feature-card {
            background: #E8F4F8;
            border-left: 4px solid #1E64C8;
            border-radius: 8px;
            padding: 12px 15px;
            display: flex;
            align-items: flex-start;
            gap: 12px;
        }
        
        .feature-icon {
            font-size: 24px;
            flex-shrink: 0;
            margin-top: 2px;
        }
        
        .feature-content {
            flex: 1;
        }
        
        .feature-title {
            font-size: 17px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 4px;
        }
        
        .feature-text {
            font-size: 16px;
            color: #333333;
            line-height: 1.4;
        }
        
        .achievement-box {
            background: #C8E6C9;
            border: 3px solid #4CAF50;
            border-radius: 10px;
            padding: 15px 18px;
            text-align: center;
        }
        
        .achievement-icon {
            font-size: 32px;
            margin-bottom: 8px;
        }
        
        .achievement-title {
            font-size: 18px;
            font-weight: 600;
            color: #2E7D32;
            margin-bottom: 5px;
        }
        
        .achievement-text {
            font-size: 16px;
            color: #1B5E20;
            line-height: 1.3;
        }
        
        .highlight {
            font-weight: 600;
            color: #1E64C8;
        }
        
        /* Process Section Styles */
        .section-title {
            font-size: 24px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 20px;
            text-align: center;
            padding-bottom: 10px;
            border-bottom: 3px solid #1E64C8;
        }
        
        .process-container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        
        .process-step {
            background: #ffffff;
            border: 2px solid #1E64C8;
            border-radius: 12px;
            padding: 20px;
            position: relative;
        }
        
        .step-header {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 15px;
        }
        
        .step-number {
            background: #1E64C8;
            color: white;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 20px;
            font-weight: 600;
            flex-shrink: 0;
        }
        
        .step-title {
            font-size: 20px;
            font-weight: 600;
            color: #1E64C8;
        }
        
        .step-content {
            padding-left: 55px;
        }
        
        .step-description {
            font-size: 16px;
            color: #333333;
            line-height: 1.6;
            margin-bottom: 12px;
        }
        
        .example-box {
            background: #F8F9FA;
            border-left: 4px solid #FFA726;
            border-radius: 6px;
            padding: 12px 15px;
            margin-top: 10px;
        }
        
        .example-label {
            font-size: 14px;
            font-weight: 600;
            color: #F57C00;
            margin-bottom: 6px;
        }
        
        .example-text {
            font-size: 15px;
            color: #555555;
            font-family: 'Courier New', monospace;
            line-height: 1.5;
        }
        
        .masked-token {
            background: #FFE0B2;
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: 600;
            color: #E65100;
        }
        
        .arrow-down {
            text-align: center;
            font-size: 32px;
            color: #1E64C8;
            margin: 10px 0;
        }
        
        .task-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin-top: 10px;
        }
        
        .task-card {
            background: #E8F4F8;
            border: 2px solid #1E64C8;
            border-radius: 8px;
            padding: 15px;
        }
        
        .task-title {
            font-size: 16px;
            font-weight: 600;
            color: #1E64C8;
            margin-bottom: 8px;
        }
        
        .task-description {
            font-size: 14px;
            color: #555555;
            line-height: 1.4;
        }
        
        .result-box {
            background: #C8E6C9;
            border: 2px solid #4CAF50;
            border-radius: 8px;
            padding: 15px;
            margin-top: 15px;
        }
        
        .result-title {
            font-size: 16px;
            font-weight: 600;
            color: #2E7D32;
            margin-bottom: 8px;
        }
        
        .result-text {
            font-size: 15px;
            color: #1B5E20;
            line-height: 1.5;
        }
    </style>
</head>
<body>
    <!-- Original Overview Section -->
    <div class="container">
        <div class="title">BERT: Bidirectional Encoder Representations from Transformers</div>
        <div class="subtitle">Google, 2018 - Revolutionary NLP Model</div>
        
        <div class="main-layout">
            <!-- Architecture Section -->
            <div class="architecture-section">
                <div class="architecture-box">
                    <div class="bidirectional-arrows">
                        <div class="arrow-group">‚Üê Left</div>
                        <div class="arrow-group">Right ‚Üí</div>
                    </div>
                    
                    <div class="encoder-stack">
                        <div class="encoder-layer">Encoder Layer 1</div>
                        <div class="encoder-layer">Encoder Layer 2</div>
                        <div class="encoder-layer">...</div>
                        <div class="encoder-layer highlight">Encoder Layer N</div>
                    </div>
                    
                    <div style="font-size: 16px; color: #1E64C8; font-weight: 600; margin: 10px 0;">
                        ‚ÜïÔ∏è Bidirectional Attention
                    </div>
                    
                    <div class="input-tokens">
                        <div class="token">[CLS]</div>
                        <div class="token">Token</div>
                        <div class="token">Token</div>
                        <div class="token">[SEP]</div>
                    </div>
                </div>
                
                <div class="specs-box">
                    <div class="specs-grid">
                        <div class="spec-item">
                            <span class="spec-label">Base:</span>
                            <span>110M params</span>
                        </div>
                        <div class="spec-item">
                            <span class="spec-label">Large:</span>
                            <span>340M params</span>
                        </div>
                        <div class="spec-item" style="grid-column: 1 / -1;">
                            <span class="spec-label">Dataset:</span>
                            <span>BooksCorpus + Wikipedia (3.3B words)</span>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Features Section -->
            <div class="features-section">
                <div class="feature-card">
                    <div class="feature-icon">üîÑ</div>
                    <div class="feature-content">
                        <div class="feature-title">Bidirectional Context</div>
                        <div class="feature-text">
                            Deep <span class="highlight">bidirectional</span> understanding from both directions
                        </div>
                    </div>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">üóÇÔ∏è</div>
                    <div class="feature-content">
                        <div class="feature-title">Transformer Encoder</div>
                        <div class="feature-text">
                            Stack of <span class="highlight">Transformer encoders</span> with self-attention
                        </div>
                    </div>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">üìö</div>
                    <div class="feature-content">
                        <div class="feature-title">Pre-training Corpus</div>
                        <div class="feature-text">
                            Trained on <span class="highlight">BooksCorpus</span> and <span class="highlight">Wikipedia</span>
                        </div>
                    </div>
                </div>
                
                <div class="feature-card">
                    <div class="feature-icon">‚ö°</div>
                    <div class="feature-content">
                        <div class="feature-title">Two Model Sizes</div>
                        <div class="feature-text">
                            BERT-Base (110M) and BERT-Large (340M) parameters
                        </div>
                    </div>
                </div>
                
                <div class="achievement-box">
                    <div class="achievement-icon">üèÜ</div>
                    <div class="achievement-title">State-of-the-Art Performance</div>
                    <div class="achievement-text">
                        Achieved SOTA on <strong>11 NLP benchmarks</strong><br>
                        Revolutionized NLP in 2018
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Training Process Section -->
    <div class="container">
        <div class="section-title">üéì BERT Pre-Training Process</div>
        
        <div class="process-container">
            <!-- Step 1 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">1</div>
                    <div class="step-title">Input Preparation</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Tokenize the input text and add special tokens. [CLS] marks the start of the sentence, and [SEP] marks the end.
                    </div>
                    <div class="example-box">
                        <div class="example-label">üìù Example Input:</div>
                        <div class="example-text">
                            "The cat sat on the mat"<br>
                            ‚Üí [CLS] The cat sat on the mat [SEP]
                        </div>
                    </div>
                </div>
            </div>

            <!-- Step 2 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">2</div>
                    <div class="step-title">Masked Language Modeling (MLM)</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Randomly mask 15% of input tokens. The model learns to predict masked words using bidirectional context.
                    </div>
                    <div class="example-box">
                        <div class="example-label">üé≠ Masking Example:</div>
                        <div class="example-text">
                            Input: [CLS] The cat sat on the mat [SEP]<br>
                            Masked: [CLS] The <span class="masked-token">[MASK]</span> sat on the mat [SEP]<br>
                            Target: Predict "cat"
                        </div>
                    </div>
                    <div class="result-box">
                        <div class="result-title">üí° Key Points</div>
                        <div class="result-text">
                            ‚Ä¢ 80% replaced with [MASK]<br>
                            ‚Ä¢ 10% replaced with random word<br>
                            ‚Ä¢ 10% keep original word
                        </div>
                    </div>
                </div>
            </div>

            <!-- Step 3 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">3</div>
                    <div class="step-title">Next Sentence Prediction (NSP)</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Learn to determine whether two sentences are consecutive. This improves the ability to understand relationships between sentences.
                    </div>
                    <div class="example-box">
                        <div class="example-label">üîó NSP Example:</div>
                        <div class="example-text">
                            <strong>Case 1 (IsNext):</strong><br>
                            [CLS] The cat sat on the mat [SEP] It was sleeping [SEP]<br>
                            Label: IsNext ‚úì<br><br>
                            <strong>Case 2 (NotNext):</strong><br>
                            [CLS] The cat sat on the mat [SEP] Paris is beautiful [SEP]<br>
                            Label: NotNext ‚úó
                        </div>
                    </div>
                </div>
            </div>

            <!-- Step 4 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">4</div>
                    <div class="step-title">Training Objective</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Train the model by simultaneously optimizing both MLM and NSP losses.
                    </div>
                    <div class="task-grid">
                        <div class="task-card">
                            <div class="task-title">MLM Loss</div>
                            <div class="task-description">
                                Cross-Entropy Loss aiming for accurate prediction of masked tokens
                            </div>
                        </div>
                        <div class="task-card">
                            <div class="task-title">NSP Loss</div>
                            <div class="task-description">
                                Binary Classification Loss for correctly judging sentence pair continuity
                            </div>
                        </div>
                    </div>
                    <div class="result-box">
                        <div class="result-title">üéØ Total Loss</div>
                        <div class="result-text">
                            Loss = MLM Loss + NSP Loss
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Fine-tuning Process Section -->
    <div class="container">
        <div class="section-title">üéØ BERT Fine-tuning Process</div>
        
        <div class="process-container">
            <!-- Step 1 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">1</div>
                    <div class="step-title">Load Pre-trained Model</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Load the pre-trained BERT model. It has already learned general patterns of language.
                    </div>
                    <div class="result-box">
                        <div class="result-title">‚ú® Pre-trained Knowledge</div>
                        <div class="result-text">
                            ‚Ä¢ Understanding grammatical structure<br>
                            ‚Ä¢ Capturing semantic relationships<br>
                            ‚Ä¢ Bidirectional context comprehension
                        </div>
                    </div>
                </div>
            </div>

            <!-- Step 2 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">2</div>
                    <div class="step-title">Add Task-Specific Layer</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Add an output layer specific to the task. Different structures are used depending on the task.
                    </div>
                    <div class="task-grid">
                        <div class="task-card">
                            <div class="task-title">üìä Classification</div>
                            <div class="task-description">
                                [CLS] token output + Softmax Layer<br>
                                (Sentiment analysis, topic classification, etc.)
                            </div>
                        </div>
                        <div class="task-card">
                            <div class="task-title">üè∑Ô∏è Token Classification</div>
                            <div class="task-description">
                                Each token output + Classification Layer<br>
                                (Named entity recognition, POS tagging, etc.)
                            </div>
                        </div>
                        <div class="task-card">
                            <div class="task-title">‚ùì Question Answering</div>
                            <div class="task-description">
                                Start/End Position Prediction Layers<br>
                                (SQuAD, reading comprehension, etc.)
                            </div>
                        </div>
                        <div class="task-card">
                            <div class="task-title">üîÑ Sequence Pairing</div>
                            <div class="task-description">
                                [CLS] token + Binary Classifier<br>
                                (Natural language inference, sentence similarity, etc.)
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Step 3 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">3</div>
                    <div class="step-title">Fine-tune on Task Data</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Fine-tune the entire model with task-specific training data. Typically, 2-4 epochs are sufficient.
                    </div>
                    <div class="example-box">
                        <div class="example-label">üìù Sentiment Analysis Example:</div>
                        <div class="example-text">
                            Input: [CLS] This movie is amazing [SEP]<br>
                            ‚Üí BERT Encoding ‚Üí<br>
                            ‚Üí Classification Layer ‚Üí<br>
                            Output: Positive (95% confidence)
                        </div>
                    </div>
                    <div class="result-box">
                        <div class="result-title">‚öôÔ∏è Training Settings</div>
                        <div class="result-text">
                            ‚Ä¢ Learning Rate: 2e-5 ~ 5e-5<br>
                            ‚Ä¢ Epochs: 2-4<br>
                            ‚Ä¢ Batch Size: 16 or 32
                        </div>
                    </div>
                </div>
            </div>

            <!-- Step 4 -->
            <div class="process-step">
                <div class="step-header">
                    <div class="step-number">4</div>
                    <div class="step-title">Inference & Prediction</div>
                </div>
                <div class="step-content">
                    <div class="step-description">
                        Use the fine-tuned model to make predictions on new data.
                    </div>
                    <div class="example-box">
                        <div class="example-label">üîÆ Prediction Pipeline:</div>
                        <div class="example-text">
                            <strong>Step 1:</strong> Tokenize new input<br>
                            <strong>Step 2:</strong> Pass through fine-tuned BERT<br>
                            <strong>Step 3:</strong> Apply task-specific head<br>
                            <strong>Step 4:</strong> Generate prediction with confidence score
                        </div>
                    </div>
                    <div class="result-box">
                        <div class="result-title">üéä Final Output</div>
                        <div class="result-text">
                            Generate results in the appropriate format for the task:<br>
                            Classification labels, token tags, answer spans, etc.
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div style="text-align: center; padding: 20px; color: #666;">
        <p style="font-size: 14px;">BERT revolutionized NLP by introducing bidirectional pre-training and transfer learning to the field.</p>
    </div>
</body>
</html>