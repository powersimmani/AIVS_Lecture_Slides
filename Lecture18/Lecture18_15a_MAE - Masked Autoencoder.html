<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MAE - Masked Autoencoder</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: Aptos, 'Segoe UI', sans-serif; background: #FFFFFF; display: flex; justify-content: center; align-items: center; min-height: 100vh; padding: 20px; }
        .container { width: 960px; height: 540px; padding: 25px 35px; display: flex; flex-direction: column; }
        .title-section { text-align: center; margin-bottom: 12px; }
        .main-title { font-size: 24px; font-weight: 600; color: #1E64C8; margin-bottom: 4px; }
        .subtitle { font-size: 14px; color: #666; }
        .content-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 16px; flex: 1; }
        .card { background: white; border: 2.5px solid #1E64C8; border-radius: 12px; padding: 14px; display: flex; flex-direction: column; }
        .card.concept { border-color: #2196F3; }
        .card.details { border-color: #FF9800; }
        .card-title { font-size: 16px; font-weight: 700; margin-bottom: 10px; }
        .concept .card-title { color: #2196F3; }
        .details .card-title { color: #FF9800; }
        .idea-box { background: #E3F2FD; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .idea-title { font-size: 12px; font-weight: 700; color: #1565C0; margin-bottom: 6px; }
        .idea-content { font-size: 11px; color: #333; line-height: 1.5; }
        .arch-box { background: #f8f8f8; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .arch-title { font-size: 12px; font-weight: 700; color: #1E64C8; margin-bottom: 6px; }
        .arch-content { font-family: 'Courier New', monospace; font-size: 10px; color: #333; line-height: 1.5; }
        .why-box { background: #E8F5E9; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .why-title { font-size: 12px; font-weight: 700; color: #2E7D32; margin-bottom: 6px; }
        .why-content { font-size: 11px; color: #333; line-height: 1.5; }
        .stats-box { background: #FFF3E0; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .stats-title { font-size: 12px; font-weight: 700; color: #E65100; margin-bottom: 6px; }
        .stats-item { font-size: 11px; color: #333; margin-bottom: 4px; }
        .comparison-box { background: #F3E5F5; border-radius: 8px; padding: 10px; margin-top: auto; }
        .comparison-title { font-size: 12px; font-weight: 700; color: #7B1FA2; margin-bottom: 6px; }
        .comparison-content { font-size: 11px; color: #333; line-height: 1.4; }
        .key-insight { background: #FFEBEE; border-radius: 8px; padding: 10px; margin-bottom: 10px; }
        .key-title { font-size: 12px; font-weight: 700; color: #C62828; margin-bottom: 6px; }
        .key-content { font-size: 11px; color: #333; line-height: 1.5; }
    </style>
</head>
<body>
    <div class="container">
        <div class="title-section">
            <div class="main-title">MAE: Masked Autoencoders Are Scalable Vision Learners</div>
            <div class="subtitle">BERT-style pre-training for images (He et al., 2021)</div>
        </div>
        <div class="content-grid">
            <div class="card concept">
                <div class="card-title">Core Idea</div>
                <div class="idea-box">
                    <div class="idea-title">Simple Yet Powerful</div>
                    <div class="idea-content">
                        1. Randomly mask 75% of image patches<br>
                        2. Encode only visible patches (25%)<br>
                        3. Decode to reconstruct full image<br>
                        4. Loss: MSE on masked patches only
                    </div>
                </div>
                <div class="arch-box">
                    <div class="arch-title">Architecture</div>
                    <div class="arch-content">
                        Image -> [Patchify] -> [Mask 75%]<br>
                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
                        Visible patches -> [ViT Encoder] -> latent<br>
                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
                        latent + [MASK] -> [Small Decoder] -> pixels<br>
                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;|<br>
                        Loss = MSE(prediction, original) on masked
                    </div>
                </div>
                <div class="why-box">
                    <div class="why-title">Why 75% Masking?</div>
                    <div class="why-content">
                        <strong>Images have high redundancy:</strong><br>
                        • Missing patches can be inferred from neighbors<br>
                        • 75% forces learning semantic understanding<br>
                        • Too little masking = trivial task (just interpolate)<br>
                        • Compare: BERT uses only 15% masking for text
                    </div>
                </div>
            </div>
            <div class="card details">
                <div class="card-title">Key Design Choices</div>
                <div class="key-insight">
                    <div class="key-title">Asymmetric Encoder-Decoder</div>
                    <div class="key-content">
                        <strong>Encoder:</strong> Large ViT, operates on 25% patches only<br>
                        <strong>Decoder:</strong> Small, lightweight (8 blocks)<br><br>
                        <em>This makes pre-training 3x faster!</em>
                    </div>
                </div>
                <div class="stats-box">
                    <div class="stats-title">Performance Results</div>
                    <div class="stats-item"><strong>ImageNet fine-tune:</strong> 87.8% (ViT-H)</div>
                    <div class="stats-item"><strong>Pre-training speed:</strong> 3x faster than contrastive</div>
                    <div class="stats-item"><strong>Data efficiency:</strong> Works with ImageNet-1K alone</div>
                    <div class="stats-item"><strong>Transfer:</strong> Strong on detection, segmentation</div>
                </div>
                <div class="comparison-box">
                    <div class="comparison-title">MAE vs Contrastive (SimCLR, MoCo)</div>
                    <div class="comparison-content">
                        <strong>MAE advantages:</strong><br>
                        • No negative samples needed<br>
                        • No data augmentation design<br>
                        • More efficient (processes 25% of image)<br>
                        • Simpler training recipe<br><br>
                        <strong>Contrastive advantages:</strong><br>
                        • Better for linear probe (features more semantic)<br>
                        • Works well with smaller models
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
