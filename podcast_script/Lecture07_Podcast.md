# Lecture 07 Podcast: 데이터 모달리티와 특징 추출의 모든 것

## 에피소드 정보
- **주제**: 다양한 데이터 유형과 전통적/딥러닝 기반 특징 추출
- **예상 시간**: 15분
- **대상**: 다양한 데이터를 다루는 ML 실무자와 연구자

---

## 스크립트

**[인트로 - 0:00]**

**Host A**: 안녕하세요! AI 비전 시스템 팟캐스트에 오신 것을 환영합니다. 오늘은 정말 중요한 주제를 다룰 거예요.

**Host B**: 네! 오늘은 데이터 모달리티에 대해 이야기해볼 건데요. 텍스트, 이미지, 오디오, 비디오... 각각의 데이터 유형이 어떤 특징을 가지고 있고, 어떻게 처리해야 하는지 알아볼 거예요.

**Host A**: 요즘 멀티모달 AI가 화제잖아요. GPT-4도 이미지를 이해하고, 음성도 처리하고. 이런 기술의 기반이 되는 개념들이죠.

**Host B**: 맞아요! 각 데이터 유형의 특성을 이해하는 게 멀티모달 학습의 첫걸음이에요.

---

**[섹션 1: 데이터 모달리티란? - 1:30]**

**Host A**: 먼저 데이터 모달리티가 뭔지 설명해주실래요?

**Host B**: 모달리티는 쉽게 말해 데이터의 종류예요. 텍스트, 이미지, 오디오, 비디오, 시계열, 그래프, 테이블 데이터 등이 있죠. 각각이 완전히 다른 구조를 가지고 있어요.

**Host A**: 구조화된 데이터와 비구조화된 데이터의 차이는요?

**Host B**: 구조화된 데이터는 테이블 형태로 깔끔하게 정리된 거예요. CSV, 데이터베이스처럼요. 반면 비구조화된 데이터는 텍스트, 이미지, 오디오처럼 정해진 형식이 없어요.

**Host A**: 기업 데이터의 80%가 비구조화된 데이터라고 하던데요?

**Host B**: 네, 그래서 비구조화 데이터 처리 기술이 중요한 거예요. 딥러닝이 이 영역에서 혁명을 일으킨 거죠.

---

**[섹션 2: 텍스트와 이미지 데이터 - 3:30]**

**Host A**: 각 모달리티의 특징을 좀 더 자세히 알아볼까요? 텍스트 데이터부터요.

**Host B**: 텍스트는 순차적이고 가변 길이예요. 단어나 문자라는 이산적인 토큰으로 이루어져 있죠. 가장 큰 도전은 모호성이에요. 같은 단어도 문맥에 따라 의미가 달라지거든요.

**Host A**: 예를 들면요?

**Host B**: "bank"가 은행인지 강둑인지는 문맥을 봐야 알죠. 그리고 언어마다 처리 방식도 달라요. 한국어는 형태소 분석이 필요하고요.

**Host A**: 이미지는요?

**Host B**: 이미지는 픽셀들의 그리드예요. 높이 곱하기 너비 곱하기 채널. RGB면 3채널이고요. 1000 곱하기 1000 곱하기 3이면 300만 개의 값이에요!

**Host A**: 차원이 엄청 높네요.

**Host B**: 그래서 CNN이 필요한 거예요. 공간적 구조를 활용해서 효율적으로 처리하죠. 그리고 이미지는 시점 변화, 가림, 조명 같은 도전도 있어요.

---

**[섹션 3: 오디오와 비디오 데이터 - 5:30]**

**Host A**: 오디오 데이터는 어떤 특징이 있어요?

**Host B**: 오디오는 1차원 시간 신호예요. 샘플 레이트가 중요한데, CD 품질이면 44.1kHz, 즉 초당 44,100개의 샘플이에요. 음성 인식에서는 보통 16kHz를 써요.

**Host A**: 오디오를 어떻게 표현해요?

**Host B**: 여러 방법이 있어요. 원시 파형 그대로 쓰거나, 스펙트로그램으로 변환해서 2D 이미지처럼 다루기도 해요. 스펙트로그램은 시간-주파수 표현이에요.

**Host A**: 비디오는요?

**Host B**: 비디오는 이미지의 시퀀스에 시간 차원이 추가된 거예요. 시간 곱하기 높이 곱하기 너비 곱하기 채널. 차원이 정말 높아요!

**Host A**: 그래서 비디오 처리가 어려운 거군요.

**Host B**: 네, 계산 비용이 엄청나요. 프레임 샘플링하거나, 3D CNN, 또는 optical flow를 사용하기도 해요.

---

**[섹션 4: 그래프와 멀티모달 데이터 - 7:30]**

**Host A**: 그래프 데이터는 좀 특별하죠?

**Host B**: 네! 그래프는 노드와 엣지로 구성돼요. 소셜 네트워크, 분자 구조, 지식 그래프 같은 관계형 데이터를 표현해요. 유클리디안 구조가 아니라서 특별한 처리가 필요해요.

**Host A**: GNN, Graph Neural Network가 그래서 나온 거죠?

**Host B**: 정확해요! 노드 특징과 연결 구조를 함께 학습하는 거예요. 크기가 가변적이고 순열 불변성도 있어서 CNN이나 RNN과는 다른 접근이 필요해요.

**Host A**: 멀티모달 데이터는요?

**Host B**: 여러 모달리티를 함께 다루는 거예요. 영화는 비디오와 오디오가 함께 있고, SNS 포스트는 이미지와 텍스트가 같이 있죠. VQA, Visual Question Answering 같은 태스크가 대표적이에요.

**Host A**: 멀티모달 학습의 어려움은 뭐예요?

**Host B**: 모달리티 간 정렬, 서로 다른 표현 방식 통합, 하나가 빠졌을 때의 처리 같은 문제가 있어요. 융합 전략도 중요하고요.

---

**[섹션 5: 전통적 특징 추출 - 텍스트 - 9:00]**

**Host A**: 이제 특징 추출 얘기로 넘어가볼까요? 딥러닝 이전에 어떻게 했어요?

**Host B**: 전통적 방법들도 여전히 유용해요! 텍스트에서는 Bag of Words, BoW가 기본이에요. 문서를 단어 빈도 벡터로 표현하는 거죠.

**Host A**: 단점은요?

**Host B**: 단어 순서를 무시해요. 그리고 모든 단어를 동등하게 취급하죠. TF-IDF가 이걸 개선해요. Term Frequency에 Inverse Document Frequency를 곱해서 흔한 단어의 가중치를 낮춰요.

**Host A**: N-gram은요?

**Host B**: 연속된 N개 단어를 하나로 보는 거예요. Bigram은 "machine learning"처럼 두 단어 쌍을 캡처해요. 지역적 문맥을 어느 정도 반영할 수 있죠.

---

**[섹션 6: 전통적 특징 추출 - 이미지/오디오 - 10:30]**

**Host A**: 이미지 특징 추출은요?

**Host B**: SIFT, SURF, HOG 같은 방법이 있었어요. SIFT는 스케일과 회전에 불변인 키포인트를 찾아요. 128차원 디스크립터를 만들죠.

**Host A**: HOG는 뭐예요?

**Host B**: Histogram of Oriented Gradients. 이미지를 셀로 나누고 각 셀에서 그래디언트 방향 히스토그램을 만들어요. 보행자 검출에 많이 썼어요.

**Host A**: 오디오는요?

**Host B**: FFT로 시간 영역을 주파수 영역으로 변환하고, 스펙트로그램을 만들어요. MFCC가 가장 표준적인데, 사람의 청각 특성을 반영한 Mel 스케일을 사용해요. 보통 13-20개의 계수로 음성을 표현해요.

**Host A**: 딥러닝 시대에도 이런 거 쓰나요?

**Host B**: 네, MFCC는 여전히 많이 써요. 그리고 전통 방법들이 딥러닝의 동작 원리를 이해하는 데 도움이 되기도 해요.

---

**[섹션 7: 딥러닝 기반 표현 학습 - 12:00]**

**Host A**: 딥러닝의 표현 학습은 뭐가 다른 거예요?

**Host B**: 핵심은 자동으로 특징을 학습한다는 거예요. 수동 설계 없이 데이터에서 최적의 표현을 찾아내죠.

**Host A**: 예를 들어볼까요?

**Host B**: Word2Vec 같은 워드 임베딩이요. 단어를 50-300차원의 밀집 벡터로 표현해요. 놀라운 건 "king - man + woman = queen" 같은 벡터 연산이 된다는 거예요!

**Host A**: CNN의 특징 학습은요?

**Host B**: CNN은 계층적으로 학습해요. 초기 레이어는 엣지나 텍스처, 중간은 부분, 상위는 객체 전체를 캡처해요. ImageNet 학습된 특징이 다른 태스크에도 잘 전이되고요.

**Host A**: 오토인코더도 있죠?

**Host B**: 네! 입력을 압축했다가 다시 복원하도록 학습해요. 잠재 공간이 유용한 표현이 되죠. VAE는 여기에 확률적 요소를 더해서 생성 모델로도 쓸 수 있어요.

---

**[섹션 8: 전이 학습과 파인튜닝 - 13:30]**

**Host A**: 전이 학습이 왜 중요해요?

**Host B**: 데이터가 적을 때 특히 중요해요! ImageNet에서 학습된 CNN 특징이 다른 비전 태스크에서도 잘 작동해요. BERT나 GPT의 언어 표현도 마찬가지고요.

**Host A**: 특징 추출과 파인튜닝의 차이는요?

**Host B**: 특징 추출은 사전학습 모델을 동결하고 새 분류기만 학습해요. 빠르고 데이터가 적어도 괜찮아요. 파인튜닝은 사전학습 가중치도 업데이트해요. 성능은 더 좋지만 데이터가 더 필요하죠.

**Host A**: 언제 뭘 써야 해요?

**Host B**: 데이터가 적고 도메인이 비슷하면 특징 추출, 데이터가 많거나 도메인이 다르면 파인튜닝이 좋아요. 점진적으로 레이어를 녹이는 방식도 있어요.

---

**[아웃트로 - 14:30]**

**Host A**: 오늘 많은 내용을 다뤘네요! 정리해볼까요?

**Host B**: 첫째, 각 데이터 모달리티는 고유한 특성이 있어서 적합한 처리 방법이 달라요.

**Host A**: 둘째, 전통적 특징 추출 방법들, TF-IDF, SIFT, MFCC 같은 것들이 여전히 유용하고 이해하면 도움이 돼요.

**Host B**: 셋째, 딥러닝은 자동으로 계층적 특징을 학습해서 수동 설계를 대체했어요.

**Host A**: 마지막으로, 전이 학습과 파인튜닝은 적은 데이터로 좋은 성능을 내는 핵심 전략이에요!

**Host B**: 다음 시간에는 손실 함수와 최적화에 대해 다룰 예정이에요. 많은 관심 부탁드려요!

**Host A**: 감사합니다! 다음 시간에 만나요!

---

## 핵심 키워드
- Data Modality, Structured/Unstructured Data
- Text: Bag of Words, TF-IDF, N-gram, Tokenization
- Image: SIFT, SURF, HOG, Edge Detection
- Audio: FFT, Spectrogram, MFCC, Mel Scale
- Video: 3D CNN, Optical Flow, Frame Sampling
- Graph: GNN, Node, Edge, Non-Euclidean
- Representation Learning, Word2Vec, GloVe
- Transfer Learning, Fine-tuning, Feature Extraction
- Autoencoder, VAE, Multimodal Fusion
