# Lecture 02 Podcast: 데이터 시각화의 예술과 과학

## 에피소드 정보
- **주제**: 시각화 기본 원칙, 차트 유형, ML을 위한 고급 시각화
- **예상 시간**: 15분
- **대상**: 데이터 분석가, ML 엔지니어, 시각화 입문자

---

## 스크립트

**[인트로 - 0:00]**

**Host A**: 안녕하세요! AI 비전 시스템 팟캐스트입니다. 오늘은 데이터 시각화에 대해 깊이 있게 다뤄볼 거예요.

**Host B**: 네! 시각화가 왜 중요한지, Anscombe's Quartet라고 들어보셨어요?

**Host A**: 같은 통계치를 가진 네 개의 데이터셋인데, 실제로 보면 완전히 다른 패턴이라는 거죠?

**Host B**: 맞아요! 평균, 분산, 상관계수가 다 똑같은데, 하나는 선형, 하나는 곡선, 하나는 아웃라이어 포함... 숫자만 보면 절대 알 수 없어요. 그래서 시각화가 필수인 거예요.

---

**[섹션 1: 시각적 인코딩 원칙 - 1:30]**

**Host A**: 시각화의 기본 원칙부터 알아볼까요? Visual Encoding이라고 하죠.

**Host B**: 인간의 시각 인지 능력에 따라 채널별 정확도가 다르거든요. 가장 정확한 건 Position, 위치예요. 그다음이 길이, 각도, 면적, 부피 순이고, 색상이 가장 부정확해요.

**Host A**: 그래서 중요한 데이터는 위치로 인코딩하라는 거군요!

**Host B**: 정확해요. 데이터 타입에 따라서도 다른데요, 수치형 데이터는 위치나 길이, 면적으로. 순서형은 위치나 색상 채도로. 범주형은 색상, 모양, 위치로 표현하면 효과적이에요.

**Host A**: Pre-attentive Processing이라는 개념도 중요하더라고요.

**Host B**: 네, 색상, 크기, 방향 같은 특성은 의식적 노력 없이도 바로 인지돼요. 이걸 활용하면 핵심 정보를 빠르게 전달할 수 있죠.

---

**[섹션 2: 게슈탈트 원리 - 3:30]**

**Host A**: 게슈탈트 원리도 시각화에서 자주 언급되죠.

**Host B**: 심리학에서 온 개념인데, 우리 뇌가 시각 요소를 어떻게 그룹화하는지 설명해요. 첫째, Proximity, 가까이 있는 요소는 그룹으로 인식해요.

**Host A**: Similarity도 있죠? 비슷하게 생긴 건 관련 있다고 느끼는 거.

**Host B**: 맞아요! Continuity는 선이나 곡선 위의 요소들을 연결해서 보는 거고, Closure는 불완전한 도형도 완성해서 인식하는 거예요. 이 원리들을 활용하면 시청자의 주의를 자연스럽게 유도할 수 있어요.

---

**[섹션 3: 색상과 접근성 - 5:00]**

**Host A**: 색상 얘기로 넘어가볼까요? 색맹 접근성이 특히 중요하다고 하던데요.

**Host B**: 남성의 약 8%, 여성의 0.5%가 색맹이에요. 생각보다 많죠! 가장 흔한 실수가 빨강-초록 조합을 쓰는 건데, 절대 피해야 해요.

**Host A**: 어떤 색상 팔레트를 써야 하나요?

**Host B**: Viridis가 색맹 친화적으로 유명해요. ColorBrewer 같은 도구도 좋고요. 그리고 색상에만 의존하지 말고, 패턴이나 레이블로 중복 인코딩하는 게 좋아요.

**Host A**: 팔레트 종류도 데이터에 따라 다르죠?

**Host B**: 네! Sequential은 밝은색에서 어두운색으로, 순서 있는 데이터에. Diverging은 양극단이 있는 데이터에, 중간점을 중심으로 색이 갈라지고요. Categorical은 구분되는 범주에 서로 다른 색을 쓰는 거예요.

---

**[섹션 4: 차트 유형 - 7:00]**

**Host A**: 이제 실제 차트 유형을 알아볼까요? 언제 어떤 차트를 써야 하는지가 항상 고민이에요.

**Host B**: 데이터 타입과 목적에 따라 달라요. 분포를 보려면 히스토그램이나 KDE. 두 변수 관계는 산점도. 범주 비교는 바 차트.

**Host A**: 파이 차트는요?

**Host B**: 솔직히 말하면, 파이 차트는 피하는 게 좋아요! 각도 비교가 부정확해서요. 5-7개 이하 슬라이스만 쓰고, 그마저도 바 차트가 나을 때가 많아요.

**Host A**: Boxplot이랑 Violin Plot 차이는요?

**Host B**: Boxplot은 다섯 숫자 요약, min, Q1, 중앙값, Q3, max를 보여줘요. 간결하죠. Violin Plot은 여기에 KDE를 추가해서 전체 분포 모양을 보여줘요. 다봉 분포를 볼 때 특히 유용해요.

---

**[섹션 5: 시계열과 상관관계 - 9:00]**

**Host A**: 시계열 데이터는 어떻게 시각화하나요?

**Host B**: 라인 그래프가 기본이에요. 시간은 항상 x축에, 왼쪽에서 오른쪽으로. 트렌드, 계절성, 이상치를 한눈에 볼 수 있어요. 중요한 이벤트는 수직선으로 표시하면 좋고요.

**Host A**: Area Chart는요?

**Host B**: 라인 아래를 채운 거예요. 크기감을 강조할 때 좋은데, 여러 시리즈가 겹치면 가려지니까 주의해야 해요. Stacked Area Chart는 전체 대비 부분을 시간에 따라 볼 때 쓰고요.

**Host A**: 상관관계는 Heatmap이 대표적이죠?

**Host B**: 맞아요! 상관계수 매트릭스를 색상으로 인코딩하는 건데, ML에서 피처 선택할 때 필수예요. Diverging 컬러맵을 쓰고 0을 중심에 두는 게 포인트예요. 비슷한 변수끼리 클러스터링하면 패턴이 더 잘 보이고요.

---

**[섹션 6: ML을 위한 시각화 - 10:30]**

**Host A**: 이제 ML에 특화된 시각화를 얘기해볼까요?

**Host B**: EDA부터 시작해요. 전체 개요 확인, 각 피처 분포 확인, 피처 간 관계, 다변량 분석 순서로요. pandas-profiling이나 sweetviz 쓰면 자동으로 리포트가 생성돼요.

**Host A**: 고차원 데이터는요?

**Host B**: PCA, t-SNE, UMAP 같은 차원 축소 기법을 시각화해요. PCA는 선형이고 전역 구조 보존, t-SNE는 비선형이고 지역 구조 집중, UMAP은 둘 다 어느 정도 보존하면서 더 빠르죠.

**Host A**: 모델 학습 중에도 시각화가 중요하죠?

**Host B**: Learning Curve가 핵심이에요! Training loss와 Validation loss를 같이 그리면, 둘 다 높으면 Underfitting, Training만 낮고 Validation이 높으면 Overfitting이에요. 모델 복잡도나 데이터 양을 조절하는 기준이 되죠.

---

**[섹션 7: 모델 평가 시각화 - 12:00]**

**Host A**: Classification 모델 평가는요?

**Host B**: Confusion Matrix가 기본이에요. TP, FP, FN, TN을 히트맵으로 보여주죠. 여기서 Precision, Recall, F1 다 계산할 수 있어요.

**Host A**: ROC 커브랑 PR 커브 차이는요?

**Host B**: ROC는 FPR 대 TPR을 그리는데, 밸런스된 데이터셋에 좋아요. AUC가 1에 가까울수록 좋은 모델이고요. PR 커브는 불균형 데이터에 더 적합해요. 클래스 불균형이 심하면 ROC가 과대평가될 수 있거든요.

**Host A**: 회귀 모델은요?

**Host B**: Residual Plot이 핵심이에요. 잔차가 0 주변에 랜덤하게 흩어져야 좋은 모델이에요. 패턴이 보이면 비선형성이나 이분산성 문제가 있는 거고요. Q-Q Plot으로 정규성도 체크해요.

---

**[섹션 8: 모델 해석과 대시보드 - 13:30]**

**Host A**: 요즘 XAI, 설명 가능한 AI도 중요하잖아요.

**Host B**: SHAP이랑 LIME이 대표적이에요. SHAP은 게임 이론 기반으로, Summary Plot으로 전역적 피처 중요도를, Waterfall Plot으로 개별 예측을 설명해요. LIME은 개별 예측 주변을 perturbation해서 지역적 설명을 만들어요.

**Host A**: Attention 시각화도 있죠?

**Host B**: 트랜스포머 모델에서 Attention 가중치를 히트맵으로 보여주는 건데, 모델이 어디에 "집중"하는지 알 수 있어요. NLP에서 어떤 단어가 중요한지, 비전에서 어떤 영역을 보는지 확인할 수 있죠.

**Host A**: 마지막으로 대시보드 디자인 팁은요?

**Host B**: KPI는 상단에, 정보는 중요도 순으로 배치해요. 일관된 색상과 폰트를 쓰고, 인터랙티브 필터를 추가하면 좋아요. Streamlit이나 Dash 같은 도구로 쉽게 만들 수 있어요. 그리고 데이터 스토리텔링! Setup, Conflict, Resolution 구조로 맥락, 문제, 해결책을 전달하세요.

---

**[아웃트로 - 14:30]**

**Host A**: 오늘 배운 핵심을 정리해볼까요?

**Host B**: 첫째, 시각적 인코딩은 데이터 타입에 맞게! 위치가 가장 정확하고, 색상은 보조적으로 쓰세요.

**Host A**: 둘째, 색맹 접근성을 항상 고려하고, 게슈탈트 원리로 시청자 주의를 유도하세요.

**Host B**: 셋째, 차트 선택은 목적에 따라! 파이 차트보다는 바 차트가 대부분 나아요.

**Host A**: 넷째, ML 워크플로우 전반에서 시각화가 필수예요. EDA부터 모델 평가, 해석까지!

**Host B**: 마지막으로, 시각화는 데이터로 스토리를 전달하는 거예요. 다음 에피소드에서 만나요!

**Host A**: 감사합니다!

---

## 핵심 키워드
- Visual Encoding, Pre-attentive Processing
- Gestalt Principles, Color Accessibility
- Histogram, Scatter Plot, Boxplot, Heatmap
- PCA, t-SNE, UMAP
- Learning Curve, ROC, PR Curve, Confusion Matrix
- SHAP, LIME, Attention Visualization
- Data Storytelling, Dashboard Design
