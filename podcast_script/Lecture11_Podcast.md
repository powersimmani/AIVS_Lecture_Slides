# Lecture 11 Podcast: 시퀀스 모델링 기초

## 에피소드 정보
- **주제**: 시퀀스 데이터, RNN, LSTM, GRU와 시퀀스-투-시퀀스 모델
- **예상 시간**: 15분
- **대상**: ML/DL을 공부하는 학생 및 실무자

---

## 스크립트

**[인트로 - 0:00]**

**Host A**: 안녕하세요! AI 비전 시스템 팟캐스트에 오신 것을 환영합니다. 저는 호스트 A이고요.

**Host B**: 안녕하세요, 호스트 B입니다! 오늘은 시퀀스 모델링에 대해 깊이 있게 다뤄볼 건데요, 사실 우리 일상에서 마주하는 데이터 대부분이 시퀀스 데이터라는 거 알고 계셨나요?

**Host A**: 맞아요. 텍스트, 음성, 주가, 센서 데이터... 시간이나 순서가 중요한 데이터는 전부 시퀀스 데이터죠. 이번 강의에서는 이런 데이터를 어떻게 모델링하는지 배워볼 거예요.

---

**[섹션 1: 시퀀스 데이터란? - 1:00]**

**Host B**: 자, 그럼 시퀀스 데이터가 정확히 뭔지부터 시작해볼까요?

**Host A**: 시퀀스 데이터는 순서가 의미를 가지는 데이터예요. "Dog bites man"이랑 "Man bites dog"은 같은 단어지만 순서가 다르면 의미가 완전히 달라지잖아요.

**Host B**: 그렇죠! 시퀀스 데이터의 핵심 특징들을 정리해보면, 첫째 시간적 상관관계가 있어요. 인접한 요소들이 서로 관련되어 있죠.

**Host A**: 둘째, 길이가 가변적이에요. 문장마다 단어 수가 다르고, 동영상마다 프레임 수가 다르잖아요. 셋째, 문맥 의존성이 있어요. 같은 단어라도 문맥에 따라 의미가 달라지고요.

**Host B**: 근데 전통적인 머신러닝은 이런 시퀀스 데이터를 다루기 어려워요. 왜 그럴까요?

**Host A**: 고정된 입력 크기를 요구하고, 내장된 메모리가 없고, 시간적 패턴을 포착할 수 없기 때문이에요. 그래서 특별한 접근법이 필요한 거죠.

---

**[섹션 2: 시퀀스 데이터의 종류 - 3:00]**

**Host B**: 시퀀스 데이터에도 여러 종류가 있는데요, 하나씩 살펴볼까요?

**Host A**: 먼저 시계열 데이터가 있어요. 주가, 센서 측정값, 날씨 데이터 같은 것들이요. 숫자 값이 시간에 따라 기록되는 거죠. 트렌드, 계절성, 노이즈로 구성돼요.

**Host B**: 텍스트 데이터는 이산적인 토큰의 시퀀스예요. 단어나 문자 단위로 처리하고, 풍부한 의미적 내용을 담고 있죠. 토큰화, 임베딩 같은 전처리가 필요해요.

**Host A**: 음성 데이터는 1차원 파형 신호예요. 샘플링 레이트가 16kHz에서 44kHz 정도로 꽤 높고, 스펙트로그램이나 MFCC 같은 표현으로 변환해서 사용해요.

**Host B**: 비디오 데이터는 이미지 프레임의 시퀀스고요, 생물학적 시퀀스인 DNA, RNA, 단백질 데이터도 시퀀스 모델링 대상이에요. 각각의 데이터 타입에 맞는 전처리 방법이 있어요.

---

**[섹션 3: 전통적 통계 방법 - 5:00]**

**Host A**: 딥러닝 이전에는 어떤 방법들을 썼나요?

**Host B**: 가장 기본적인 게 이동 평균, MA 모델이에요. 과거 오차들의 가중합으로 예측하는 거죠. MA(q)에서 q는 몇 개의 과거 오차를 볼지를 나타내요.

**Host A**: 자기회귀 모델, AR도 있죠. 이건 과거 값들을 기반으로 예측해요. "어제 주가가 올랐으니까 오늘도 오를 거다" 같은 관성을 모델링하는 거예요.

**Host B**: ARIMA는 AR과 MA를 합친 거예요. p, d, q 세 개의 파라미터로 구성되는데, d는 차분 횟수를 나타내서 비정상 시계열도 다룰 수 있어요.

**Host A**: 하지만 이런 전통적 방법들은 선형성을 가정하고, 정상성을 요구하고, 고차원 데이터를 다루기 어렵다는 한계가 있어요.

**Host B**: 맞아요. 이미지나 텍스트 같은 복잡한 시퀀스는 딥러닝이 필요한 이유죠.

---

**[섹션 4: RNN의 등장 - 7:00]**

**Host A**: 자, 이제 딥러닝 이야기로 넘어가볼까요? RNN, Recurrent Neural Network가 시퀀스 모델링의 시작이에요.

**Host B**: RNN의 핵심 아이디어는 "숨겨진 상태"가 시간을 통해 정보를 전달한다는 거예요. 수식으로 보면 h_t = tanh(W_hh * h_{t-1} + W_xh * x_t + b)예요.

**Host A**: 풀어서 설명하면, 현재 시점의 숨겨진 상태는 이전 숨겨진 상태와 현재 입력의 조합으로 만들어진다는 거죠.

**Host B**: RNN의 장점은 가변 길이 시퀀스를 처리할 수 있고, 과거 정보를 기억할 수 있고, 시간에 걸쳐 파라미터를 공유한다는 거예요.

**Host A**: 하지만 치명적인 문제가 있어요. 바로 기울기 소실과 폭발 문제죠.

**Host B**: 맞아요! 역전파할 때 기울기가 여러 시간 단계를 거치면서 점점 작아지거나 커지는 거예요. 그래서 긴 시퀀스에서 장기 의존성을 학습하기 어려워요.

---

**[섹션 5: LSTM과 GRU - 9:00]**

**Host A**: LSTM이 이 문제를 어떻게 해결했나요?

**Host B**: LSTM은 "셀 상태"라는 고속도로를 만들고, 게이트로 정보 흐름을 제어해요. 세 가지 게이트가 있는데요, 먼저 망각 게이트는 "뭘 버릴까?"를 결정해요.

**Host A**: 입력 게이트는 "뭘 저장할까?"를 결정하고, 출력 게이트는 "뭘 출력할까?"를 결정하죠.

**Host B**: 셀 상태 업데이트 공식은 C_t = f_t * C_{t-1} + i_t * C~_t예요. 이전 셀 상태에서 일부를 잊고, 새로운 정보 일부를 더하는 거죠.

**Host A**: GRU는 LSTM을 단순화한 버전이에요. 게이트가 두 개밖에 없어요. 리셋 게이트와 업데이트 게이트죠.

**Host B**: GRU는 파라미터가 적어서 학습이 빠르고, 성능은 LSTM과 비슷해요. 셀 상태가 따로 없고 숨겨진 상태만 있어요.

**Host A**: 실무에서는 둘 다 써보고 데이터에 맞는 걸 고르는 게 좋아요. 일반적으로 GRU가 작은 데이터셋에서, LSTM이 복잡한 시퀀스에서 좀 더 낫다고 해요.

---

**[섹션 6: 양방향 RNN - 10:30]**

**Host B**: 양방향 RNN은 왜 필요한가요?

**Host A**: 일반 RNN은 왼쪽에서 오른쪽으로만 처리하잖아요. 근데 "I saw a bat"에서 bat이 동물인지 야구 방망이인지는 뒤에 오는 단어를 봐야 알 수 있어요.

**Host B**: 그래서 양방향 RNN은 순방향과 역방향 두 개의 RNN을 사용해요. 각 위치에서 두 방향의 숨겨진 상태를 연결해서 사용하죠.

**Host A**: 물론 한계도 있어요. 실시간 스트리밍 처리는 불가능해요. 전체 시퀀스가 있어야 하니까요. 그리고 파라미터와 연산량이 두 배예요.

**Host B**: 그래도 개체명 인식이나 감성 분석 같은 태스크에서는 양방향 RNN이 표준이에요.

---

**[섹션 7: 시퀀스-투-시퀀스 모델 - 11:30]**

**Host A**: 이제 Seq2Seq 모델 이야기를 해볼까요? 번역처럼 입력과 출력 길이가 다른 경우에 필요하죠.

**Host B**: Seq2Seq는 인코더-디코더 구조예요. 인코더는 입력을 읽어서 컨텍스트 벡터로 압축하고, 디코더는 그걸 바탕으로 출력을 생성해요.

**Host A**: 인코더는 입력 시퀀스를 처리해서 마지막 숨겨진 상태를 컨텍스트로 사용하고, 디코더는 그 컨텍스트에서 시작해서 한 토큰씩 출력을 생성해요.

**Host B**: 근데 여기서 문제가 있어요. 컨텍스트 벡터가 고정 크기라서 긴 시퀀스의 모든 정보를 담기 어려워요. 이걸 "정보 병목 현상"이라고 해요.

**Host A**: 이 문제는 다음 강의에서 배울 어텐션 메커니즘으로 해결돼요!

---

**[섹션 8: 학습 기법들 - 12:30]**

**Host B**: Seq2Seq 학습할 때 Teacher Forcing이라는 기법을 사용하는데요, 이게 뭔가요?

**Host A**: 학습할 때 디코더 입력으로 자기 예측 대신 정답을 넣어주는 거예요. 선생님이 정답을 알려주듯이요. 학습이 빠르고 안정적이에요.

**Host B**: 근데 문제가 있어요. 학습 때는 항상 정답을 보는데 추론 때는 자기 예측을 써야 하니까 분포 불일치가 생겨요. 이걸 노출 편향이라고 해요.

**Host A**: 해결책으로 Scheduled Sampling이 있어요. 학습 초반에는 Teacher Forcing을 많이 쓰다가 점점 줄여나가는 거죠.

**Host B**: 추론할 때는 Beam Search를 많이 써요. 그리디하게 한 토큰씩 선택하는 대신, 여러 후보를 유지하면서 최적 시퀀스를 찾는 거예요.

---

**[섹션 9: CTC Loss와 실용적 팁 - 13:30]**

**Host A**: CTC Loss는 뭔가요?

**Host B**: Connectionist Temporal Classification의 약자인데요, 입력과 출력 사이의 정렬을 모를 때 사용해요. 음성 인식이나 OCR에서 많이 쓰여요.

**Host A**: 예를 들어 "hello"를 "--hh-e-ll-oo--"처럼 여러 방식으로 정렬할 수 있는데, CTC는 가능한 모든 정렬의 확률을 합해서 학습해요.

**Host B**: 실용적인 팁들도 정리해볼까요? 먼저 가변 길이 처리를 위해 패딩과 마스킹이 필수예요.

**Host A**: 기울기 클리핑으로 폭발을 방지하고요. PyTorch에서는 clip_grad_norm_ 함수를 쓰면 돼요. RNN은 학습률을 좀 낮게 시작하는 게 좋아요.

**Host B**: 순환 가중치는 직교 초기화를, 레이어 정규화로 학습을 안정화시키고, 드롭아웃은 시간 단계 사이가 아니라 레이어 사이에 적용하세요.

---

**[아웃트로 - 14:30]**

**Host A**: 오늘 정말 많은 내용을 다뤘네요! 정리하자면요?

**Host B**: 첫째, 시퀀스 데이터는 순서가 중요한 데이터고, 전통적 방법으로는 한계가 있어서 딥러닝이 필요해요.

**Host A**: 둘째, RNN은 숨겨진 상태로 정보를 전달하지만 기울기 소실 문제가 있고, LSTM과 GRU가 게이트 메커니즘으로 이를 해결해요.

**Host B**: 셋째, Seq2Seq는 인코더-디코더 구조로 가변 길이 입출력을 처리하는데, 컨텍스트 벡터 병목 문제가 있어요.

**Host A**: 다음 강의에서는 이 병목 문제를 해결하는 어텐션 메커니즘을 배울 거예요. 정말 기대되네요!

**Host B**: 감사합니다! 다음 시간에 만나요!

---

## 핵심 키워드
- Sequence Data, Time Series, Text Data, Audio Data
- RNN (Recurrent Neural Network), Vanishing Gradient
- LSTM (Long Short-Term Memory), Forget Gate, Input Gate, Output Gate
- GRU (Gated Recurrent Unit), Reset Gate, Update Gate
- Bidirectional RNN, Seq2Seq, Encoder-Decoder
- Teacher Forcing, Exposure Bias, Scheduled Sampling
- Beam Search, CTC Loss, Gradient Clipping
