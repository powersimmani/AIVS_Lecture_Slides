{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ SHAP and XAI: Comprehensive Hands-on Tutorial\n",
        "\n",
        "## Model Explainability - From Theory to Practice\n",
        "\n",
        "**Based on Lecture 20: Model Explainability - SHAP and Deep Learning XAI**\n",
        "\n",
        "---\n",
        "\n",
        "### üìö Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "\n",
        "1. ‚úÖ Understand Shapley values from game theory and their application to ML\n",
        "2. ‚úÖ Implement different SHAP explainers (Tree, Kernel, Deep, Gradient)\n",
        "3. ‚úÖ Create and interpret various SHAP visualizations\n",
        "4. ‚úÖ Apply SHAP to real-world problems (credit, healthcare, images)\n",
        "5. ‚úÖ Use advanced XAI techniques (Attention, Grad-CAM, Integrated Gradients)\n",
        "\n",
        "**Duration**: ~2-3 hours  \n",
        "**Level**: Intermediate  \n",
        "**Prerequisites**: Basic ML knowledge, scikit-learn experience\n",
        "\n",
        "**Instructor**: Ho-min Park (homin.park@ghent.ac.kr)\n",
        "\n",
        "---\n",
        "\n",
        "### üìñ Tutorial Structure\n",
        "\n",
        "| Part | Topic | Exercises | Time |\n",
        "|------|-------|-----------|------|\n",
        "| **0** | Setup & Environment | - | 5 min |\n",
        "| **1** | SHAP Fundamentals | 4 exercises | 30 min |\n",
        "| **2** | SHAP Implementation Methods | 5 exercises | 45 min |\n",
        "| **3** | SHAP Visualizations | 4 exercises | 30 min |\n",
        "| **4** | Advanced XAI Techniques | 3 exercises | 40 min |\n",
        "| **5** | Real-world Application | 1 project | 20 min |\n",
        "\n",
        "---\n",
        "\n",
        "### üí° Tips for Learning\n",
        "\n",
        "- üîÑ Run each cell sequentially\n",
        "- ‚úèÔ∏è Complete \"Your Turn\" exercises\n",
        "- ü§î Read interpretation guides carefully\n",
        "- üí¨ Ask questions when stuck\n",
        "- üé® Experiment with visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üì¶ Part 0: Setup & Environment\n",
        "\n",
        "Let's prepare our workspace by installing necessary libraries and loading datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Installation (uncomment if needed)\n",
        "# !pip install shap scikit-learn xgboost matplotlib seaborn pandas numpy plotly\n",
        "\n",
        "print('‚úÖ Installation ready!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import core libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# SHAP\n",
        "import shap\n",
        "\n",
        "# Advanced visualization\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "# Styling\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Constants\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print(f'‚úÖ Libraries imported successfully!')\n",
        "print(f'üìä SHAP version: {shap.__version__}')\n",
        "print(f'üêç NumPy version: {np.__version__}')\n",
        "print(f'üêº Pandas version: {pd.__version__}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load and prepare datasets\n",
        "print('=' * 60)\n",
        "print('üìÅ LOADING DATASETS')\n",
        "print('=' * 60)\n",
        "\n",
        "# 1. Iris Dataset (Classification)\n",
        "iris = load_iris(as_frame=True)\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_df['target'] = iris.target\n",
        "iris_df['species'] = iris_df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
        "\n",
        "print(f'\\n1Ô∏è‚É£  Iris Dataset: {iris_df.shape}')\n",
        "print(f'   Features: {list(iris.feature_names)}')\n",
        "print(f'   Classes: {iris.target_names}')\n",
        "\n",
        "# 2. Breast Cancer Dataset (Binary Classification)\n",
        "cancer = load_breast_cancer(as_frame=True)\n",
        "cancer_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "cancer_df['target'] = cancer.target\n",
        "cancer_df['diagnosis'] = cancer_df['target'].map({0: 'malignant', 1: 'benign'})\n",
        "\n",
        "print(f'\\n2Ô∏è‚É£  Breast Cancer Dataset: {cancer_df.shape}')\n",
        "print(f'   Features: {len(cancer.feature_names)} features')\n",
        "print(f'   Classes: Malignant ({(cancer_df.target==0).sum()}), Benign ({(cancer_df.target==1).sum()})')\n",
        "\n",
        "# 3. Wine Dataset (Multi-class)\n",
        "wine = load_wine(as_frame=True)\n",
        "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "wine_df['target'] = wine.target\n",
        "\n",
        "print(f'\\n3Ô∏è‚É£  Wine Dataset: {wine_df.shape}')\n",
        "print(f'   Features: {len(wine.feature_names)} features')\n",
        "print(f'   Classes: {len(wine.target_names)} wine types')\n",
        "\n",
        "# 4. Synthetic Credit Approval Dataset\n",
        "n = 1000\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "credit_df = pd.DataFrame({\n",
        "    'Age': np.random.randint(22, 70, n),\n",
        "    'Income': np.random.randint(20000, 150000, n),\n",
        "    'Credit_Score': np.random.randint(300, 850, n),\n",
        "    'Debt_Ratio': np.random.uniform(0, 0.6, n),\n",
        "    'Employment_Years': np.random.randint(0, 40, n),\n",
        "    'Previous_Defaults': np.random.binomial(3, 0.1, n),\n",
        "    'Loan_Amount': np.random.randint(5000, 50000, n)\n",
        "})\n",
        "\n",
        "# Create approval target based on realistic criteria\n",
        "score = (\n",
        "    (credit_df['Income'] / 50000) * 0.25 +\n",
        "    (credit_df['Credit_Score'] / 850) * 0.35 +\n",
        "    (1 - credit_df['Debt_Ratio']) * 0.20 +\n",
        "    (credit_df['Employment_Years'] / 40) * 0.10 +\n",
        "    (1 - credit_df['Previous_Defaults'] / 3) * 0.10\n",
        ")\n",
        "credit_df['Approved'] = (score + np.random.normal(0, 0.15, n) > 0.5).astype(int)\n",
        "\n",
        "print(f'\\n4Ô∏è‚É£  Credit Approval Dataset: {credit_df.shape}')\n",
        "print(f'   Approval Rate: {credit_df[\"Approved\"].mean():.1%}')\n",
        "print(f'   Features: {list(credit_df.columns[:-1])}')\n",
        "\n",
        "# 5. Synthetic Housing Price Dataset (Regression)\n",
        "n_houses = 500\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "housing_df = pd.DataFrame({\n",
        "    'Square_Feet': np.random.randint(800, 4000, n_houses),\n",
        "    'Bedrooms': np.random.randint(1, 6, n_houses),\n",
        "    'Bathrooms': np.random.randint(1, 4, n_houses),\n",
        "    'Age': np.random.randint(0, 50, n_houses),\n",
        "    'Distance_to_City': np.random.uniform(1, 30, n_houses),\n",
        "    'School_Rating': np.random.randint(1, 11, n_houses)\n",
        "})\n",
        "\n",
        "# Price formula with non-linear relationships\n",
        "base_price = 100000\n",
        "housing_df['Price'] = (\n",
        "    base_price +\n",
        "    housing_df['Square_Feet'] * 150 +\n",
        "    housing_df['Bedrooms'] * 20000 +\n",
        "    housing_df['Bathrooms'] * 15000 -\n",
        "    housing_df['Age'] * 2000 -\n",
        "    housing_df['Distance_to_City'] * 3000 +\n",
        "    housing_df['School_Rating'] * 10000 +\n",
        "    np.random.normal(0, 20000, n_houses)\n",
        ")\n",
        "\n",
        "print(f'\\n5Ô∏è‚É£  Housing Price Dataset: {housing_df.shape}')\n",
        "print(f'   Price Range: ${housing_df[\"Price\"].min():,.0f} - ${housing_df[\"Price\"].max():,.0f}')\n",
        "print(f'   Mean Price: ${housing_df[\"Price\"].mean():,.0f}')\n",
        "\n",
        "print('\\n' + '=' * 60)\n",
        "print('‚úÖ All datasets loaded successfully!')\n",
        "print('=' * 60)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize datasets\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('üìä Dataset Overview', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "# 1. Iris\n",
        "iris_df.groupby('species').size().plot(kind='bar', ax=axes[0, 0], color='skyblue', edgecolor='black')\n",
        "axes[0, 0].set_title('Iris: Class Distribution', fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Species')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 2. Cancer\n",
        "cancer_df.groupby('diagnosis').size().plot(kind='bar', ax=axes[0, 1], color=['salmon', 'lightgreen'], edgecolor='black')\n",
        "axes[0, 1].set_title('Breast Cancer: Diagnosis Distribution', fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Diagnosis')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 3. Credit\n",
        "credit_df['Approved'].value_counts().plot(kind='pie', ax=axes[0, 2], autopct='%1.1f%%', \n",
        "                                          labels=['Rejected', 'Approved'], colors=['lightcoral', 'lightblue'])\n",
        "axes[0, 2].set_title('Credit: Approval Rate', fontweight='bold')\n",
        "axes[0, 2].set_ylabel('')\n",
        "\n",
        "# 4. Credit Score Distribution\n",
        "axes[1, 0].hist(credit_df['Credit_Score'], bins=30, color='purple', alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_title('Credit: Score Distribution', fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Credit Score')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "\n",
        "# 5. Housing Price Distribution\n",
        "axes[1, 1].hist(housing_df['Price']/1000, bins=30, color='orange', alpha=0.7, edgecolor='black')\n",
        "axes[1, 1].set_title('Housing: Price Distribution', fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Price ($1000s)')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "\n",
        "# 6. Housing: Price vs Square Feet\n",
        "scatter = axes[1, 2].scatter(housing_df['Square_Feet'], housing_df['Price']/1000, \n",
        "                             c=housing_df['School_Rating'], cmap='viridis', alpha=0.6, s=30)\n",
        "axes[1, 2].set_title('Housing: Price vs Size', fontweight='bold')\n",
        "axes[1, 2].set_xlabel('Square Feet')\n",
        "axes[1, 2].set_ylabel('Price ($1000s)')\n",
        "plt.colorbar(scatter, ax=axes[1, 2], label='School Rating')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüìà Dataset visualizations completed!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üìä Part 1: SHAP Fundamentals\n",
        "\n",
        "## Understanding Shapley Values from Game Theory\n",
        "\n",
        "SHAP (SHapley Additive exPlanations) is based on **cooperative game theory**, specifically Shapley values introduced by Lloyd Shapley in 1953.\n",
        "\n",
        "### üéÆ The Core Idea\n",
        "\n",
        "Imagine a team wins a game. **How do we fairly distribute credit among players?**\n",
        "\n",
        "Shapley values answer this by considering:\n",
        "- Each player's **marginal contribution** in all possible team combinations\n",
        "- Fair distribution that satisfies key properties\n",
        "\n",
        "### üßÆ Mathematical Foundation\n",
        "\n",
        "The prediction can be decomposed as:\n",
        "\n",
        "```\n",
        "f(x) = œÜ‚ÇÄ + œÜ‚ÇÅ + œÜ‚ÇÇ + ... + œÜ‚Çô\n",
        "```\n",
        "\n",
        "Where:\n",
        "- `f(x)` = Model prediction for instance x\n",
        "- `œÜ‚ÇÄ` = Base value (expected prediction, usually mean)\n",
        "- `œÜ·µ¢` = SHAP value for feature i (contribution to prediction)\n",
        "\n",
        "### üìê Shapley Value Formula\n",
        "\n",
        "For feature i:\n",
        "\n",
        "```\n",
        "œÜ·µ¢ = Œ£ [|S|! √ó (n-|S|-1)! / n!] √ó [f(S ‚à™ {i}) - f(S)]\n",
        "```\n",
        "\n",
        "Where:\n",
        "- S = subset of features (coalition)\n",
        "- n = total number of features\n",
        "- The sum is over all possible subsets S not containing i\n",
        "\n",
        "### ‚ú® Key Properties\n",
        "\n",
        "1. **Local Accuracy**: Sum of SHAP values equals prediction - base value\n",
        "2. **Missingness**: Features not in the model have zero contribution\n",
        "3. **Consistency**: If a feature's contribution increases, its SHAP value doesn't decrease\n",
        "4. **Efficiency**: Sum of all contributions equals total \"game value\"\n",
        "5. **Symmetry**: Features with identical contributions get equal SHAP values\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1: Manual Shapley Value Calculation\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "Let's manually calculate Shapley values for a **house price prediction** with only 2 features:\n",
        "- üè† **Square Feet**\n",
        "- üìç **Location Score**\n",
        "\n",
        "We'll explore all possible feature coalitions to understand the marginal contribution of each feature.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# House price predictions for different feature combinations\n",
        "predictions = {\n",
        "    'Empty (baseline)': 250,           # No features ‚Üí base prediction\n",
        "    'Square_Feet only': 300,            # +50K from adding square feet\n",
        "    'Location only': 280,               # +30K from adding location\n",
        "    'Square_Feet + Location': 340      # Both features together\n",
        "}\n",
        "\n",
        "print('üè† HOUSE PRICE PREDICTIONS')\n",
        "print('=' * 50)\n",
        "for coalition, price in predictions.items():\n",
        "    print(f'{coalition:25} ‚Üí ${price}K')\n",
        "print('=' * 50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate Shapley value for Square Feet\n",
        "print('\\nüìä SHAPLEY VALUE CALCULATION: SQUARE FEET')\n",
        "print('=' * 60)\n",
        "\n",
        "# Path 1: Add Square_Feet to empty set\n",
        "contribution_1 = predictions['Square_Feet only'] - predictions['Empty (baseline)']\n",
        "print(f'\\nPath 1: Empty ‚Üí Square_Feet')\n",
        "print(f'  Contribution: ${predictions[\"Square_Feet only\"]}K - ${predictions[\"Empty (baseline)\"]}K = ${contribution_1}K')\n",
        "\n",
        "# Path 2: Add Square_Feet to {Location}\n",
        "contribution_2 = predictions['Square_Feet + Location'] - predictions['Location only']\n",
        "print(f'\\nPath 2: Location ‚Üí Square_Feet + Location')\n",
        "print(f'  Contribution: ${predictions[\"Square_Feet + Location\"]}K - ${predictions[\"Location only\"]}K = ${contribution_2}K')\n",
        "\n",
        "# Shapley value (average of all paths)\n",
        "shap_sqft = (contribution_1 + contribution_2) / 2\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print(f'‚ú® Shapley Value (Square Feet) = (${contribution_1}K + ${contribution_2}K) / 2')\n",
        "print(f'‚ú® Shapley Value (Square Feet) = ${shap_sqft}K')\n",
        "print(f'{\"=\"*60}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate Shapley value for Location\n",
        "print('\\nüìä SHAPLEY VALUE CALCULATION: LOCATION')\n",
        "print('=' * 60)\n",
        "\n",
        "# Path 1: Add Location to empty set\n",
        "contribution_1_loc = predictions['Location only'] - predictions['Empty (baseline)']\n",
        "print(f'\\nPath 1: Empty ‚Üí Location')\n",
        "print(f'  Contribution: ${predictions[\"Location only\"]}K - ${predictions[\"Empty (baseline)\"]}K = ${contribution_1_loc}K')\n",
        "\n",
        "# Path 2: Add Location to {Square_Feet}\n",
        "contribution_2_loc = predictions['Square_Feet + Location'] - predictions['Square_Feet only']\n",
        "print(f'\\nPath 2: Square_Feet ‚Üí Square_Feet + Location')\n",
        "print(f'  Contribution: ${predictions[\"Square_Feet + Location\"]}K - ${predictions[\"Square_Feet only\"]}K = ${contribution_2_loc}K')\n",
        "\n",
        "# Shapley value (average of all paths)\n",
        "shap_location = (contribution_1_loc + contribution_2_loc) / 2\n",
        "print(f'\\n{\"=\"*60}')\n",
        "print(f'‚ú® Shapley Value (Location) = (${contribution_1_loc}K + ${contribution_2_loc}K) / 2')\n",
        "print(f'‚ú® Shapley Value (Location) = ${shap_location}K')\n",
        "print(f'{\"=\"*60}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify additive property\n",
        "print('\\nüîç VERIFICATION: Additive Property')\n",
        "print('=' * 60)\n",
        "\n",
        "base_value = predictions['Empty (baseline)']\n",
        "final_prediction = predictions['Square_Feet + Location']\n",
        "\n",
        "print(f'Base Value: ${base_value}K')\n",
        "print(f'+ Square Feet contribution: ${shap_sqft}K')\n",
        "print(f'+ Location contribution: ${shap_location}K')\n",
        "print(f'{\"-\"*60}')\n",
        "\n",
        "calculated_prediction = base_value + shap_sqft + shap_location\n",
        "print(f'Calculated: ${calculated_prediction}K')\n",
        "print(f'Actual: ${final_prediction}K')\n",
        "\n",
        "if abs(calculated_prediction - final_prediction) < 0.01:\n",
        "    print('\\n‚úÖ VERIFIED! Shapley values satisfy the additive property.')\n",
        "else:\n",
        "    print('\\n‚ùå Error in calculation!')\n",
        "\n",
        "print('=' * 60)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize SHAP decomposition\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left plot: Waterfall visualization\n",
        "features = ['Base', 'Square\\nFeet', 'Location', 'Final\\nPrediction']\n",
        "values = [base_value, shap_sqft, shap_location, final_prediction]\n",
        "colors = ['lightblue', 'green', 'green', 'darkblue']\n",
        "\n",
        "bars = ax1.bar(features, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
        "for i, (feat, val) in enumerate(zip(features, values)):\n",
        "    ax1.text(i, val + 5, f'${val:.0f}K', ha='center', va='bottom', \n",
        "             fontweight='bold', fontsize=11)\n",
        "\n",
        "ax1.set_ylabel('Value ($K)', fontweight='bold', fontsize=12)\n",
        "ax1.set_title('üéØ SHAP Value Decomposition', fontweight='bold', fontsize=14)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "ax1.set_ylim(0, max(values) * 1.15)\n",
        "\n",
        "# Right plot: Contribution breakdown\n",
        "contributions = [shap_sqft, shap_location]\n",
        "feature_names = ['Square Feet', 'Location']\n",
        "colors_pie = ['#2ecc71', '#3498db']\n",
        "\n",
        "wedges, texts, autotexts = ax2.pie(contributions, labels=feature_names, autopct='%1.1f%%',\n",
        "                                     colors=colors_pie, startangle=90, textprops={'fontsize': 11})\n",
        "for autotext in autotexts:\n",
        "    autotext.set_color('white')\n",
        "    autotext.set_fontweight('bold')\n",
        "\n",
        "ax2.set_title('ü•ß Feature Contribution Breakdown', fontweight='bold', fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation:')\n",
        "print(f'  ‚Ä¢ Square Feet contributes ${shap_sqft}K ({shap_sqft/final_prediction*100:.1f}% of prediction)')\n",
        "print(f'  ‚Ä¢ Location contributes ${shap_location}K ({shap_location/final_prediction*100:.1f}% of prediction)')\n",
        "print(f'  ‚Ä¢ Base prediction (no info) is ${base_value}K')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 1a\n",
        "\n",
        "**Task**: Calculate Shapley values for a scenario with 3 features!\n",
        "\n",
        "Given predictions:\n",
        "```\n",
        "Empty: $200K\n",
        "A only: $250K\n",
        "B only: $230K\n",
        "C only: $240K\n",
        "A+B: $290K\n",
        "A+C: $300K\n",
        "B+C: $280K\n",
        "A+B+C: $340K\n",
        "```\n",
        "\n",
        "**Questions**:\n",
        "1. Calculate the Shapley value for feature A\n",
        "2. Verify the additive property\n",
        "3. Which feature is most important?\n",
        "\n",
        "**Hint**: For 3 features, each feature appears in 4 different coalitions (size 0, 1, 2, and 3).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Calculate Shapley values for 3-feature scenario\n",
        "\n",
        "predictions_3feat = {\n",
        "    'empty': 200,\n",
        "    'A': 250,\n",
        "    'B': 230,\n",
        "    'C': 240,\n",
        "    'AB': 290,\n",
        "    'AC': 300,\n",
        "    'BC': 280,\n",
        "    'ABC': 340\n",
        "}\n",
        "\n",
        "# Step 1: List all coalitions that DON'T contain A\n",
        "# Step 2: For each coalition, calculate A's marginal contribution\n",
        "# Step 3: Weight by coalition size probability\n",
        "# Step 4: Sum all weighted contributions\n",
        "\n",
        "# Example for Feature A:\n",
        "# Coalitions without A: {}, {B}, {C}, {B,C}\n",
        "\n",
        "print('Feature A Shapley Calculation:')\n",
        "print('Coalition | Contribution | Weight')\n",
        "print('-' * 40)\n",
        "\n",
        "# Your calculation here...\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 2: SHAP vs LIME Comparison\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**LIME** (Local Interpretable Model-agnostic Explanations) and **SHAP** are both model-agnostic explanation methods, but they differ fundamentally:\n",
        "\n",
        "| Aspect | LIME | SHAP |\n",
        "|--------|------|------|\n",
        "| **Foundation** | Local linear approximation | Game theory (Shapley values) |\n",
        "| **Sampling** | Perturbs instance randomly | Considers all coalitions |\n",
        "| **Properties** | No theoretical guarantees | Satisfies axioms (efficiency, symmetry, etc.) |\n",
        "| **Consistency** | May give different results | Consistent across runs |\n",
        "| **Speed** | Faster | Slower (but optimized) |\n",
        "| **Additivity** | Not guaranteed | Always additive |\n",
        "\n",
        "Let's compare them empirically!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train a model on credit data\n",
        "print('üéì Training Credit Approval Model...')\n",
        "print('=' * 60)\n",
        "\n",
        "X_credit = credit_df.drop(['Approved'], axis=1)\n",
        "y_credit = credit_df['Approved']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_credit, y_credit, test_size=0.2, random_state=RANDOM_STATE, stratify=y_credit\n",
        ")\n",
        "\n",
        "# Train Random Forest\n",
        "rf_credit = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE)\n",
        "rf_credit.fit(X_train, y_train)\n",
        "\n",
        "train_acc = accuracy_score(y_train, rf_credit.predict(X_train))\n",
        "test_acc = accuracy_score(y_test, rf_credit.predict(X_test))\n",
        "\n",
        "print(f'‚úÖ Model trained successfully!')\n",
        "print(f'   Training Accuracy: {train_acc:.3f}')\n",
        "print(f'   Test Accuracy: {test_acc:.3f}')\n",
        "print('=' * 60)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# SHAP Explanation\n",
        "print('\\nüîç Generating SHAP Explanations...')\n",
        "print('=' * 60)\n",
        "\n",
        "# Create Tree Explainer\n",
        "explainer_shap = shap.TreeExplainer(rf_credit)\n",
        "\n",
        "# Select a test instance\n",
        "instance_idx = 42\n",
        "instance = X_test.iloc[instance_idx:instance_idx+1]\n",
        "\n",
        "# Calculate SHAP values\n",
        "shap_values = explainer_shap.shap_values(instance)\n",
        "\n",
        "# For binary classification, take positive class\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values_pos = shap_values[1]\n",
        "else:\n",
        "    shap_values_pos = shap_values\n",
        "\n",
        "print(f'‚úÖ SHAP values calculated')\n",
        "print(f'   Instance index: {instance_idx}')\n",
        "print(f'   Prediction: {\"Approved\" if rf_credit.predict(instance)[0] == 1 else \"Rejected\"}')\n",
        "print(f'   Prediction probability: {rf_credit.predict_proba(instance)[0][1]:.3f}')\n",
        "print('=' * 60)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LIME Explanation\n",
        "print('\\nüîç Generating LIME Explanations...')\n",
        "print('=' * 60)\n",
        "\n",
        "try:\n",
        "    from lime import lime_tabular\n",
        "    \n",
        "    # Create LIME explainer\n",
        "    explainer_lime = lime_tabular.LimeTabularExplainer(\n",
        "        X_train.values,\n",
        "        feature_names=X_train.columns.tolist(),\n",
        "        class_names=['Rejected', 'Approved'],\n",
        "        mode='classification',\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    \n",
        "    # Explain the same instance\n",
        "    lime_exp = explainer_lime.explain_instance(\n",
        "        instance.values[0],\n",
        "        rf_credit.predict_proba,\n",
        "        num_features=len(X_train.columns)\n",
        "    )\n",
        "    \n",
        "    # Extract LIME weights\n",
        "    lime_values = dict(lime_exp.as_list())\n",
        "    lime_values_dict = {}\n",
        "    for feat in X_train.columns:\n",
        "        for key, val in lime_values.items():\n",
        "            if feat in key:\n",
        "                lime_values_dict[feat] = val\n",
        "                break\n",
        "    \n",
        "    print(f'‚úÖ LIME explanation generated')\n",
        "    print('=' * 60)\n",
        "    \n",
        "    lime_available = True\n",
        "except ImportError:\n",
        "    print('‚ö†Ô∏è  LIME not installed. Run: pip install lime')\n",
        "    print('   Skipping LIME comparison...')\n",
        "    lime_available = False\n",
        "    print('=' * 60)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compare SHAP and LIME\n",
        "if lime_available:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    # SHAP plot\n",
        "    feature_names = X_train.columns\n",
        "    shap_vals = shap_values_pos[0]\n",
        "    \n",
        "    sorted_idx = np.argsort(np.abs(shap_vals))\n",
        "    sorted_features = feature_names[sorted_idx]\n",
        "    sorted_shap = shap_vals[sorted_idx]\n",
        "    \n",
        "    colors_shap = ['red' if x < 0 else 'green' for x in sorted_shap]\n",
        "    ax1.barh(range(len(sorted_features)), sorted_shap, color=colors_shap, alpha=0.7, edgecolor='black')\n",
        "    ax1.set_yticks(range(len(sorted_features)))\n",
        "    ax1.set_yticklabels(sorted_features)\n",
        "    ax1.set_xlabel('SHAP Value (impact on prediction)', fontweight='bold')\n",
        "    ax1.set_title('üéØ SHAP Explanations', fontweight='bold', fontsize=14)\n",
        "    ax1.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "    ax1.grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # LIME plot\n",
        "    lime_features = list(lime_values_dict.keys())\n",
        "    lime_vals = list(lime_values_dict.values())\n",
        "    \n",
        "    sorted_idx_lime = np.argsort(np.abs(lime_vals))\n",
        "    sorted_features_lime = [lime_features[i] for i in sorted_idx_lime]\n",
        "    sorted_lime = [lime_vals[i] for i in sorted_idx_lime]\n",
        "    \n",
        "    colors_lime = ['red' if x < 0 else 'green' for x in sorted_lime]\n",
        "    ax2.barh(range(len(sorted_features_lime)), sorted_lime, color=colors_lime, alpha=0.7, edgecolor='black')\n",
        "    ax2.set_yticks(range(len(sorted_features_lime)))\n",
        "    ax2.set_yticklabels(sorted_features_lime)\n",
        "    ax2.set_xlabel('LIME Weight (impact on prediction)', fontweight='bold')\n",
        "    ax2.set_title('üçã LIME Explanations', fontweight='bold', fontsize=14)\n",
        "    ax2.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "    ax2.grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print('\\nüìä Comparison Results:')\n",
        "    print('=' * 60)\n",
        "    print('\\nSHAP Feature Rankings:')\n",
        "    for i, (feat, val) in enumerate(zip(sorted_features[-5:][::-1], sorted_shap[-5:][::-1]), 1):\n",
        "        print(f'  {i}. {feat:20} ‚Üí {val:+.4f}')\n",
        "    \n",
        "    print('\\nLIME Feature Rankings:')\n",
        "    for i, (feat, val) in enumerate(zip(sorted_features_lime[-5:][::-1], sorted_lime[-5:][::-1]), 1):\n",
        "        print(f'  {i}. {feat:20} ‚Üí {val:+.4f}')\n",
        "    \n",
        "    print('\\nüí° Key Differences:')\n",
        "    print('  ‚Ä¢ SHAP: Based on game theory, considers all coalitions')\n",
        "    print('  ‚Ä¢ LIME: Based on local linear approximation')\n",
        "    print('  ‚Ä¢ Rankings may differ due to different methodologies')\n",
        "    print('  ‚Ä¢ SHAP satisfies theoretical properties (additivity, consistency)')\n",
        "    print('=' * 60)\n",
        "else:\n",
        "    print('\\n‚ö†Ô∏è  Install LIME to see comparison: pip install lime')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 2a\n",
        "\n",
        "**Task**: Run SHAP and LIME explanations on 5 different instances and compare:\n",
        "\n",
        "1. Do they always agree on the top-3 most important features?\n",
        "2. Calculate the correlation between SHAP and LIME feature importances\n",
        "3. Which method is more stable across different instances?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Compare SHAP and LIME on multiple instances\n",
        "\n",
        "n_instances = 5\n",
        "# Sample random instances from test set\n",
        "# Calculate both SHAP and LIME for each\n",
        "# Compare feature rankings\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3: Mathematical Properties of SHAP\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "SHAP values satisfy four key axioms that make them theoretically sound:\n",
        "\n",
        "#### 1. **Local Accuracy (Efficiency)**\n",
        "```\n",
        "f(x) - E[f(X)] = Œ£ œÜ·µ¢(x)\n",
        "```\n",
        "The sum of SHAP values equals the difference between prediction and expected value.\n",
        "\n",
        "#### 2. **Missingness**\n",
        "If a feature is missing (not used), its SHAP value is 0.\n",
        "\n",
        "#### 3. **Consistency (Monotonicity)**\n",
        "If a model changes so a feature's contribution increases, its SHAP value shouldn't decrease.\n",
        "\n",
        "#### 4. **Symmetry**\n",
        "If two features contribute equally to all predictions, they get equal SHAP values.\n",
        "\n",
        "Let's verify these properties empirically!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Property 1: Local Accuracy (Efficiency)\n",
        "print('üîç PROPERTY 1: LOCAL ACCURACY (EFFICIENCY)')\n",
        "print('=' * 70)\n",
        "\n",
        "# Get base value (expected prediction)\n",
        "explainer_full = shap.TreeExplainer(rf_credit)\n",
        "shap_values_all = explainer_shap.shap_values(X_test)\n",
        "\n",
        "# For binary classification\n",
        "if isinstance(shap_values_all, list):\n",
        "    shap_values_test = shap_values_all[1]\n",
        "else:\n",
        "    shap_values_test = shap_values_all\n",
        "\n",
        "expected_value = explainer_full.expected_value\n",
        "if isinstance(expected_value, list):\n",
        "    expected_value = expected_value[1]\n",
        "\n",
        "# Check first 5 instances\n",
        "print(f'Base value (expected prediction): {expected_value:.4f}\\n')\n",
        "\n",
        "for i in range(min(5, len(X_test))):\n",
        "    instance = X_test.iloc[i:i+1]\n",
        "    actual_pred = rf_credit.predict_proba(instance)[0][1]\n",
        "    shap_sum = shap_values_test[i].sum()\n",
        "    reconstructed_pred = expected_value + shap_sum\n",
        "    \n",
        "    print(f'Instance {i}:')\n",
        "    print(f'  Actual prediction:        {actual_pred:.4f}')\n",
        "    print(f'  Base + SHAP sum:          {reconstructed_pred:.4f}')\n",
        "    print(f'  Difference:               {abs(actual_pred - reconstructed_pred):.6f}')\n",
        "    print(f'  Satisfies property:       {\"‚úÖ Yes\" if abs(actual_pred - reconstructed_pred) < 0.01 else \"‚ùå No\"}')\n",
        "    print()\n",
        "\n",
        "print('üí° Interpretation: SHAP values perfectly reconstruct predictions!')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Property 2: Missingness - Verify with feature ablation\n",
        "print('\\nüîç PROPERTY 2: MISSINGNESS')\n",
        "print('=' * 70)\n",
        "\n",
        "# Train model WITHOUT one feature\n",
        "X_ablated = X_train.drop('Previous_Defaults', axis=1)\n",
        "X_test_ablated = X_test.drop('Previous_Defaults', axis=1)\n",
        "\n",
        "rf_ablated = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE)\n",
        "rf_ablated.fit(X_ablated, y_train)\n",
        "\n",
        "# Calculate SHAP for ablated model\n",
        "explainer_ablated = shap.TreeExplainer(rf_ablated)\n",
        "shap_values_ablated = explainer_ablated.shap_values(X_test_ablated)\n",
        "\n",
        "if isinstance(shap_values_ablated, list):\n",
        "    shap_values_ablated = shap_values_ablated[1]\n",
        "\n",
        "print('Model trained WITHOUT \"Previous_Defaults\" feature')\n",
        "print(f'Number of features in original model: {X_train.shape[1]}')\n",
        "print(f'Number of features in ablated model:  {X_ablated.shape[1]}\\n')\n",
        "\n",
        "print('SHAP values for \"Previous_Defaults\" in original model:')\n",
        "prev_def_idx = X_train.columns.get_loc('Previous_Defaults')\n",
        "print(f'  Mean absolute SHAP: {np.abs(shap_values_test[:, prev_def_idx]).mean():.4f}')\n",
        "print(f'  Non-zero SHAP values: {(shap_values_test[:, prev_def_idx] != 0).sum()} / {len(shap_values_test)}')\n",
        "\n",
        "print('\\nüí° Interpretation: When feature is in model, it has non-zero SHAP values.')\n",
        "print('   If removed from model, it would have zero contribution.')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Property 3 & 4: Visualize with heatmap\n",
        "print('\\nüîç PROPERTY 3 & 4: CONSISTENCY AND SYMMETRY')\n",
        "print('=' * 70)\n",
        "\n",
        "# Calculate SHAP for multiple instances\n",
        "n_samples = 20\n",
        "sample_indices = np.random.choice(len(X_test), n_samples, replace=False)\n",
        "X_sample = X_test.iloc[sample_indices]\n",
        "\n",
        "explainer_sample = shap.TreeExplainer(rf_credit)\n",
        "shap_sample = explainer_sample.shap_values(X_sample)\n",
        "\n",
        "if isinstance(shap_sample, list):\n",
        "    shap_sample = shap_sample[1]\n",
        "\n",
        "# Create heatmap\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "im = ax.imshow(shap_sample.T, cmap='RdBu_r', aspect='auto', vmin=-0.5, vmax=0.5)\n",
        "\n",
        "# Labels\n",
        "ax.set_xticks(range(n_samples))\n",
        "ax.set_yticks(range(len(X_train.columns)))\n",
        "ax.set_xticklabels([f'Inst {i}' for i in range(n_samples)], rotation=90)\n",
        "ax.set_yticklabels(X_train.columns)\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(im, ax=ax)\n",
        "cbar.set_label('SHAP Value', rotation=270, labelpad=20, fontweight='bold')\n",
        "\n",
        "# Add title\n",
        "ax.set_title('üé® SHAP Values Heatmap: Feature Contributions Across Instances', \n",
        "             fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Consistency: Features with higher contributions show warmer colors')\n",
        "print('üí° Symmetry: Features with similar patterns have similar SHAP distributions')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 3a\n",
        "\n",
        "**Task**: Verify SHAP properties on the Iris dataset\n",
        "\n",
        "1. Train a classifier on Iris data\n",
        "2. Calculate SHAP values for test set\n",
        "3. Verify local accuracy for 10 random instances\n",
        "4. Create a feature importance ranking\n",
        "5. Compare with model's built-in feature_importances_\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Verify SHAP properties on Iris\n",
        "\n",
        "# Step 1: Prepare data\n",
        "X_iris = iris_df.drop(['target', 'species'], axis=1)\n",
        "y_iris = iris_df['target']\n",
        "\n",
        "# Step 2: Train model\n",
        "\n",
        "# Step 3: Calculate SHAP values\n",
        "\n",
        "# Step 4: Verify local accuracy\n",
        "\n",
        "# Step 5: Compare with feature_importances_\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 4: Understanding Feature Interactions\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "SHAP not only provides individual feature contributions but can also reveal **feature interactions**.\n",
        "\n",
        "**Interaction**: When the combined effect of two features differs from their individual effects.\n",
        "\n",
        "**Formula for SHAP Interaction Values**:\n",
        "```\n",
        "œÜ·µ¢,‚±º = effect of features i and j together - effect of i alone - effect of j alone\n",
        "```\n",
        "\n",
        "**Example**:\n",
        "- Feature A (size): +$50K\n",
        "- Feature B (location): +$30K\n",
        "- Together: +$95K (not $80K!)\n",
        "- Interaction: $95K - $50K - $30K = +$15K (synergy!)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate SHAP interaction values\n",
        "print('üîó CALCULATING SHAP INTERACTION VALUES')\n",
        "print('=' * 70)\n",
        "\n",
        "# Use a smaller sample for faster computation\n",
        "X_interaction = X_test.iloc[:100]\n",
        "\n",
        "print('‚è≥ Computing interactions (this may take a moment)...')\n",
        "\n",
        "try:\n",
        "    # Calculate interaction values\n",
        "    shap_interaction_values = explainer_shap.shap_interaction_values(X_interaction)\n",
        "    \n",
        "    # For binary classification, take positive class\n",
        "    if isinstance(shap_interaction_values, list):\n",
        "        interactions = shap_interaction_values[1]\n",
        "    else:\n",
        "        interactions = shap_interaction_values\n",
        "    \n",
        "    # Average over all instances\n",
        "    mean_interactions = np.abs(interactions).mean(axis=0)\n",
        "    \n",
        "    print('‚úÖ Interaction values computed successfully!')\n",
        "    print(f'   Shape: {interactions.shape}')\n",
        "    print(f'   (instances, features, features)')\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f'‚ö†Ô∏è  Error computing interactions: {e}')\n",
        "    print('   Using approximate method...')\n",
        "    # Fallback: compute pairwise correlations of SHAP values\n",
        "    mean_interactions = np.abs(np.corrcoef(shap_values_test[:100].T))\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize interaction matrix\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "# Mask diagonal for better visualization\n",
        "interaction_matrix = mean_interactions.copy()\n",
        "np.fill_diagonal(interaction_matrix, 0)\n",
        "\n",
        "im = ax.imshow(interaction_matrix, cmap='YlOrRd', aspect='auto')\n",
        "\n",
        "# Add labels\n",
        "feature_names = X_train.columns\n",
        "ax.set_xticks(range(len(feature_names)))\n",
        "ax.set_yticks(range(len(feature_names)))\n",
        "ax.set_xticklabels(feature_names, rotation=45, ha='right')\n",
        "ax.set_yticklabels(feature_names)\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(im, ax=ax)\n",
        "cbar.set_label('|Interaction Strength|', rotation=270, labelpad=20, fontweight='bold')\n",
        "\n",
        "# Add values to cells\n",
        "for i in range(len(feature_names)):\n",
        "    for j in range(len(feature_names)):\n",
        "        if i != j:\n",
        "            text = ax.text(j, i, f'{interaction_matrix[i, j]:.3f}',\n",
        "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "\n",
        "ax.set_title('üîó SHAP Interaction Matrix\\n(Diagonal removed for clarity)', \n",
        "             fontweight='bold', fontsize=14, pad=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find top interactions\n",
        "print('\\nüîù TOP 5 FEATURE INTERACTIONS')\n",
        "print('=' * 70)\n",
        "\n",
        "interaction_pairs = []\n",
        "for i in range(len(feature_names)):\n",
        "    for j in range(i+1, len(feature_names)):\n",
        "        interaction_pairs.append((feature_names[i], feature_names[j], interaction_matrix[i, j]))\n",
        "\n",
        "interaction_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "for idx, (feat1, feat2, strength) in enumerate(interaction_pairs[:5], 1):\n",
        "    print(f'{idx}. {feat1:20} √ó {feat2:20} ‚Üí {strength:.4f}')\n",
        "\n",
        "print('\\nüí° Interpretation:')\n",
        "print('  ‚Ä¢ Higher values indicate stronger interactions')\n",
        "print('  ‚Ä¢ Positive: Features amplify each other')\n",
        "print('  ‚Ä¢ Consider interactions for feature engineering')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 4a\n",
        "\n",
        "**Task**: Analyze interactions in the Housing Price dataset\n",
        "\n",
        "1. Train a regression model on housing data\n",
        "2. Calculate SHAP interaction values\n",
        "3. Find the top-3 strongest interactions\n",
        "4. Explain why these interactions make sense (domain knowledge)\n",
        "5. Create a scatter plot showing the interaction effect\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Analyze housing price interactions\n",
        "\n",
        "# Hint: Look for interactions like:\n",
        "# - Square_Feet √ó Bedrooms (bigger houses need more rooms)\n",
        "# - Age √ó Distance_to_City (old suburban vs new urban)\n",
        "# - School_Rating √ó Distance_to_City\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üõ† Part 2: SHAP Implementation Methods\n",
        "\n",
        "## Different Explainers for Different Models\n",
        "\n",
        "SHAP provides **specialized explainers** optimized for different model types:\n",
        "\n",
        "| Explainer | Best For | Speed | Accuracy |\n",
        "|-----------|----------|-------|----------|\n",
        "| **TreeExplainer** | Tree-based models (RF, XGBoost, LightGBM) | ‚ö°‚ö°‚ö° Fast | ‚úÖ Exact |\n",
        "| **KernelExplainer** | Any model (black-box) | üêå Slow | ‚âà Approximation |\n",
        "| **DeepExplainer** | Neural networks (TensorFlow, PyTorch) | ‚ö°‚ö° Medium | ‚âà Approximation |\n",
        "| **GradientExplainer** | Differentiable models | ‚ö°‚ö° Medium | ‚âà Approximation |\n",
        "| **LinearExplainer** | Linear models | ‚ö°‚ö°‚ö° Fast | ‚úÖ Exact |\n",
        "\n",
        "### üéØ Selection Guide\n",
        "\n",
        "```python\n",
        "if model in [RandomForest, XGBoost, LightGBM, CatBoost]:\n",
        "    use TreeExplainer()  # Fastest and exact\n",
        "    \n",
        "elif model in [Neural Network]:\n",
        "    use DeepExplainer()  # Optimized for deep learning\n",
        "    \n",
        "elif model in [Logistic Regression, Linear SVM]:\n",
        "    use LinearExplainer()  # Exact for linear models\n",
        "    \n",
        "else:  # SVM, KNN, or custom models\n",
        "    use KernelExplainer()  # Works for anything\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 5: TreeSHAP - Exact and Fast\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**TreeSHAP** is a breakthrough algorithm that computes exact SHAP values for tree-based models in polynomial time.\n",
        "\n",
        "**Key advantages**:\n",
        "- ‚ö° **Fast**: O(TLD¬≤) where T=trees, L=leaves, D=depth\n",
        "- ‚úÖ **Exact**: Not an approximation\n",
        "- üå≥ **Optimized**: Leverages tree structure\n",
        "\n",
        "**Supported models**:\n",
        "- Random Forest\n",
        "- Gradient Boosting (XGBoost, LightGBM, CatBoost)\n",
        "- Decision Trees\n",
        "- Isolation Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train multiple tree-based models\n",
        "print('üå≥ TRAINING TREE-BASED MODELS')\n",
        "print('=' * 70)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb\n",
        "import time\n",
        "\n",
        "# Prepare cancer data\n",
        "X_cancer = cancer_df.drop(['target', 'diagnosis'], axis=1)\n",
        "y_cancer = cancer_df['target']\n",
        "\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
        "    X_cancer, y_cancer, test_size=0.2, random_state=RANDOM_STATE, stratify=y_cancer\n",
        ")\n",
        "\n",
        "models = {}\n",
        "\n",
        "# 1. Random Forest\n",
        "print('\\n1Ô∏è‚É£  Training Random Forest...')\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=RANDOM_STATE)\n",
        "start = time.time()\n",
        "rf.fit(X_train_c, y_train_c)\n",
        "rf_time = time.time() - start\n",
        "models['Random Forest'] = rf\n",
        "print(f'   Training time: {rf_time:.3f}s')\n",
        "print(f'   Test accuracy: {accuracy_score(y_test_c, rf.predict(X_test_c)):.3f}')\n",
        "\n",
        "# 2. Gradient Boosting\n",
        "print('\\n2Ô∏è‚É£  Training Gradient Boosting...')\n",
        "gb = GradientBoostingClassifier(n_estimators=100, max_depth=4, random_state=RANDOM_STATE)\n",
        "start = time.time()\n",
        "gb.fit(X_train_c, y_train_c)\n",
        "gb_time = time.time() - start\n",
        "models['Gradient Boosting'] = gb\n",
        "print(f'   Training time: {gb_time:.3f}s')\n",
        "print(f'   Test accuracy: {accuracy_score(y_test_c, gb.predict(X_test_c)):.3f}')\n",
        "\n",
        "# 3. XGBoost\n",
        "print('\\n3Ô∏è‚É£  Training XGBoost...')\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=4, random_state=RANDOM_STATE, \n",
        "                               eval_metric='logloss')\n",
        "start = time.time()\n",
        "xgb_model.fit(X_train_c, y_train_c)\n",
        "xgb_time = time.time() - start\n",
        "models['XGBoost'] = xgb_model\n",
        "print(f'   Training time: {xgb_time:.3f}s')\n",
        "print(f'   Test accuracy: {accuracy_score(y_test_c, xgb_model.predict(X_test_c)):.3f}')\n",
        "\n",
        "print('\\n' + '=' * 70)\n",
        "print('‚úÖ All models trained successfully!')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate TreeSHAP for each model\n",
        "print('\\n‚è±Ô∏è  TREESHAP COMPUTATION TIME COMPARISON')\n",
        "print('=' * 70)\n",
        "\n",
        "shap_times = {}\n",
        "shap_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f'\\n{model_name}:')\n",
        "    \n",
        "    # Create explainer\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    \n",
        "    # Time the computation\n",
        "    start = time.time()\n",
        "    shap_values = explainer.shap_values(X_test_c)\n",
        "    elapsed = time.time() - start\n",
        "    \n",
        "    shap_times[model_name] = elapsed\n",
        "    shap_results[model_name] = shap_values\n",
        "    \n",
        "    # Handle different output formats\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[1]  # Positive class\n",
        "    \n",
        "    print(f'   Computation time: {elapsed:.3f}s')\n",
        "    print(f'   Instances explained: {len(X_test_c)}')\n",
        "    print(f'   Time per instance: {elapsed/len(X_test_c)*1000:.2f}ms')\n",
        "    print(f'   Expected value: {explainer.expected_value:.4f}')\n",
        "\n",
        "print('\\n' + '=' * 70)\n",
        "print('‚úÖ TreeSHAP is extremely fast for all tree models!')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize computation times\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left: Computation time comparison\n",
        "model_names = list(shap_times.keys())\n",
        "times = list(shap_times.values())\n",
        "\n",
        "bars = ax1.bar(model_names, times, color=['#3498db', '#2ecc71', '#e74c3c'], \n",
        "               alpha=0.7, edgecolor='black', linewidth=2)\n",
        "\n",
        "for bar, time_val in zip(bars, times):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{time_val:.3f}s',\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax1.set_ylabel('Computation Time (seconds)', fontweight='bold', fontsize=12)\n",
        "ax1.set_title('‚è±Ô∏è TreeSHAP Computation Speed', fontweight='bold', fontsize=14)\n",
        "ax1.set_ylim(0, max(times) * 1.2)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Right: Feature importance comparison\n",
        "explainer_rf = shap.TreeExplainer(models['Random Forest'])\n",
        "shap_vals_rf = explainer_rf.shap_values(X_test_c)\n",
        "if isinstance(shap_vals_rf, list):\n",
        "    shap_vals_rf = shap_vals_rf[1]\n",
        "\n",
        "# Calculate mean absolute SHAP values\n",
        "mean_shap = np.abs(shap_vals_rf).mean(axis=0)\n",
        "sorted_idx = np.argsort(mean_shap)[-10:]  # Top 10\n",
        "\n",
        "ax2.barh(range(len(sorted_idx)), mean_shap[sorted_idx], \n",
        "         color='coral', alpha=0.7, edgecolor='black')\n",
        "ax2.set_yticks(range(len(sorted_idx)))\n",
        "ax2.set_yticklabels(X_cancer.columns[sorted_idx], fontsize=9)\n",
        "ax2.set_xlabel('Mean |SHAP value|', fontweight='bold', fontsize=12)\n",
        "ax2.set_title('üéØ Top 10 Important Features (Random Forest)', fontweight='bold', fontsize=14)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Key Insight: TreeSHAP provides exact SHAP values in milliseconds!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 5a\n",
        "\n",
        "**Task**: Compare TreeSHAP across different tree configurations\n",
        "\n",
        "1. Train 3 Random Forests with different settings:\n",
        "   - Shallow trees (max_depth=3)\n",
        "   - Medium trees (max_depth=10)\n",
        "   - Deep trees (max_depth=None)\n",
        "2. Measure TreeSHAP computation time for each\n",
        "3. Compare feature importance rankings\n",
        "4. Analyze how tree depth affects computation time\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Compare TreeSHAP performance vs tree depth\n",
        "\n",
        "configurations = [\n",
        "    {'name': 'Shallow', 'max_depth': 3},\n",
        "    {'name': 'Medium', 'max_depth': 10},\n",
        "    {'name': 'Deep', 'max_depth': None}\n",
        "]\n",
        "\n",
        "# Train models and measure TreeSHAP times\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 6: KernelSHAP - Model-Agnostic Approach\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**KernelSHAP** is the most general SHAP explainer - it works with **any model**!\n",
        "\n",
        "**How it works**:\n",
        "1. Generate random coalitions of features\n",
        "2. Evaluate model on perturbed inputs\n",
        "3. Fit a weighted linear model\n",
        "4. Extract coefficients as SHAP values\n",
        "\n",
        "**Trade-off**:\n",
        "- ‚úÖ **Universal**: Works with any model (even black-box)\n",
        "- ‚ùå **Slow**: Requires many model evaluations\n",
        "- ‚âà **Approximate**: Monte Carlo sampling\n",
        "\n",
        "**When to use**:\n",
        "- SVM, KNN, or other non-tree models\n",
        "- Custom models or ensembles\n",
        "- When you need model-agnostic explanations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train non-tree models\n",
        "print('üîÆ TRAINING NON-TREE MODELS')\n",
        "print('=' * 70)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Use iris for faster computation\n",
        "X_iris = iris_df.drop(['target', 'species'], axis=1)\n",
        "y_iris = iris_df['target']\n",
        "\n",
        "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
        "    X_iris, y_iris, test_size=0.2, random_state=RANDOM_STATE, stratify=y_iris\n",
        ")\n",
        "\n",
        "# 1. Support Vector Machine\n",
        "print('\\n1Ô∏è‚É£  Training SVM...')\n",
        "svm_model = SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE)\n",
        "svm_model.fit(X_train_i, y_train_i)\n",
        "print(f'   Test accuracy: {accuracy_score(y_test_i, svm_model.predict(X_test_i)):.3f}')\n",
        "\n",
        "# 2. K-Nearest Neighbors\n",
        "print('\\n2Ô∏è‚É£  Training KNN...')\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_i, y_train_i)\n",
        "print(f'   Test accuracy: {accuracy_score(y_test_i, knn_model.predict(X_test_i)):.3f}')\n",
        "\n",
        "# 3. Naive Bayes\n",
        "print('\\n3Ô∏è‚É£  Training Naive Bayes...')\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_i, y_train_i)\n",
        "print(f'   Test accuracy: {accuracy_score(y_test_i, nb_model.predict(X_test_i)):.3f}')\n",
        "\n",
        "print('\\n' + '=' * 70)\n",
        "print('‚úÖ Non-tree models trained!')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply KernelSHAP to SVM\n",
        "print('\\nüîç APPLYING KERNELSHAP TO SVM')\n",
        "print('=' * 70)\n",
        "\n",
        "# Create KernelExplainer\n",
        "# Note: KernelSHAP needs a background dataset\n",
        "background = shap.sample(X_train_i, 50)  # Use 50 samples as background\n",
        "\n",
        "print(f'Background dataset: {background.shape}')\n",
        "print('Creating KernelExplainer...')\n",
        "\n",
        "# Create explainer\n",
        "explainer_kernel = shap.KernelExplainer(svm_model.predict_proba, background)\n",
        "\n",
        "# Explain a single instance (KernelSHAP is slow!)\n",
        "print('\\nExplaining 1 instance...')\n",
        "test_instance = X_test_i.iloc[0:1]\n",
        "\n",
        "start = time.time()\n",
        "shap_values_kernel = explainer_kernel.shap_values(test_instance, nsamples=100)\n",
        "kernel_time = time.time() - start\n",
        "\n",
        "print(f'‚úÖ KernelSHAP computation completed in {kernel_time:.3f}s')\n",
        "print(f'   Time per instance: {kernel_time:.3f}s (vs TreeSHAP: ~0.001s)')\n",
        "\n",
        "# Compare with TreeSHAP (if we had a tree model)\n",
        "rf_iris = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
        "rf_iris.fit(X_train_i, y_train_i)\n",
        "explainer_tree = shap.TreeExplainer(rf_iris)\n",
        "\n",
        "start = time.time()\n",
        "shap_values_tree = explainer_tree.shap_values(test_instance)\n",
        "tree_time = time.time() - start\n",
        "\n",
        "print(f'\\nüìä Speed Comparison:')\n",
        "print(f'   KernelSHAP: {kernel_time:.3f}s')\n",
        "print(f'   TreeSHAP:   {tree_time:.3f}s')\n",
        "print(f'   Speedup:    {kernel_time/tree_time:.0f}x faster with TreeSHAP!')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize KernelSHAP results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# For multi-class, visualize each class\n",
        "for class_idx in range(3):\n",
        "    ax = axes[class_idx]\n",
        "    \n",
        "    # Extract SHAP values for this class\n",
        "    if isinstance(shap_values_kernel, list):\n",
        "        shap_class = shap_values_kernel[class_idx][0]\n",
        "    else:\n",
        "        shap_class = shap_values_kernel[0]\n",
        "    \n",
        "    # Create bar plot\n",
        "    features = X_iris.columns\n",
        "    colors = ['red' if x < 0 else 'green' for x in shap_class]\n",
        "    \n",
        "    ax.barh(range(len(features)), shap_class, color=colors, alpha=0.7, edgecolor='black')\n",
        "    ax.set_yticks(range(len(features)))\n",
        "    ax.set_yticklabels(features)\n",
        "    ax.set_xlabel('SHAP value', fontweight='bold')\n",
        "    ax.set_title(f'Class {iris.target_names[class_idx]}', fontweight='bold')\n",
        "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.suptitle('üîÆ KernelSHAP: SVM Explanations for Iris Classes', \n",
        "             fontweight='bold', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation: KernelSHAP works with ANY model, but is slower')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 6a\n",
        "\n",
        "**Task**: Compare KernelSHAP vs TreeSHAP on the same data\n",
        "\n",
        "1. Train both Random Forest and SVM on credit data\n",
        "2. Use KernelSHAP for SVM and TreeSHAP for RF\n",
        "3. Explain the same 5 instances with both methods\n",
        "4. Compare:\n",
        "   - Computation time\n",
        "   - Feature rankings\n",
        "   - Explanation consistency\n",
        "5. When would you choose KernelSHAP despite its slowness?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Compare KernelSHAP and TreeSHAP\n",
        "\n",
        "# Hints:\n",
        "# - Use small background sample (50-100) for KernelSHAP\n",
        "# - Set nsamples=100 for faster but less accurate results\n",
        "# - Compare feature rankings using rank correlation\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 7: DeepSHAP for Neural Networks\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**DeepSHAP** combines SHAP with DeepLIFT to explain neural networks efficiently.\n",
        "\n",
        "**Key features**:\n",
        "- üß† Designed for deep learning models\n",
        "- ‚ö° Faster than KernelSHAP for neural nets\n",
        "- üìä Backpropagates through network layers\n",
        "- üéØ Works with TensorFlow, PyTorch, Keras\n",
        "\n",
        "**How it works**:\n",
        "1. Uses reference activations (baseline)\n",
        "2. Computes gradients √ó activations\n",
        "3. Distributes attribution through layers\n",
        "4. Much faster than sampling-based methods\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a simple neural network\n",
        "print('üß† BUILDING NEURAL NETWORK')\n",
        "print('=' * 70)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Train MLP on cancer data\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32, 16), max_iter=500, \n",
        "                    random_state=RANDOM_STATE, early_stopping=True)\n",
        "\n",
        "print('Training Multi-Layer Perceptron...')\n",
        "mlp.fit(X_train_c, y_train_c)\n",
        "\n",
        "train_acc = mlp.score(X_train_c, y_train_c)\n",
        "test_acc = mlp.score(X_test_c, y_test_c)\n",
        "\n",
        "print(f'\\n‚úÖ Neural Network Trained!')\n",
        "print(f'   Architecture: {[X_train_c.shape[1]] + list(mlp.hidden_layer_sizes) + [2]}')\n",
        "print(f'   Training accuracy: {train_acc:.3f}')\n",
        "print(f'   Test accuracy: {test_acc:.3f}')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply GradientExplainer (alternative to DeepSHAP for sklearn)\n",
        "print('\\nüîç APPLYING GRADIENTEXPLAINER')\n",
        "print('=' * 70)\n",
        "\n",
        "# For sklearn MLP, we use GradientExplainer\n",
        "# Note: sklearn's MLP doesn't support DeepSHAP directly\n",
        "# In practice, you'd use TensorFlow/PyTorch for DeepSHAP\n",
        "\n",
        "print('Using GradientExplainer for sklearn MLP...')\n",
        "print('(For true DeepSHAP, use TensorFlow/PyTorch models)')\n",
        "\n",
        "# Create background dataset\n",
        "background_nn = X_train_c.iloc[:50]\n",
        "\n",
        "# Create explainer\n",
        "explainer_nn = shap.KernelExplainer(mlp.predict_proba, background_nn)\n",
        "\n",
        "# Explain a few instances\n",
        "print('\\nExplaining 3 test instances...')\n",
        "test_sample = X_test_c.iloc[:3]\n",
        "\n",
        "start = time.time()\n",
        "shap_values_nn = explainer_nn.shap_values(test_sample, nsamples=100)\n",
        "nn_time = time.time() - start\n",
        "\n",
        "print(f'‚úÖ Explanation completed in {nn_time:.3f}s')\n",
        "print(f'   Time per instance: {nn_time/3:.3f}s')\n",
        "\n",
        "print('\\nüí° Note: For production deep learning, use:')\n",
        "print('   ‚Ä¢ TensorFlow ‚Üí shap.DeepExplainer(model, background)')\n",
        "print('   ‚Ä¢ PyTorch ‚Üí shap.DeepExplainer(model, background)')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize neural network explanations\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "for idx in range(3):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Get SHAP values for this instance (positive class)\n",
        "    if isinstance(shap_values_nn, list):\n",
        "        shap_vals = shap_values_nn[1][idx]\n",
        "    else:\n",
        "        shap_vals = shap_values_nn[idx]\n",
        "    \n",
        "    # Sort by absolute value\n",
        "    sorted_idx = np.argsort(np.abs(shap_vals))[-10:]  # Top 10\n",
        "    sorted_features = X_cancer.columns[sorted_idx]\n",
        "    sorted_values = shap_vals[sorted_idx]\n",
        "    \n",
        "    colors = ['red' if x < 0 else 'green' for x in sorted_values]\n",
        "    \n",
        "    ax.barh(range(len(sorted_features)), sorted_values, color=colors, \n",
        "            alpha=0.7, edgecolor='black')\n",
        "    ax.set_yticks(range(len(sorted_features)))\n",
        "    ax.set_yticklabels(sorted_features, fontsize=9)\n",
        "    ax.set_xlabel('SHAP value', fontweight='bold')\n",
        "    ax.set_title(f'Instance {idx+1}', fontweight='bold')\n",
        "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.suptitle('üß† Neural Network SHAP Explanations', fontweight='bold', \n",
        "             fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Neural networks can capture complex non-linear patterns!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 7a\n",
        "\n",
        "**Task**: Compare shallow vs deep neural networks\n",
        "\n",
        "1. Train two MLPs:\n",
        "   - Shallow: 1 hidden layer with 32 neurons\n",
        "   - Deep: 3 hidden layers with (64, 32, 16) neurons\n",
        "2. Compare:\n",
        "   - Test accuracy\n",
        "   - SHAP explanation time\n",
        "   - Feature importance rankings\n",
        "3. Which architecture provides more consistent explanations?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Compare shallow vs deep neural networks\n",
        "\n",
        "# Train shallow network\n",
        "mlp_shallow = MLPClassifier(hidden_layer_sizes=(32,), max_iter=500, \n",
        "                             random_state=RANDOM_STATE)\n",
        "\n",
        "# Train deep network  \n",
        "mlp_deep = MLPClassifier(hidden_layer_sizes=(64, 32, 16), max_iter=500,\n",
        "                          random_state=RANDOM_STATE)\n",
        "\n",
        "# Compare explanations\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 8: GradientSHAP for Differentiable Models\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**GradientSHAP** combines integrated gradients with SHAP sampling.\n",
        "\n",
        "**Formula**:\n",
        "```\n",
        "œÜ·µ¢ = (x·µ¢ - x'·µ¢) √ó E[‚àÇf/‚àÇx·µ¢]\n",
        "```\n",
        "\n",
        "Where:\n",
        "- x·µ¢ = input feature value\n",
        "- x'·µ¢ = baseline feature value  \n",
        "- ‚àÇf/‚àÇx·µ¢ = gradient w.r.t. feature i\n",
        "\n",
        "**Advantages**:\n",
        "- ‚ö° Fast for differentiable models\n",
        "- üéØ Incorporates gradient information\n",
        "- üìâ Reduces variance vs plain gradients\n",
        "\n",
        "**Best for**:\n",
        "- Neural networks\n",
        "- Gradient boosting machines (with gradients)\n",
        "- Any differentiable model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstrate gradient-based feature attribution\n",
        "print('üìà GRADIENT-BASED FEATURE ATTRIBUTION')\n",
        "print('=' * 70)\n",
        "\n",
        "# Train a simple logistic regression (differentiable)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
        "logreg.fit(X_train_c, y_train_c)\n",
        "\n",
        "print(f'Logistic Regression trained')\n",
        "print(f'Test accuracy: {logreg.score(X_test_c, y_test_c):.3f}')\n",
        "\n",
        "# For logistic regression, coefficients ARE the gradients\n",
        "print('\\nüìä Model Coefficients (= Feature Importance for Linear Models):')\n",
        "print('=' * 70)\n",
        "\n",
        "# Get feature importance from coefficients\n",
        "coef_importance = np.abs(logreg.coef_[0])\n",
        "sorted_idx = np.argsort(coef_importance)[-10:]\n",
        "\n",
        "print('\\nTop 10 features by |coefficient|:')\n",
        "for i, idx in enumerate(sorted_idx[::-1], 1):\n",
        "    feat = X_cancer.columns[idx]\n",
        "    val = logreg.coef_[0][idx]\n",
        "    print(f'{i:2}. {feat:30} ‚Üí {val:+.4f}')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply LinearExplainer (exact for linear models)\n",
        "print('\\nüîç LINEAREXPLAINER FOR LOGISTIC REGRESSION')\n",
        "print('=' * 70)\n",
        "\n",
        "# LinearExplainer gives exact SHAP values for linear models\n",
        "explainer_linear = shap.LinearExplainer(logreg, X_train_c)\n",
        "\n",
        "# Explain test set\n",
        "shap_values_linear = explainer_linear.shap_values(X_test_c)\n",
        "\n",
        "print('‚úÖ SHAP values computed (exact for linear models)')\n",
        "print(f'   Shape: {shap_values_linear.shape}')\n",
        "print(f'   Computation: Instant (analytical formula)')\n",
        "\n",
        "# Compare with model coefficients\n",
        "print('\\nüìä Comparison: SHAP vs Coefficients')\n",
        "print('=' * 70)\n",
        "\n",
        "mean_abs_shap = np.abs(shap_values_linear).mean(axis=0)\n",
        "correlation = np.corrcoef(mean_abs_shap, coef_importance)[0, 1]\n",
        "\n",
        "print(f'Correlation between mean |SHAP| and |coefficients|: {correlation:.3f}')\n",
        "print('\\nüí° For linear models, SHAP values are scaled coefficients!')\n",
        "print('   They account for feature distributions and interactions.')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize gradient-based attributions\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left: Coefficients\n",
        "sorted_idx = np.argsort(coef_importance)[-10:]\n",
        "ax1.barh(range(10), coef_importance[sorted_idx], color='steelblue', \n",
        "         alpha=0.7, edgecolor='black')\n",
        "ax1.set_yticks(range(10))\n",
        "ax1.set_yticklabels(X_cancer.columns[sorted_idx], fontsize=9)\n",
        "ax1.set_xlabel('|Coefficient|', fontweight='bold')\n",
        "ax1.set_title('üìà Logistic Regression Coefficients', fontweight='bold', fontsize=14)\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Right: Mean SHAP values\n",
        "sorted_idx_shap = np.argsort(mean_abs_shap)[-10:]\n",
        "ax2.barh(range(10), mean_abs_shap[sorted_idx_shap], color='coral', \n",
        "         alpha=0.7, edgecolor='black')\n",
        "ax2.set_yticks(range(10))\n",
        "ax2.set_yticklabels(X_cancer.columns[sorted_idx_shap], fontsize=9)\n",
        "ax2.set_xlabel('Mean |SHAP value|', fontweight='bold')\n",
        "ax2.set_title('üéØ SHAP Feature Importance', fontweight='bold', fontsize=14)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Both methods identify similar important features!')\n",
        "print('   But SHAP provides instance-level attributions.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 8a\n",
        "\n",
        "**Task**: Integrated Gradients for Neural Networks\n",
        "\n",
        "While we can't implement true integrated gradients without a deep learning framework, let's simulate the concept:\n",
        "\n",
        "1. Train a neural network on housing prices (regression)\n",
        "2. Calculate SHAP values for a test instance\n",
        "3. For a single feature, manually compute:\n",
        "   - Base prediction (feature = 0)\n",
        "   - Final prediction (feature = actual value)\n",
        "   - Interpolate between them\n",
        "4. Compare with SHAP value\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Simulate integrated gradients concept\n",
        "\n",
        "# Prepare housing regression data\n",
        "X_house = housing_df.drop('Price', axis=1)\n",
        "y_house = housing_df['Price']\n",
        "\n",
        "# Split data\n",
        "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
        "    X_house, y_house, test_size=0.2, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Train regression model\n",
        "\n",
        "# Calculate SHAP values\n",
        "\n",
        "# Manually compute integrated gradient for one feature\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 9: Deep Dive into SHAP Interactions\n",
        "\n",
        "### üìñ Concept Recap\n",
        "\n",
        "**SHAP Interaction Values** decompose predictions into:\n",
        "- Main effects (individual features)\n",
        "- Pairwise interactions (feature pairs)\n",
        "\n",
        "**Mathematical formula**:\n",
        "```\n",
        "f(x) = œÜ‚ÇÄ + Œ£œÜ·µ¢ + Œ£œÜ·µ¢,‚±º\n",
        "       base  main   interactions\n",
        "```\n",
        "\n",
        "**Use cases**:\n",
        "- Detect feature synergies or conflicts\n",
        "- Guide feature engineering\n",
        "- Understand model complexity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate detailed interaction analysis\n",
        "print('üîó DEEP INTERACTION ANALYSIS')\n",
        "print('=' * 70)\n",
        "\n",
        "# Use Random Forest on credit data\n",
        "rf_interact = RandomForestClassifier(n_estimators=50, max_depth=6, \n",
        "                                     random_state=RANDOM_STATE)\n",
        "rf_interact.fit(X_train, y_train)\n",
        "\n",
        "# Calculate interactions for subset of data\n",
        "X_interact_sample = X_test.iloc[:50]\n",
        "\n",
        "print('Computing SHAP interaction values...')\n",
        "print('(This may take a moment for pairwise interactions)')\n",
        "\n",
        "explainer_interact = shap.TreeExplainer(rf_interact)\n",
        "\n",
        "try:\n",
        "    interaction_vals = explainer_interact.shap_interaction_values(X_interact_sample)\n",
        "    \n",
        "    if isinstance(interaction_vals, list):\n",
        "        interaction_vals = interaction_vals[1]  # Positive class\n",
        "    \n",
        "    print(f'\\n‚úÖ Interaction values computed')\n",
        "    print(f'   Shape: {interaction_vals.shape}')\n",
        "    print(f'   Format: (instances, features, features)')\n",
        "    \n",
        "    # Analyze diagonal (main effects) vs off-diagonal (interactions)\n",
        "    main_effects = np.array([interaction_vals[i, :, :].diagonal() \n",
        "                             for i in range(len(interaction_vals))])\n",
        "    \n",
        "    mean_main = np.abs(main_effects).mean(axis=0)\n",
        "    \n",
        "    # Off-diagonal (interactions)\n",
        "    mean_interact = np.abs(interaction_vals).mean(axis=0)\n",
        "    np.fill_diagonal(mean_interact, 0)\n",
        "    \n",
        "    print(f'\\nüìä Analysis:')\n",
        "    print(f'   Mean |main effect|:     {mean_main.mean():.4f}')\n",
        "    print(f'   Mean |interaction|:     {mean_interact[mean_interact > 0].mean():.4f}')\n",
        "    print(f'   Ratio (main/interact):  {mean_main.mean() / mean_interact[mean_interact > 0].mean():.2f}x')\n",
        "    \n",
        "    interaction_computed = True\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f'\\n‚ö†Ô∏è  Could not compute interactions: {e}')\n",
        "    print('   Using approximation based on SHAP value correlations')\n",
        "    interaction_computed = False\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Find strongest interactions\n",
        "if interaction_computed:\n",
        "    print('\\nüîù STRONGEST FEATURE INTERACTIONS')\n",
        "    print('=' * 70)\n",
        "    \n",
        "    # Get feature names\n",
        "    features = X_train.columns\n",
        "    \n",
        "    # Find top interactions\n",
        "    interaction_strength = []\n",
        "    for i in range(len(features)):\n",
        "        for j in range(i+1, len(features)):\n",
        "            strength = mean_interact[i, j]\n",
        "            interaction_strength.append((features[i], features[j], strength))\n",
        "    \n",
        "    # Sort by strength\n",
        "    interaction_strength.sort(key=lambda x: x[2], reverse=True)\n",
        "    \n",
        "    print('\\nTop 10 Feature Interactions:')\n",
        "    print('-' * 70)\n",
        "    print(f'{\"Rank\":<6} {\"Feature 1\":<22} {\"Feature 2\":<22} {\"Strength\":<10}')\n",
        "    print('-' * 70)\n",
        "    \n",
        "    for rank, (feat1, feat2, strength) in enumerate(interaction_strength[:10], 1):\n",
        "        print(f'{rank:<6} {feat1:<22} {feat2:<22} {strength:<10.4f}')\n",
        "    \n",
        "    print('=' * 70)\n",
        "    \n",
        "    # Visualize top interaction\n",
        "    top_i, top_j = features.get_loc(interaction_strength[0][0]), features.get_loc(interaction_strength[0][1])\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    # Scatter plot showing interaction\n",
        "    scatter = ax.scatter(X_interact_sample.iloc[:, top_i], \n",
        "                        X_interact_sample.iloc[:, top_j],\n",
        "                        c=interaction_vals[:, top_i, top_j],\n",
        "                        cmap='RdYlGn', s=100, alpha=0.6, edgecolors='black')\n",
        "    \n",
        "    ax.set_xlabel(features[top_i], fontweight='bold', fontsize=12)\n",
        "    ax.set_ylabel(features[top_j], fontweight='bold', fontsize=12)\n",
        "    ax.set_title(f'üîó Strongest Interaction: {features[top_i]} √ó {features[top_j]}',\n",
        "                 fontweight='bold', fontsize=14)\n",
        "    \n",
        "    cbar = plt.colorbar(scatter, ax=ax)\n",
        "    cbar.set_label('Interaction SHAP Value', rotation=270, labelpad=20, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print('\\nüí° Interpretation:')\n",
        "    print(f'   ‚Ä¢ {features[top_i]} and {features[top_j]} have strong interaction')\n",
        "    print('   ‚Ä¢ Color shows combined effect on prediction')\n",
        "    print('   ‚Ä¢ Consider creating interaction features!')\n",
        "\n",
        "else:\n",
        "    print('\\nüìä Showing SHAP value correlation as interaction proxy...')\n",
        "    \n",
        "    shap_vals_full = explainer_interact.shap_values(X_test)\n",
        "    if isinstance(shap_vals_full, list):\n",
        "        shap_vals_full = shap_vals_full[1]\n",
        "    \n",
        "    # Correlation of SHAP values\n",
        "    shap_corr = np.corrcoef(shap_vals_full.T)\n",
        "    np.fill_diagonal(shap_corr, 0)\n",
        "    \n",
        "    # Find high correlations\n",
        "    high_corr_pairs = []\n",
        "    for i in range(len(X_train.columns)):\n",
        "        for j in range(i+1, len(X_train.columns)):\n",
        "            high_corr_pairs.append((X_train.columns[i], X_train.columns[j], \n",
        "                                   abs(shap_corr[i, j])))\n",
        "    \n",
        "    high_corr_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "    \n",
        "    print('\\nTop correlated SHAP values (potential interactions):')\n",
        "    for feat1, feat2, corr in high_corr_pairs[:5]:\n",
        "        print(f'  {feat1} √ó {feat2}: {corr:.3f}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üìà Part 3: SHAP Visualizations\n",
        "\n",
        "## Communicating Model Behavior\n",
        "\n",
        "SHAP provides powerful visualizations to understand model predictions at different levels:\n",
        "\n",
        "| Plot Type | Level | Purpose |\n",
        "|-----------|-------|---------|\n",
        "| **Waterfall** | Instance | Show prediction breakdown for one instance |\n",
        "| **Force** | Instance | Interactive explanation of single prediction |\n",
        "| **Decision** | Instance | Compare multiple instances |\n",
        "| **Summary** | Global | Overview of feature importance |\n",
        "| **Dependence** | Global | Show feature effect across all data |\n",
        "| **Bar** | Global | Simple feature ranking |\n",
        "\n",
        "### üé® Visualization Philosophy\n",
        "\n",
        "1. **Start local** ‚Üí Understand individual predictions\n",
        "2. **Go global** ‚Üí See overall patterns\n",
        "3. **Dive deep** ‚Üí Explore specific features\n",
        "4. **Tell stories** ‚Üí Use plots to communicate insights\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 10: Waterfall Plots - Explaining Single Predictions\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**Waterfall plots** show how each feature pushes the prediction from the base value to the final prediction.\n",
        "\n",
        "**Components**:\n",
        "- üîµ **Base value**: Expected model output (usually mean)\n",
        "- üü¢ **Positive contributions**: Features increasing prediction\n",
        "- üî¥ **Negative contributions**: Features decreasing prediction\n",
        "- ‚ö´ **Final prediction**: Where we end up\n",
        "\n",
        "**Perfect for**:\n",
        "- Explaining specific decisions to stakeholders\n",
        "- Debugging model behavior\n",
        "- Regulatory compliance (e.g., loan rejections)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prepare data for waterfall demonstration\n",
        "print('üåä WATERFALL PLOT DEMONSTRATION')\n",
        "print('=' * 70)\n",
        "\n",
        "# Get SHAP values for a specific instance\n",
        "instance_idx = 15\n",
        "instance = X_test.iloc[instance_idx]\n",
        "instance_values = instance.values\n",
        "feature_names = X_test.columns.tolist()\n",
        "\n",
        "# Calculate SHAP values\n",
        "shap_vals = explainer_shap.shap_values(X_test.iloc[instance_idx:instance_idx+1])\n",
        "\n",
        "if isinstance(shap_vals, list):\n",
        "    shap_vals = shap_vals[1][0]  # Positive class, first instance\n",
        "else:\n",
        "    shap_vals = shap_vals[0]\n",
        "\n",
        "# Get base value\n",
        "base_value = explainer_shap.expected_value\n",
        "if isinstance(base_value, list):\n",
        "    base_value = base_value[1]\n",
        "\n",
        "# Get prediction\n",
        "prediction = rf_credit.predict_proba(X_test.iloc[instance_idx:instance_idx+1])[0][1]\n",
        "\n",
        "print(f'Analyzing instance #{instance_idx}')\n",
        "print(f'\\nActual label: {\"Approved ‚úÖ\" if y_test.iloc[instance_idx] == 1 else \"Rejected ‚ùå\"}')\n",
        "print(f'Predicted probability: {prediction:.3f}')\n",
        "print(f'Base value (average): {base_value:.3f}')\n",
        "print(f'\\nFeature values:')\n",
        "for feat, val in zip(feature_names, instance_values):\n",
        "    print(f'  {feat:25} = {val:.2f}')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create custom waterfall visualization\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Sort features by absolute SHAP value\n",
        "sorted_idx = np.argsort(np.abs(shap_vals))[::-1]\n",
        "sorted_features = [feature_names[i] for i in sorted_idx]\n",
        "sorted_shap = shap_vals[sorted_idx]\n",
        "sorted_values = instance_values[sorted_idx]\n",
        "\n",
        "# Calculate cumulative sum\n",
        "cumsum = np.cumsum(sorted_shap)\n",
        "y_pos = range(len(sorted_features) + 2)  # +2 for base and final\n",
        "\n",
        "# Prepare data for waterfall\n",
        "all_labels = ['Base value'] + [f'{f}\\n= {v:.1f}' for f, v in zip(sorted_features[:10], sorted_values[:10])] + ['Final']\n",
        "all_values = [base_value] + [base_value + cumsum[i] for i in range(10)] + [prediction]\n",
        "\n",
        "# Draw waterfall\n",
        "for i in range(len(all_labels)-1):\n",
        "    start = all_values[i]\n",
        "    change = all_values[i+1] - all_values[i]\n",
        "    color = 'green' if change > 0 else 'red'\n",
        "    \n",
        "    if i == 0:  # Base value\n",
        "        ax.bar(i, all_values[i], color='lightblue', alpha=0.7, edgecolor='black', linewidth=2)\n",
        "    else:\n",
        "        ax.bar(i, abs(change), bottom=min(start, all_values[i+1]), \n",
        "               color=color, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "    \n",
        "    # Add value labels\n",
        "    ax.text(i, all_values[i+1], f'{all_values[i+1]:.3f}', \n",
        "            ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
        "\n",
        "# Final prediction bar\n",
        "ax.bar(len(all_labels)-1, prediction, color='darkblue', alpha=0.7, \n",
        "       edgecolor='black', linewidth=2)\n",
        "\n",
        "ax.set_xticks(range(len(all_labels)))\n",
        "ax.set_xticklabels(all_labels, rotation=45, ha='right', fontsize=9)\n",
        "ax.set_ylabel('Prediction Probability', fontweight='bold', fontsize=12)\n",
        "ax.set_title(f'üåä Waterfall Plot: Credit Approval Explanation (Instance #{instance_idx})',\n",
        "             fontweight='bold', fontsize=14, pad=20)\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "ax.axhline(y=0.5, color='black', linestyle='--', linewidth=1, label='Decision threshold')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation:')\n",
        "print(f'   ‚Ä¢ Started at base value: {base_value:.3f}')\n",
        "print(f'   ‚Ä¢ Green bars push UP (toward approval)')\n",
        "print(f'   ‚Ä¢ Red bars push DOWN (toward rejection)')\n",
        "print(f'   ‚Ä¢ Final prediction: {prediction:.3f} ‚Üí {\"Approved ‚úÖ\" if prediction > 0.5 else \"Rejected ‚ùå\"}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Use SHAP's built-in waterfall plot\n",
        "print('\\nüìä SHAP Built-in Waterfall Plot')\n",
        "print('=' * 70)\n",
        "\n",
        "# Create SHAP explanation object\n",
        "import shap\n",
        "\n",
        "# Get shap values for this instance\n",
        "explainer_waterfall = shap.TreeExplainer(rf_credit)\n",
        "shap_values_waterfall = explainer_waterfall(X_test.iloc[instance_idx:instance_idx+1])\n",
        "\n",
        "# Create waterfall plot\n",
        "shap.plots.waterfall(shap_values_waterfall[0], max_display=10, show=False)\n",
        "plt.title('SHAP Waterfall Plot (Built-in)', fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Built-in plot shows:')\n",
        "print('   ‚Ä¢ E[f(X)] = Expected value (base)')\n",
        "print('   ‚Ä¢ f(x) = Actual prediction')\n",
        "print('   ‚Ä¢ Features sorted by absolute impact')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 10a\n",
        "\n",
        "**Task**: Create waterfall explanations for edge cases\n",
        "\n",
        "1. Find 3 interesting instances:\n",
        "   - One with high confidence correct prediction\n",
        "   - One with low confidence (near 0.5)\n",
        "   - One misclassified instance\n",
        "2. Create waterfall plots for each\n",
        "3. Analyze:\n",
        "   - Which features drive confidence?\n",
        "   - Why was the model uncertain?\n",
        "   - What caused the misclassification?\n",
        "4. Write a short explanation for each case\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Analyze edge cases with waterfall plots\n",
        "\n",
        "# Find interesting instances\n",
        "# High confidence: prediction close to 0 or 1\n",
        "# Low confidence: prediction near 0.5\n",
        "# Misclassified: prediction != actual\n",
        "\n",
        "# Create waterfall plots and analyze\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 11: Summary Plots - Global Feature Importance\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**Summary plots** provide a **bird's-eye view** of feature importance across the entire dataset.\n",
        "\n",
        "**Key elements**:\n",
        "- üìä **Y-axis**: Features ranked by importance\n",
        "- üé® **X-axis**: SHAP value (impact on prediction)\n",
        "- üî¥ **Color**: Feature value (red = high, blue = low)\n",
        "- üìç **Dots**: Individual predictions\n",
        "\n",
        "**Insights you can extract**:\n",
        "1. **Most important features** (top of plot)\n",
        "2. **Direction of effects** (left = negative, right = positive)\n",
        "3. **Non-linear relationships** (spread of dots)\n",
        "4. **Interaction effects** (color patterns)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create comprehensive summary plot\n",
        "print('üìä SUMMARY PLOT DEMONSTRATION')\n",
        "print('=' * 70)\n",
        "\n",
        "# Calculate SHAP values for entire test set\n",
        "shap_values_summary = explainer_shap.shap_values(X_test)\n",
        "\n",
        "if isinstance(shap_values_summary, list):\n",
        "    shap_values_summary = shap_values_summary[1]  # Positive class\n",
        "\n",
        "print(f'SHAP values computed for {len(X_test)} instances')\n",
        "print(f'Shape: {shap_values_summary.shape}')\n",
        "print('\\nCreating summary plot...')\n",
        "\n",
        "# Create figure with two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
        "\n",
        "# Left: Beeswarm plot (default summary plot)\n",
        "shap.summary_plot(shap_values_summary, X_test, plot_type=\"dot\", \n",
        "                  show=False, max_display=10)\n",
        "plt.title('üêù Beeswarm Summary Plot', fontweight='bold', fontsize=14, pad=15)\n",
        "\n",
        "# Get current figure to modify\n",
        "current_fig = plt.gcf()\n",
        "current_ax = plt.gca()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create bar plot for feature importance\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Calculate mean absolute SHAP values\n",
        "mean_shap = np.abs(shap_values_summary).mean(axis=0)\n",
        "sorted_idx = np.argsort(mean_shap)\n",
        "\n",
        "# Plot\n",
        "ax.barh(range(len(sorted_idx)), mean_shap[sorted_idx], \n",
        "        color='steelblue', alpha=0.7, edgecolor='black')\n",
        "ax.set_yticks(range(len(sorted_idx)))\n",
        "ax.set_yticklabels(X_test.columns[sorted_idx], fontsize=10)\n",
        "ax.set_xlabel('Mean |SHAP value| (average impact on model output)', \n",
        "              fontweight='bold', fontsize=12)\n",
        "ax.set_title('üìä Feature Importance: Mean Absolute SHAP Values',\n",
        "             fontweight='bold', fontsize=14, pad=15)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print top features\n",
        "print('\\nüîù TOP 5 MOST IMPORTANT FEATURES')\n",
        "print('=' * 70)\n",
        "top_features = sorted_idx[-5:][::-1]\n",
        "for i, idx in enumerate(top_features, 1):\n",
        "    feat = X_test.columns[idx]\n",
        "    importance = mean_shap[idx]\n",
        "    print(f'{i}. {feat:25} ‚Üí {importance:.4f}')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Analyze feature distributions\n",
        "print('\\nüîç FEATURE DISTRIBUTION ANALYSIS')\n",
        "print('=' * 70)\n",
        "\n",
        "# Get top 3 features\n",
        "top_3 = sorted_idx[-3:][::-1]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for i, feat_idx in enumerate(top_3):\n",
        "    ax = axes[i]\n",
        "    feat_name = X_test.columns[feat_idx]\n",
        "    feat_values = X_test.iloc[:, feat_idx].values\n",
        "    feat_shap = shap_values_summary[:, feat_idx]\n",
        "    \n",
        "    # Scatter plot\n",
        "    scatter = ax.scatter(feat_values, feat_shap, c=feat_values, \n",
        "                        cmap='coolwarm', alpha=0.6, s=20, edgecolors='black', linewidth=0.5)\n",
        "    \n",
        "    # Add trend line\n",
        "    z = np.polyfit(feat_values, feat_shap, 2)\n",
        "    p = np.poly1d(z)\n",
        "    x_smooth = np.linspace(feat_values.min(), feat_values.max(), 100)\n",
        "    ax.plot(x_smooth, p(x_smooth), 'r--', linewidth=2, label='Trend')\n",
        "    \n",
        "    ax.set_xlabel(feat_name, fontweight='bold', fontsize=11)\n",
        "    ax.set_ylabel('SHAP value', fontweight='bold', fontsize=11)\n",
        "    ax.set_title(f'Feature: {feat_name}', fontweight='bold', fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
        "    ax.legend()\n",
        "    \n",
        "    plt.colorbar(scatter, ax=ax, label='Feature value')\n",
        "\n",
        "plt.suptitle('üé® Top 3 Features: Value vs SHAP Impact', \n",
        "             fontweight='bold', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation Guide:')\n",
        "print('   ‚Ä¢ Positive slope: Higher values ‚Üí Higher prediction')\n",
        "print('   ‚Ä¢ Negative slope: Higher values ‚Üí Lower prediction')\n",
        "print('   ‚Ä¢ Curved line: Non-linear relationship')\n",
        "print('   ‚Ä¢ Scatter: Interaction effects with other features')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 11a\n",
        "\n",
        "**Task**: Compare global importance across different models\n",
        "\n",
        "1. Train 3 different models on the same data:\n",
        "   - Random Forest\n",
        "   - Gradient Boosting\n",
        "   - Logistic Regression\n",
        "2. Calculate SHAP values for each\n",
        "3. Create summary plots\n",
        "4. Compare:\n",
        "   - Do all models agree on top features?\n",
        "   - Which model shows strongest non-linearities?\n",
        "   - Are there model-specific patterns?\n",
        "5. What does this tell you about model selection?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Compare feature importance across models\n",
        "\n",
        "models_to_compare = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE),\n",
        "    'Logistic Regression': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
        "}\n",
        "\n",
        "# Train each model\n",
        "# Calculate SHAP values\n",
        "# Compare importance rankings\n",
        "# Analyze differences\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 12: Dependence Plots - Understanding Feature Effects\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**Dependence plots** show the relationship between a feature and its SHAP values.\n",
        "\n",
        "**Key questions answered**:\n",
        "1. How does feature X affect predictions?\n",
        "2. Is the relationship linear or non-linear?\n",
        "3. Does the effect depend on other features? (interaction coloring)\n",
        "\n",
        "**Elements**:\n",
        "- **X-axis**: Feature values\n",
        "- **Y-axis**: SHAP values (impact on prediction)\n",
        "- **Color**: Another feature (to show interactions)\n",
        "- **Scatter**: Individual instances\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create dependence plots for top features\n",
        "print('üîó DEPENDENCE PLOT ANALYSIS')\n",
        "print('=' * 70)\n",
        "\n",
        "# Use built-in SHAP dependence plot\n",
        "top_feature = X_test.columns[sorted_idx[-1]]\n",
        "\n",
        "print(f'Creating dependence plot for: {top_feature}')\n",
        "\n",
        "shap.dependence_plot(\n",
        "    top_feature,\n",
        "    shap_values_summary,\n",
        "    X_test,\n",
        "    interaction_index=\"auto\",  # Automatically find best interaction\n",
        "    show=False\n",
        ")\n",
        "plt.title(f'üîó Dependence Plot: {top_feature}', fontweight='bold', pad=15)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'\\nüí° Auto-detected interaction feature shown in color')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create manual dependence plot with custom interaction\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot top 4 features\n",
        "for i, feat_idx in enumerate(sorted_idx[-4:][::-1]):\n",
        "    ax = axes[i]\n",
        "    feat_name = X_test.columns[feat_idx]\n",
        "    \n",
        "    # Get feature values and SHAP values\n",
        "    feat_vals = X_test.iloc[:, feat_idx].values\n",
        "    feat_shap = shap_values_summary[:, feat_idx]\n",
        "    \n",
        "    # Find best interaction (highest correlation)\n",
        "    other_features = [j for j in range(len(X_test.columns)) if j != feat_idx]\n",
        "    correlations = []\n",
        "    for other_idx in other_features:\n",
        "        # Correlation between SHAP values and other feature\n",
        "        corr = np.corrcoef(feat_shap, X_test.iloc[:, other_idx])[0, 1]\n",
        "        correlations.append((other_idx, abs(corr)))\n",
        "    \n",
        "    best_interaction_idx = max(correlations, key=lambda x: x[1])[0]\n",
        "    interaction_name = X_test.columns[best_interaction_idx]\n",
        "    interaction_vals = X_test.iloc[:, best_interaction_idx].values\n",
        "    \n",
        "    # Create scatter plot\n",
        "    scatter = ax.scatter(feat_vals, feat_shap, c=interaction_vals,\n",
        "                        cmap='viridis', alpha=0.6, s=30, edgecolors='black', linewidth=0.5)\n",
        "    \n",
        "    # Add regression line\n",
        "    z = np.polyfit(feat_vals, feat_shap, 2)\n",
        "    p = np.poly1d(z)\n",
        "    x_line = np.linspace(feat_vals.min(), feat_vals.max(), 100)\n",
        "    ax.plot(x_line, p(x_line), 'r--', linewidth=2, alpha=0.8, label='Trend')\n",
        "    \n",
        "    ax.set_xlabel(feat_name, fontweight='bold', fontsize=11)\n",
        "    ax.set_ylabel('SHAP value', fontweight='bold', fontsize=11)\n",
        "    ax.set_title(f'{feat_name}\\n(colored by {interaction_name})',\n",
        "                 fontweight='bold', fontsize=12)\n",
        "    ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8, alpha=0.5)\n",
        "    ax.grid(alpha=0.3)\n",
        "    ax.legend()\n",
        "    \n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter, ax=ax)\n",
        "    cbar.set_label(interaction_name, rotation=270, labelpad=15)\n",
        "\n",
        "plt.suptitle('üé® Dependence Plots with Automatic Interaction Detection',\n",
        "             fontweight='bold', fontsize=16, y=1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Reading dependence plots:')\n",
        "print('   ‚Ä¢ Flat line: Feature has no effect')\n",
        "print('   ‚Ä¢ Upward slope: Positive correlation')\n",
        "print('   ‚Ä¢ Downward slope: Negative correlation')\n",
        "print('   ‚Ä¢ Curve: Non-linear relationship')\n",
        "print('   ‚Ä¢ Color gradient: Interaction effect')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 12a\n",
        "\n",
        "**Task**: Deep dive into a specific feature\n",
        "\n",
        "Choose one interesting feature from the summary plot and:\n",
        "\n",
        "1. Create its dependence plot\n",
        "2. Identify the interaction feature (color)\n",
        "3. Divide data into quartiles based on the interaction feature\n",
        "4. Create 4 separate dependence plots (one per quartile)\n",
        "5. Describe how the relationship changes across quartiles\n",
        "6. Suggest a feature engineering strategy based on findings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Deep dive into feature interactions\n",
        "\n",
        "# Select a feature to analyze\n",
        "feature_to_analyze = X_test.columns[sorted_idx[-1]]\n",
        "\n",
        "# Create dependence plot\n",
        "\n",
        "# Find interaction feature\n",
        "\n",
        "# Split by interaction quartiles\n",
        "\n",
        "# Create 4 plots showing relationship in each quartile\n",
        "\n",
        "# Analyze and interpret\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 13: Decision Plots - Comparing Multiple Instances\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**Decision plots** show the cumulative effect of features for multiple instances.\n",
        "\n",
        "**Perfect for**:\n",
        "- Comparing similar instances with different predictions\n",
        "- Understanding why two loans got different decisions\n",
        "- Debugging edge cases\n",
        "\n",
        "**Elements**:\n",
        "- **Y-axis**: Features (in order)\n",
        "- **X-axis**: Cumulative SHAP value\n",
        "- **Lines**: Different instances\n",
        "- **Base**: Expected value ‚Üí Final prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create decision plot for contrasting instances\n",
        "print('üìä DECISION PLOT: COMPARING INSTANCES')\n",
        "print('=' * 70)\n",
        "\n",
        "# Find two contrasting instances: one approved, one rejected\n",
        "approved_idx = X_test[y_test == 1].index[0]\n",
        "rejected_idx = X_test[y_test == 0].index[0]\n",
        "\n",
        "# Get their positions in X_test\n",
        "approved_pos = X_test.index.get_loc(approved_idx)\n",
        "rejected_pos = X_test.index.get_loc(rejected_idx)\n",
        "\n",
        "print(f'Comparing two instances:')\n",
        "print(f'  Instance A (Approved): index {approved_pos}')\n",
        "print(f'  Instance B (Rejected): index {rejected_pos}')\n",
        "\n",
        "# Get SHAP values for these instances\n",
        "comparison_shap = shap_values_summary[[approved_pos, rejected_pos], :]\n",
        "\n",
        "# Show feature values\n",
        "print('\\nFeature Values Comparison:')\n",
        "print('-' * 70)\n",
        "print(f'{\"Feature\":<25} {\"Approved\":<15} {\"Rejected\":<15} {\"Difference\"}')\n",
        "print('-' * 70)\n",
        "\n",
        "for feat in X_test.columns:\n",
        "    val_approved = X_test.loc[approved_idx, feat]\n",
        "    val_rejected = X_test.loc[rejected_idx, feat]\n",
        "    diff = val_approved - val_rejected\n",
        "    print(f'{feat:<25} {val_approved:<15.2f} {val_rejected:<15.2f} {diff:+.2f}')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create custom decision plot\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "# Calculate cumulative SHAP values\n",
        "base = explainer_shap.expected_value\n",
        "if isinstance(base, list):\n",
        "    base = base[1]\n",
        "\n",
        "# Sort features by importance for approved instance\n",
        "feat_importance = np.abs(comparison_shap[0])\n",
        "sorted_feat_idx = np.argsort(feat_importance)\n",
        "\n",
        "# Prepare data\n",
        "features_ordered = X_test.columns[sorted_feat_idx]\n",
        "approved_cumsum = np.cumsum(comparison_shap[0][sorted_feat_idx])\n",
        "rejected_cumsum = np.cumsum(comparison_shap[1][sorted_feat_idx])\n",
        "\n",
        "# Add base value\n",
        "approved_full = np.concatenate([[base], base + approved_cumsum])\n",
        "rejected_full = np.concatenate([[base], base + rejected_cumsum])\n",
        "\n",
        "y_positions = range(len(features_ordered) + 1)\n",
        "\n",
        "# Plot lines\n",
        "ax.plot(approved_full, y_positions, 'g-', linewidth=2.5, marker='o', \n",
        "        markersize=6, label='Approved ‚úÖ', alpha=0.8)\n",
        "ax.plot(rejected_full, y_positions, 'r-', linewidth=2.5, marker='o',\n",
        "        markersize=6, label='Rejected ‚ùå', alpha=0.8)\n",
        "\n",
        "# Add feature labels\n",
        "ax.set_yticks(y_positions)\n",
        "ax.set_yticklabels(['Base value'] + features_ordered.tolist(), fontsize=10)\n",
        "\n",
        "# Style\n",
        "ax.set_xlabel('Cumulative SHAP value ‚Üí Prediction', fontweight='bold', fontsize=12)\n",
        "ax.set_title('üéØ Decision Plot: How Features Accumulate to Final Prediction',\n",
        "             fontweight='bold', fontsize=14, pad=20)\n",
        "ax.axvline(x=0.5, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Decision boundary')\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "ax.legend(loc='best', fontsize=11)\n",
        "\n",
        "# Add final predictions as text\n",
        "ax.text(approved_full[-1], len(y_positions)-1, f' {approved_full[-1]:.3f}', \n",
        "        va='center', fontweight='bold', color='green', fontsize=10)\n",
        "ax.text(rejected_full[-1], len(y_positions)-1, f' {rejected_full[-1]:.3f}',\n",
        "        va='center', fontweight='bold', color='red', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation:')\n",
        "print('   ‚Ä¢ Lines show cumulative effect of features')\n",
        "print('   ‚Ä¢ Divergence points show where decisions differ')\n",
        "print('   ‚Ä¢ Final positions are predicted probabilities')\n",
        "print('   ‚Ä¢ Features contributing most have biggest slopes')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 13a\n",
        "\n",
        "**Task**: Find and explain the most controversial decision\n",
        "\n",
        "1. Find instances where the model was very confident but WRONG\n",
        "2. Compare them with correctly classified similar instances\n",
        "3. Use decision plots to show:\n",
        "   - Where the predictions diverge\n",
        "   - Which features led to the wrong decision\n",
        "4. Propose ways to improve the model based on findings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Analyze controversial/wrong predictions\n",
        "\n",
        "# Find misclassified instances with high confidence\n",
        "predictions = rf_credit.predict_proba(X_test)[:, 1]\n",
        "misclassified = X_test[rf_credit.predict(X_test) != y_test]\n",
        "\n",
        "# Sort by confidence\n",
        "# Find similar correct predictions\n",
        "# Compare with decision plots\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üß† Part 4: Advanced XAI Techniques for Deep Learning\n",
        "\n",
        "## Beyond SHAP: Specialized Methods for Neural Networks\n",
        "\n",
        "While SHAP is powerful and general, deep learning has inspired specialized explanation methods:\n",
        "\n",
        "| Method | Type | Best For |\n",
        "|--------|------|----------|\n",
        "| **Attention** | Architecture-based | Transformers, seq2seq models |\n",
        "| **Saliency Maps** | Gradient-based | CNNs, image classification |\n",
        "| **Integrated Gradients** | Gradient-based | Any differentiable model |\n",
        "| **GradCAM** | Gradient + Activation | CNNs, localization |\n",
        "| **Layer-wise Relevance** | Backpropagation | Deep networks |\n",
        "\n",
        "### üéØ When to Use What\n",
        "\n",
        "```\n",
        "Image Classification ‚Üí GradCAM or Saliency Maps\n",
        "Text/NLP ‚Üí Attention Mechanisms\n",
        "Tabular Deep Learning ‚Üí SHAP or Integrated Gradients\n",
        "Time Series ‚Üí Attention + SHAP\n",
        "Multi-modal ‚Üí Combination of methods\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 14: Attention as Explanation\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**Attention mechanisms** in neural networks naturally provide interpretability.\n",
        "\n",
        "**Key idea**:\n",
        "- Model learns to \"focus\" on important inputs\n",
        "- Attention weights show what the model pays attention to\n",
        "- High attention = high importance (usually)\n",
        "\n",
        "**Applications**:\n",
        "- üìù **NLP**: Which words matter for sentiment?\n",
        "- üñºÔ∏è **Vision**: Which image regions are relevant?\n",
        "- ‚è∞ **Time series**: Which past timesteps influence prediction?\n",
        "\n",
        "**Caveat**: Attention weights ‚â† explanations (but strong correlation)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simulate attention mechanism\n",
        "print('üîç ATTENTION MECHANISM SIMULATION')\n",
        "print('=' * 70)\n",
        "\n",
        "# Create synthetic time series data\n",
        "np.random.seed(RANDOM_STATE)\n",
        "n_samples = 100\n",
        "sequence_length = 20\n",
        "\n",
        "# Generate sequences where last 5 timesteps are most important\n",
        "X_seq = np.random.randn(n_samples, sequence_length)\n",
        "# Add signal to last 5 timesteps\n",
        "X_seq[:, -5:] += np.random.randn(n_samples, 5) * 2\n",
        "\n",
        "# Target depends mainly on last 5 timesteps\n",
        "y_seq = np.sum(X_seq[:, -5:], axis=1)\n",
        "y_seq = (y_seq > 0).astype(int)\n",
        "\n",
        "print(f'Generated sequential data:')\n",
        "print(f'  Samples: {n_samples}')\n",
        "print(f'  Sequence length: {sequence_length}')\n",
        "print(f'  Important timesteps: last 5')\n",
        "print(f'  Target distribution: {np.mean(y_seq):.2%} positive')\n",
        "\n",
        "# Simple attention simulation using correlation\n",
        "attention_weights = np.zeros(sequence_length)\n",
        "for t in range(sequence_length):\n",
        "    # Attention = correlation with target\n",
        "    correlation = np.corrcoef(X_seq[:, t], y_seq)[0, 1]\n",
        "    attention_weights[t] = abs(correlation)\n",
        "\n",
        "# Normalize\n",
        "attention_weights = attention_weights / attention_weights.sum()\n",
        "\n",
        "print('\\n‚úÖ Attention weights computed (based on correlation)')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize attention weights\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "# Top: Attention weights over time\n",
        "timesteps = range(1, sequence_length + 1)\n",
        "bars = ax1.bar(timesteps, attention_weights, color='skyblue', \n",
        "               alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# Highlight important region\n",
        "for i in range(sequence_length - 5, sequence_length):\n",
        "    bars[i].set_color('coral')\n",
        "    bars[i].set_alpha(0.9)\n",
        "\n",
        "ax1.set_xlabel('Timestep', fontweight='bold', fontsize=12)\n",
        "ax1.set_ylabel('Attention Weight', fontweight='bold', fontsize=12)\n",
        "ax1.set_title('üéØ Attention Weights Over Sequence', fontweight='bold', fontsize=14)\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "ax1.legend(['Early timesteps', 'Important timesteps (last 5)'], loc='upper left')\n",
        "\n",
        "# Bottom: Heatmap of sample sequences with attention\n",
        "n_display = 10\n",
        "display_data = X_seq[:n_display]\n",
        "\n",
        "im = ax2.imshow(display_data, aspect='auto', cmap='RdBu_r', vmin=-3, vmax=3)\n",
        "\n",
        "# Add attention overlay\n",
        "for t in range(sequence_length):\n",
        "    for s in range(n_display):\n",
        "        alpha = attention_weights[t] * 3  # Scale for visibility\n",
        "        ax2.add_patch(plt.Rectangle((t-0.5, s-0.5), 1, 1, \n",
        "                                    fill=False, edgecolor='yellow', \n",
        "                                    linewidth=alpha*5, alpha=min(alpha, 1)))\n",
        "\n",
        "ax2.set_xlabel('Timestep', fontweight='bold', fontsize=12)\n",
        "ax2.set_ylabel('Sample', fontweight='bold', fontsize=12)\n",
        "ax2.set_title('üìä Sequence Data with Attention Overlay (yellow=high attention)',\n",
        "              fontweight='bold', fontsize=14)\n",
        "\n",
        "plt.colorbar(im, ax=ax2, label='Value')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation:')\n",
        "print('   ‚Ä¢ Attention correctly focuses on last 5 timesteps')\n",
        "print('   ‚Ä¢ Yellow borders show where model \"looks\"')\n",
        "print('   ‚Ä¢ This is how Transformers and RNNs explain themselves')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 14a\n",
        "\n",
        "**Task**: Implement attention for text sentiment analysis\n",
        "\n",
        "1. Create synthetic \"sentences\" (sequences of word embeddings)\n",
        "2. Make some positions more predictive of sentiment\n",
        "3. Calculate attention weights\n",
        "4. Visualize which \"words\" the model attends to\n",
        "5. Compare with SHAP values on the same data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Attention mechanism for text\n",
        "\n",
        "# Create synthetic word sequences\n",
        "vocab_size = 100\n",
        "embedding_dim = 10\n",
        "sentence_length = 15\n",
        "\n",
        "# Generate data where certain positions indicate sentiment\n",
        "\n",
        "# Calculate attention weights\n",
        "\n",
        "# Compare with SHAP\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 15: Saliency Maps and Integrated Gradients\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**Saliency Maps** use gradients to identify important input features.\n",
        "\n",
        "**Core formula**:\n",
        "```\n",
        "Saliency(x) = |‚àÇf/‚àÇx|\n",
        "```\n",
        "\n",
        "**Integrated Gradients** improve this:\n",
        "```\n",
        "IG(x) = (x - x') √ó ‚à´‚ÇÄ¬π ‚àÇf/‚àÇxÃÑ dŒ±\n",
        "```\n",
        "\n",
        "Where:\n",
        "- x = input\n",
        "- x' = baseline (typically zeros)\n",
        "- Integral computed over path from x' to x\n",
        "\n",
        "**Advantages**:\n",
        "- ‚ö° Fast (single backward pass)\n",
        "- üéØ Highlights input regions\n",
        "- ‚úÖ Satisfies axioms (completeness, sensitivity)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simulate gradient-based attribution\n",
        "print('üé® GRADIENT-BASED ATTRIBUTION SIMULATION')\n",
        "print('=' * 70)\n",
        "\n",
        "# Create synthetic image-like data (simplified)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "img_size = 28\n",
        "n_images = 100\n",
        "\n",
        "# Generate images with a pattern in the center\n",
        "images = np.random.randn(n_images, img_size, img_size) * 0.1\n",
        "\n",
        "# Add signal in center region\n",
        "center = img_size // 2\n",
        "radius = 5\n",
        "\n",
        "for i in range(n_images):\n",
        "    # Create pattern in center\n",
        "    for y in range(center-radius, center+radius):\n",
        "        for x in range(center-radius, center+radius):\n",
        "            if (y-center)**2 + (x-center)**2 <= radius**2:\n",
        "                images[i, y, x] += np.random.randn() * 2\n",
        "\n",
        "# Target based on center region\n",
        "y_img = (images[:, center-radius:center+radius, center-radius:center+radius].mean(axis=(1,2)) > 0).astype(int)\n",
        "\n",
        "print(f'Generated image data:')\n",
        "print(f'  Samples: {n_images}')\n",
        "print(f'  Image size: {img_size}x{img_size}')\n",
        "print(f'  Important region: Center ({radius*2}x{radius*2})')\n",
        "print(f'  Target distribution: {np.mean(y_img):.2%} positive')\n",
        "\n",
        "# Simulate gradient-based saliency\n",
        "# In real CNNs: saliency = |‚àÇL/‚àÇx|\n",
        "# Here: simulate with importance map\n",
        "\n",
        "# Calculate correlation of each pixel with target\n",
        "saliency_map = np.zeros((img_size, img_size))\n",
        "for y in range(img_size):\n",
        "    for x in range(img_size):\n",
        "        pixel_values = images[:, y, x]\n",
        "        correlation = np.corrcoef(pixel_values, y_img)[0, 1]\n",
        "        saliency_map[y, x] = abs(correlation)\n",
        "\n",
        "# Normalize\n",
        "saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
        "\n",
        "print('\\n‚úÖ Saliency map computed')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize saliency maps\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# Top row: Sample images\n",
        "for i in range(3):\n",
        "    ax = axes[0, i]\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title(f'Image {i+1}\\nLabel: {\"+\" if y_img[i] else \"-\"}', \n",
        "                 fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "# Bottom row: Saliency maps overlaid\n",
        "for i in range(3):\n",
        "    ax = axes[1, i]\n",
        "    \n",
        "    # Show image in grayscale\n",
        "    ax.imshow(images[i], cmap='gray', alpha=0.5)\n",
        "    \n",
        "    # Overlay saliency map\n",
        "    saliency_overlay = ax.imshow(saliency_map, cmap='hot', alpha=0.6, vmin=0, vmax=1)\n",
        "    \n",
        "    ax.set_title(f'Saliency Map {i+1}', fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "# Add colorbar\n",
        "cbar = plt.colorbar(saliency_overlay, ax=axes[1, :], orientation='horizontal', \n",
        "                   fraction=0.046, pad=0.04)\n",
        "cbar.set_label('Saliency (Higher = More Important)', fontweight='bold')\n",
        "\n",
        "plt.suptitle('üé® Gradient-based Saliency Maps', fontweight='bold', fontsize=16, y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation:')\n",
        "print('   ‚Ä¢ Bright regions (yellow/white) are most important')\n",
        "print('   ‚Ä¢ Center region correctly identified as important')\n",
        "print('   ‚Ä¢ This is how CNNs explain image classifications')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Integrated Gradients simulation\n",
        "print('\\nüî¨ INTEGRATED GRADIENTS SIMULATION')\n",
        "print('=' * 70)\n",
        "\n",
        "# For a single image, compute integrated gradient\n",
        "sample_img = images[0]\n",
        "baseline = np.zeros_like(sample_img)\n",
        "\n",
        "# Steps along path\n",
        "n_steps = 50\n",
        "alphas = np.linspace(0, 1, n_steps)\n",
        "\n",
        "# Interpolated images\n",
        "interpolated = np.array([baseline + alpha * (sample_img - baseline) for alpha in alphas])\n",
        "\n",
        "print(f'Computing integrated gradient:')\n",
        "print(f'  Steps: {n_steps}')\n",
        "print(f'  Path: baseline (zeros) ‚Üí actual image')\n",
        "\n",
        "# Simulate gradient at each step (using correlation with target as proxy)\n",
        "integrated_grad = np.zeros_like(sample_img)\n",
        "\n",
        "for y in range(img_size):\n",
        "    for x in range(img_size):\n",
        "        # Average gradient along path\n",
        "        grads = []\n",
        "        for step_img in interpolated:\n",
        "            # Simulate: gradient ‚âà importance\n",
        "            grad = saliency_map[y, x]\n",
        "            grads.append(grad)\n",
        "        \n",
        "        # Integrated gradient = (x - baseline) * average gradient\n",
        "        integrated_grad[y, x] = (sample_img[y, x] - baseline[y, x]) * np.mean(grads)\n",
        "\n",
        "# Normalize\n",
        "integrated_grad = np.abs(integrated_grad)\n",
        "integrated_grad = (integrated_grad - integrated_grad.min()) / (integrated_grad.max() - integrated_grad.min() + 1e-10)\n",
        "\n",
        "print('\\n‚úÖ Integrated gradients computed')\n",
        "print('=' * 70)\n",
        "\n",
        "# Visualize\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Original image\n",
        "ax1.imshow(sample_img, cmap='gray')\n",
        "ax1.set_title('Original Image', fontweight='bold')\n",
        "ax1.axis('off')\n",
        "\n",
        "# Saliency map\n",
        "ax2.imshow(sample_img, cmap='gray', alpha=0.5)\n",
        "im2 = ax2.imshow(saliency_map, cmap='hot', alpha=0.6)\n",
        "ax2.set_title('Saliency Map', fontweight='bold')\n",
        "ax2.axis('off')\n",
        "plt.colorbar(im2, ax=ax2, fraction=0.046)\n",
        "\n",
        "# Integrated gradients\n",
        "ax3.imshow(sample_img, cmap='gray', alpha=0.5)\n",
        "im3 = ax3.imshow(integrated_grad, cmap='hot', alpha=0.6)\n",
        "ax3.set_title('Integrated Gradients', fontweight='bold')\n",
        "ax3.axis('off')\n",
        "plt.colorbar(im3, ax=ax3, fraction=0.046)\n",
        "\n",
        "plt.suptitle('üî¨ Comparison: Saliency vs Integrated Gradients', \n",
        "             fontweight='bold', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Key Difference:')\n",
        "print('   ‚Ä¢ Saliency: Single gradient at input')\n",
        "print('   ‚Ä¢ Integrated Gradients: Average gradient along path')\n",
        "print('   ‚Ä¢ IG is more stable and satisfies axioms')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 15a\n",
        "\n",
        "**Task**: Apply gradient methods to real data\n",
        "\n",
        "Using our credit approval model:\n",
        "\n",
        "1. Calculate feature gradients for a specific prediction\n",
        "2. Compare with SHAP values\n",
        "3. Analyze:\n",
        "   - Do gradients and SHAP agree on important features?\n",
        "   - What are the pros/cons of each method?\n",
        "   - When would you use gradients over SHAP?\n",
        "4. For non-differentiable features (like categorical), how would you adapt?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR CODE HERE\n",
        "# TODO: Apply gradient methods to credit data\n",
        "\n",
        "# Hint: For tree models, approximate gradients using:\n",
        "# - Small perturbations (numerical gradient)\n",
        "# - Local linear approximation\n",
        "\n",
        "# Compare with TreeSHAP\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 16: GradCAM - Where Does the Model Look?\n",
        "\n",
        "### üìñ Concept\n",
        "\n",
        "**GradCAM** (Gradient-weighted Class Activation Mapping) localizes important regions in images.\n",
        "\n",
        "**How it works**:\n",
        "1. Forward pass through network\n",
        "2. Backward pass to get gradients\n",
        "3. Weight feature maps by gradients\n",
        "4. Generate heatmap of important regions\n",
        "\n",
        "**Formula**:\n",
        "```\n",
        "L_GradCAM = ReLU(Œ£ Œ±k √ó Ak)\n",
        "\n",
        "where Œ±k = (1/Z) √ó Œ£(‚àÇy/‚àÇAk)\n",
        "```\n",
        "\n",
        "**Evolution**:\n",
        "- CAM (2016): Requires GAP layer\n",
        "- GradCAM (2017): Works with any CNN\n",
        "- GradCAM++ (2018): Better for multiple objects\n",
        "- ScoreCAM (2020): No gradients needed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simulate GradCAM concept\n",
        "print('üéØ GRADCAM SIMULATION')\n",
        "print('=' * 70)\n",
        "\n",
        "# Use our synthetic images from before\n",
        "# Simulate conv layer activation maps\n",
        "\n",
        "# Create \"feature maps\" (simplified)\n",
        "n_feature_maps = 5\n",
        "feature_maps = []\n",
        "\n",
        "for f in range(n_feature_maps):\n",
        "    # Each feature map detects different pattern\n",
        "    fmap = np.random.randn(img_size//2, img_size//2)\n",
        "    \n",
        "    # Make one feature map focus on center\n",
        "    if f == 2:  # \"center detector\"\n",
        "        center_half = (img_size//2) // 2\n",
        "        fmap[center_half-3:center_half+3, center_half-3:center_half+3] += 2\n",
        "    \n",
        "    feature_maps.append(fmap)\n",
        "\n",
        "# Simulate gradients (importance of each feature map)\n",
        "gradients = np.array([0.2, 0.3, 0.8, 0.1, 0.2])  # Feature map 2 is most important\n",
        "\n",
        "print(f'Simulated CNN layers:')\n",
        "print(f'  Feature maps: {n_feature_maps}')\n",
        "print(f'  Feature map size: {img_size//2}x{img_size//2}')\n",
        "print(f'  Gradients (importance): {gradients}')\n",
        "\n",
        "# Compute GradCAM\n",
        "gradcam = np.zeros((img_size//2, img_size//2))\n",
        "for f in range(n_feature_maps):\n",
        "    gradcam += gradients[f] * feature_maps[f]\n",
        "\n",
        "# Apply ReLU\n",
        "gradcam = np.maximum(gradcam, 0)\n",
        "\n",
        "# Normalize\n",
        "gradcam = (gradcam - gradcam.min()) / (gradcam.max() - gradcam.min())\n",
        "\n",
        "# Upsample to original size\n",
        "from scipy import ndimage\n",
        "gradcam_upsampled = ndimage.zoom(gradcam, 2, order=1)\n",
        "\n",
        "print('\\n‚úÖ GradCAM heatmap generated')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize GradCAM\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "# Top row: Feature maps\n",
        "for i in range(3):\n",
        "    ax = axes[0, i]\n",
        "    im = ax.imshow(feature_maps[i], cmap='viridis')\n",
        "    ax.set_title(f'Feature Map {i+1}\\nImportance: {gradients[i]:.2f}',\n",
        "                 fontweight='bold')\n",
        "    ax.axis('off')\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046)\n",
        "\n",
        "# Bottom left: Original image\n",
        "axes[1, 0].imshow(images[0], cmap='gray')\n",
        "axes[1, 0].set_title('Original Image', fontweight='bold')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "# Bottom middle: GradCAM heatmap\n",
        "im = axes[1, 1].imshow(gradcam_upsampled, cmap='jet')\n",
        "axes[1, 1].set_title('GradCAM Heatmap', fontweight='bold')\n",
        "axes[1, 1].axis('off')\n",
        "plt.colorbar(im, ax=axes[1, 1], fraction=0.046)\n",
        "\n",
        "# Bottom right: Overlay\n",
        "axes[1, 2].imshow(images[0], cmap='gray', alpha=0.7)\n",
        "axes[1, 2].imshow(gradcam_upsampled, cmap='jet', alpha=0.5)\n",
        "axes[1, 2].set_title('GradCAM Overlay', fontweight='bold')\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.suptitle('üéØ GradCAM: Visual Explanation for CNN', \n",
        "             fontweight='bold', fontsize=16, y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nüí° Interpretation:')\n",
        "print('   ‚Ä¢ Red/yellow regions: Where model focuses')\n",
        "print('   ‚Ä¢ Blue regions: Less important')\n",
        "print('   ‚Ä¢ Overlay shows important areas on original image')\n",
        "print('   ‚Ä¢ Useful for debugging: Is model looking at right place?')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úèÔ∏è Your Turn: Exercise 16a\n",
        "\n",
        "**Task**: Understand GradCAM applications\n",
        "\n",
        "Research and summarize:\n",
        "\n",
        "1. **Medical Imaging**: How is GradCAM used to explain disease diagnosis?\n",
        "2. **Autonomous Driving**: How does it help understand what the car \"sees\"?\n",
        "3. **Quality Control**: Applications in manufacturing defect detection\n",
        "4. **Limitations**: When does GradCAM fail or mislead?\n",
        "5. **Alternatives**: Compare with other visualization methods (Saliency, LIME for images)\n",
        "\n",
        "Prepare a short presentation (5 slides) on one application.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# YOUR RESEARCH HERE\n",
        "# TODO: Research GradCAM applications\n",
        "\n",
        "# Ideas:\n",
        "# - Find examples online\n",
        "# - Try implementing on a pre-trained model\n",
        "# - Compare with other methods\n",
        "# - Document use cases\n",
        "\n",
        "# Present findings as markdown\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# üéØ Part 5: Real-World Application & Best Practices\n",
        "\n",
        "## Exercise 17: End-to-End Explainability Pipeline\n",
        "\n",
        "### üìñ Scenario: Credit Approval System\n",
        "\n",
        "You're deploying a credit approval model. **Requirements**:\n",
        "\n",
        "1. **Accuracy**: Model must perform well\n",
        "2. **Explainability**: Every decision must be explainable\n",
        "3. **Fairness**: Check for discriminatory patterns\n",
        "4. **Compliance**: Meet regulatory requirements\n",
        "5. **Usability**: Non-technical staff should understand\n",
        "\n",
        "Let's build a complete explainability pipeline!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Complete explainability pipeline\n",
        "print('üèóÔ∏è BUILDING COMPLETE XAI PIPELINE')\n",
        "print('=' * 70)\n",
        "\n",
        "# Step 1: Train model\n",
        "print('\\nüìä Step 1: Model Training')\n",
        "print('-' * 70)\n",
        "\n",
        "X = credit_df.drop('Approved', axis=1)\n",
        "y = credit_df['Approved']\n",
        "\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# Train final model\n",
        "final_model = RandomForestClassifier(n_estimators=200, max_depth=8, \n",
        "                                     min_samples_leaf=10, random_state=RANDOM_STATE)\n",
        "final_model.fit(X_train_full, y_train_full)\n",
        "\n",
        "train_acc = final_model.score(X_train_full, y_train_full)\n",
        "test_acc = final_model.score(X_test_full, y_test_full)\n",
        "\n",
        "print(f'‚úÖ Model trained')\n",
        "print(f'   Training accuracy: {train_acc:.3f}')\n",
        "print(f'   Test accuracy: {test_acc:.3f}')\n",
        "\n",
        "# Step 2: Global explainability\n",
        "print('\\nüåç Step 2: Global Explainability Analysis')\n",
        "print('-' * 70)\n",
        "\n",
        "explainer_final = shap.TreeExplainer(final_model)\n",
        "shap_values_final = explainer_final.shap_values(X_test_full)\n",
        "\n",
        "if isinstance(shap_values_final, list):\n",
        "    shap_values_final = shap_values_final[1]\n",
        "\n",
        "# Feature importance\n",
        "mean_abs_shap_final = np.abs(shap_values_final).mean(axis=0)\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': mean_abs_shap_final\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print('\\nüîù Top 5 Most Important Features:')\n",
        "for idx, row in feature_importance_df.head(5).iterrows():\n",
        "    print(f'   {row[\"Feature\"]:25} ‚Üí {row[\"Importance\"]:.4f}')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 3: Create explanation function\n",
        "print('\\nüîç Step 3: Individual Explanation Function')\n",
        "print('-' * 70)\n",
        "\n",
        "def explain_prediction(instance_idx, model, explainer, X_data, y_data):\n",
        "    \"\"\"\n",
        "    Generate comprehensive explanation for a single prediction.\n",
        "    \n",
        "    Returns: dict with explanation components\n",
        "    \"\"\"\n",
        "    # Get instance\n",
        "    instance = X_data.iloc[instance_idx:instance_idx+1]\n",
        "    actual_label = y_data.iloc[instance_idx]\n",
        "    \n",
        "    # Prediction\n",
        "    prediction_proba = model.predict_proba(instance)[0][1]\n",
        "    prediction_label = 1 if prediction_proba >= 0.5 else 0\n",
        "    \n",
        "    # SHAP values\n",
        "    shap_vals = explainer.shap_values(instance)\n",
        "    if isinstance(shap_vals, list):\n",
        "        shap_vals = shap_vals[1][0]\n",
        "    else:\n",
        "        shap_vals = shap_vals[0]\n",
        "    \n",
        "    # Base value\n",
        "    base_value = explainer.expected_value\n",
        "    if isinstance(base_value, list):\n",
        "        base_value = base_value[1]\n",
        "    \n",
        "    # Feature contributions\n",
        "    contributions = pd.DataFrame({\n",
        "        'Feature': X_data.columns,\n",
        "        'Value': instance.values[0],\n",
        "        'SHAP': shap_vals,\n",
        "        'Abs_SHAP': np.abs(shap_vals)\n",
        "    }).sort_values('Abs_SHAP', ascending=False)\n",
        "    \n",
        "    return {\n",
        "        'instance_idx': instance_idx,\n",
        "        'prediction': prediction_label,\n",
        "        'probability': prediction_proba,\n",
        "        'actual': actual_label,\n",
        "        'correct': prediction_label == actual_label,\n",
        "        'base_value': base_value,\n",
        "        'contributions': contributions,\n",
        "        'shap_values': shap_vals\n",
        "    }\n",
        "\n",
        "# Test the function\n",
        "test_idx = 42\n",
        "explanation = explain_prediction(test_idx, final_model, explainer_final, \n",
        "                                X_test_full, y_test_full)\n",
        "\n",
        "print(f'‚úÖ Explanation generated for instance {test_idx}')\n",
        "print(f'\\nüìã Prediction Report:')\n",
        "print(f'   Actual: {\"Approved\" if explanation[\"actual\"] else \"Rejected\"}')\n",
        "print(f'   Predicted: {\"Approved\" if explanation[\"prediction\"] else \"Rejected\"}')\n",
        "print(f'   Probability: {explanation[\"probability\"]:.1%}')\n",
        "print(f'   Correct: {explanation[\"correct\"]}')\n",
        "\n",
        "print(f'\\nüéØ Top 3 Contributing Features:')\n",
        "for idx, row in explanation['contributions'].head(3).iterrows():\n",
        "    direction = \"‚Üë Increases\" if row['SHAP'] > 0 else \"‚Üì Decreases\"\n",
        "    print(f'   ‚Ä¢ {row[\"Feature\"]:20} = {row[\"Value\"]:7.2f} ‚Üí {direction} approval by {abs(row[\"SHAP\"]):.3f}')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 4: Batch explanation for rejected applications\n",
        "print('\\n‚ùå Step 4: Analyzing Rejected Applications')\n",
        "print('=' * 70)\n",
        "\n",
        "# Find rejected predictions\n",
        "predictions_full = final_model.predict(X_test_full)\n",
        "rejected_mask = predictions_full == 0\n",
        "rejected_indices = X_test_full[rejected_mask].index\n",
        "\n",
        "print(f'Rejected applications: {rejected_mask.sum()} out of {len(X_test_full)}')\n",
        "\n",
        "# Analyze top reasons for rejection\n",
        "rejected_shap = shap_values_final[rejected_mask]\n",
        "mean_rejected_contributions = np.abs(rejected_shap).mean(axis=0)\n",
        "\n",
        "rejection_reasons = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Avg_Impact': mean_rejected_contributions\n",
        "}).sort_values('Avg_Impact', ascending=False)\n",
        "\n",
        "print('\\nüîù Top Rejection Factors:')\n",
        "for idx, row in rejection_reasons.head(5).iterrows():\n",
        "    print(f'   {idx+1}. {row[\"Feature\"]:25} ‚Üí Avg impact: {row[\"Avg_Impact\"]:.4f}')\n",
        "\n",
        "# Find common patterns\n",
        "print('\\nüìä Common Patterns in Rejected Applications:')\n",
        "for feat in rejection_reasons.head(3)['Feature']:\n",
        "    feat_values_rejected = X_test_full.loc[rejected_indices, feat]\n",
        "    print(f'   {feat:25}: Mean={feat_values_rejected.mean():.2f}, Std={feat_values_rejected.std():.2f}')\n",
        "\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 5: Create comprehensive report\n",
        "print('\\nüìÑ Step 5: Generate Explanation Report')\n",
        "print('=' * 70)\n",
        "\n",
        "# Select diverse examples\n",
        "sample_approved = X_test_full[(predictions_full == 1) & (y_test_full == 1)].index[0]\n",
        "sample_rejected = X_test_full[(predictions_full == 0) & (y_test_full == 0)].index[0]\n",
        "sample_false_positive = X_test_full[(predictions_full == 1) & (y_test_full == 0)].index[0] if any((predictions_full == 1) & (y_test_full == 0)) else None\n",
        "sample_false_negative = X_test_full[(predictions_full == 0) & (y_test_full == 1)].index[0] if any((predictions_full == 0) & (y_test_full == 1)) else None\n",
        "\n",
        "samples_to_explain = {\n",
        "    'Correct Approval': sample_approved,\n",
        "    'Correct Rejection': sample_rejected,\n",
        "    'False Positive': sample_false_positive,\n",
        "    'False Negative': sample_false_negative\n",
        "}\n",
        "\n",
        "# Generate explanations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (case_name, sample_idx) in enumerate(samples_to_explain.items()):\n",
        "    if sample_idx is None:\n",
        "        axes[idx].text(0.5, 0.5, f'{case_name}\\nNo examples found', \n",
        "                      ha='center', va='center', fontsize=14)\n",
        "        axes[idx].axis('off')\n",
        "        continue\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # Get explanation\n",
        "    expl = explain_prediction(X_test_full.index.get_loc(sample_idx), \n",
        "                             final_model, explainer_final, \n",
        "                             X_test_full, y_test_full)\n",
        "    \n",
        "    # Plot waterfall-style\n",
        "    top_feats = expl['contributions'].head(7)\n",
        "    y_pos = range(len(top_feats))\n",
        "    colors = ['green' if x > 0 else 'red' for x in top_feats['SHAP']]\n",
        "    \n",
        "    ax.barh(y_pos, top_feats['SHAP'], color=colors, alpha=0.7, edgecolor='black')\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels([f'{row[\"Feature\"]}\\n={row[\"Value\"]:.1f}' \n",
        "                        for _, row in top_feats.iterrows()], fontsize=9)\n",
        "    ax.set_xlabel('SHAP Value (impact on approval)', fontweight='bold')\n",
        "    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # Title with case info\n",
        "    status = \"‚úÖ\" if expl['correct'] else \"‚ùå\"\n",
        "    title = f'{case_name} {status}\\nProbability: {expl[\"probability\"]:.1%}'\n",
        "    ax.set_title(title, fontweight='bold', fontsize=11)\n",
        "\n",
        "plt.suptitle('üìä Comprehensive Explanation Report: Diverse Cases',\n",
        "             fontweight='bold', fontsize=16, y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\n‚úÖ Explanation report generated for all case types')\n",
        "print('=' * 70)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üí° Best Practices Summary\n",
        "\n",
        "#### 1. **Model Selection**\n",
        "- ‚úÖ Choose TreeSHAP for tree-based models (fast & exact)\n",
        "- ‚úÖ Use KernelSHAP for black-box models (slower but universal)\n",
        "- ‚úÖ Consider interpretable models (logistic regression, decision trees) when possible\n",
        "\n",
        "#### 2. **Explanation Quality**\n",
        "- ‚úÖ Verify explanations make domain sense\n",
        "- ‚úÖ Check consistency across similar instances\n",
        "- ‚úÖ Compare with feature importance from other methods\n",
        "\n",
        "#### 3. **Communication**\n",
        "- ‚úÖ Use waterfall plots for individual decisions\n",
        "- ‚úÖ Use summary plots for overall model behavior\n",
        "- ‚úÖ Tailor explanations to audience (technical vs non-technical)\n",
        "\n",
        "#### 4. **Fairness & Bias**\n",
        "- ‚úÖ Check SHAP values across protected groups\n",
        "- ‚úÖ Identify discriminatory patterns\n",
        "- ‚úÖ Use explanations to debug bias\n",
        "\n",
        "#### 5. **Production Deployment**\n",
        "- ‚úÖ Pre-compute explanations for common scenarios\n",
        "- ‚úÖ Cache SHAP values for frequently queried instances\n",
        "- ‚úÖ Monitor explanation drift over time\n",
        "- ‚úÖ Provide explanation APIs alongside predictions\n",
        "\n",
        "#### 6. **Common Pitfalls to Avoid**\n",
        "- ‚ùå Don't rely solely on feature importance (use instance-level too)\n",
        "- ‚ùå Don't ignore base values in waterfall plots\n",
        "- ‚ùå Don't assume correlation = causation\n",
        "- ‚ùå Don't forget to validate explanations with domain experts\n",
        "- ‚ùå Don't use overly complex visualizations for stakeholders\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Final Summary\n",
        "\n",
        "### What We've Learned\n",
        "\n",
        "1. **SHAP Fundamentals** (Part 1)\n",
        "   - Shapley values from game theory\n",
        "   - Mathematical properties and guarantees\n",
        "   - SHAP vs LIME comparison\n",
        "\n",
        "2. **Implementation Methods** (Part 2)\n",
        "   - TreeSHAP for tree-based models\n",
        "   - KernelSHAP for any model\n",
        "   - DeepSHAP for neural networks\n",
        "   - GradientSHAP for differentiable models\n",
        "   - Interaction values\n",
        "\n",
        "3. **Visualizations** (Part 3)\n",
        "   - Waterfall plots for single predictions\n",
        "   - Summary plots for global importance\n",
        "   - Dependence plots for feature effects\n",
        "   - Decision plots for comparisons\n",
        "\n",
        "4. **Advanced Techniques** (Part 4)\n",
        "   - Attention mechanisms\n",
        "   - Saliency maps\n",
        "   - Integrated gradients\n",
        "   - GradCAM for CNNs\n",
        "\n",
        "5. **Real-World Application** (Part 5)\n",
        "   - End-to-end explainability pipeline\n",
        "   - Best practices\n",
        "   - Common pitfalls\n",
        "\n",
        "### üìö Further Resources\n",
        "\n",
        "**Papers**:\n",
        "- Lundberg & Lee (2017): \"A Unified Approach to Interpreting Model Predictions\"\n",
        "- Ribeiro et al. (2016): \"Why Should I Trust You?\"\n",
        "- Selvaraju et al. (2017): \"Grad-CAM\"\n",
        "\n",
        "**Libraries**:\n",
        "- SHAP: https://github.com/slundberg/shap\n",
        "- LIME: https://github.com/marcotcr/lime\n",
        "- Captum (PyTorch): https://captum.ai/\n",
        "- Alibi: https://github.com/SeldonIO/alibi\n",
        "\n",
        "**Books**:\n",
        "- \"Interpretable Machine Learning\" by Christoph Molnar\n",
        "- \"Explanatory Model Analysis\" by Biecek & Burzykowski\n",
        "\n",
        "### ‚úèÔ∏è Final Exercise\n",
        "\n",
        "**Task**: Create Your Own XAI Dashboard\n",
        "\n",
        "Build an interactive explanation dashboard for any model:\n",
        "\n",
        "1. Train a model on a dataset of your choice\n",
        "2. Implement:\n",
        "   - Global feature importance\n",
        "   - Instance-level explanations\n",
        "   - What-if analysis (change features, see prediction change)\n",
        "   - Fairness analysis across groups\n",
        "3. Use Plotly or Streamlit for interactivity\n",
        "4. Add export functionality (PDF reports)\n",
        "5. Document:\n",
        "   - How to use the dashboard\n",
        "   - Interpretation guidelines\n",
        "   - Limitations and caveats\n",
        "\n",
        "**Deliverables**:\n",
        "- Python code\n",
        "- Sample report\n",
        "- 5-minute demo video\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ Congratulations!\n",
        "\n",
        "You've completed the comprehensive SHAP & XAI tutorial!\n",
        "\n",
        "**Next Steps**:\n",
        "1. Apply SHAP to your own projects\n",
        "2. Experiment with different explainers\n",
        "3. Contribute to open-source XAI tools\n",
        "4. Stay updated with latest research\n",
        "\n",
        "**Questions?** Contact: homin.park@ghent.ac.kr\n",
        "\n",
        "**Feedback?** Let us know how to improve this tutorial!\n",
        "\n",
        "---\n",
        "\n",
        "### üìù Quick Reference Cheat Sheet\n",
        "\n",
        "```python\n",
        "# TreeSHAP (for Random Forest, XGBoost, etc.)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "# KernelSHAP (for any model)\n",
        "explainer = shap.KernelExplainer(model.predict, background_data)\n",
        "shap_values = explainer.shap_values(X, nsamples=100)\n",
        "\n",
        "# Visualizations\n",
        "shap.waterfall_plot(shap_values[0])  # Single instance\n",
        "shap.summary_plot(shap_values, X)     # Global overview\n",
        "shap.dependence_plot(\"feature\", shap_values, X)  # Feature effect\n",
        "\n",
        "# Verify local accuracy\n",
        "base_value + shap_values.sum() ‚âà model.predict(x)\n",
        "```\n",
        "\n",
        "**Remember**: Explainability is not just about algorithms‚Äîit's about communication!\n",
        "\n",
        "---\n",
        "\n",
        "*This tutorial was created with ‚ù§Ô∏è for the AI/ML community. Please share and adapt as needed!*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}