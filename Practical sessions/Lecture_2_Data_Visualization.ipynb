{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Data Visualization Practice: Grammar of Graphics and Practical EDA\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand and practice Grammar of Graphics concepts\n",
    "- Master various chart types and their applications\n",
    "- Perform EDA with real data\n",
    "- Implement interactive visualizations\n",
    "- Create dashboard-style comprehensive visualizations\n",
    "\n",
    "## Practice Structure (Total 10 Labs)\n",
    "### Part A: Grammar of Graphics Fundamentals\n",
    "1. Core Concepts of Grammar of Graphics\n",
    "2. Scales and Coordinate Transformations\n",
    "3. Faceting and Small Multiples\n",
    "\n",
    "### Part B: Practical EDA Visualizations\n",
    "4. Univariate Analysis - Exploring Distributions\n",
    "5. Bivariate Relationships - Discovering Correlations\n",
    "6. Categorical Data - Comparisons and Compositions\n",
    "7. Time Series Analysis - Trends and Patterns\n",
    "\n",
    "### Part C: Advanced Visualization Techniques\n",
    "8. Interactive Visualizations - Using Plotly\n",
    "9. Geographic Data Visualization\n",
    "10. Dashboard-Style Comprehensive Visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0. Environment Setup and Library Imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required libraries (if needed)\n# !pip install pandas numpy matplotlib seaborn plotly scipy scikit-learn\n\n# Basic libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization style settings\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 12\nplt.rcParams['axes.unicode_minus'] = False\n\nprint('âœ… Libraries loaded successfully!')\nprint(f'Pandas version: {pd.__version__}')\nprint(f'NumPy version: {np.__version__}')\nprint(f'Seaborn version: {sns.__version__}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part A: Grammar of Graphics Fundamentals\n",
    "\n",
    "Grammar of Graphics is a visualization theory proposed by Leland Wilkinson that approaches visualization systematically by breaking it down into components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1: Core Concepts of Grammar of Graphics ğŸ¨\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Key components of Grammar of Graphics:\n",
    "- **Data**: The data to be visualized\n",
    "- **Aesthetics (aes)**: Mapping data to visual properties (x, y, color, size, etc.)\n",
    "- **Geometries (geom)**: Geometric objects (points, lines, bars, etc.)\n",
    "- **Scales**: Transform data values to visual values\n",
    "- **Facets**: Data partitioning and conditional plots\n",
    "- **Themes**: Visual styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare data\niris = sns.load_dataset('iris')\nprint(\"ğŸ“Š Iris Dataset Structure:\")\nprint(iris.head())\nprint(f\"\\nData size: {iris.shape}\")\nprint(f\"Species types: {iris['species'].unique()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Building layers in Grammar of Graphics style\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# 1. Data + Aesthetics only\nax1 = axes[0]\nax1.set_xlim(iris['sepal_length'].min()-0.5, iris['sepal_length'].max()+0.5)\nax1.set_ylim(iris['sepal_width'].min()-0.5, iris['sepal_width'].max()+0.5)\nax1.set_xlabel('Sepal Length')\nax1.set_ylabel('Sepal Width')\nax1.set_title('1. Data + Aesthetics (axes only)')\nax1.grid(True, alpha=0.3)\n\n# 2. + Geometry (add points)\nax2 = axes[1]\nax2.scatter(iris['sepal_length'], iris['sepal_width'], alpha=0.6)\nax2.set_xlabel('Sepal Length')\nax2.set_ylabel('Sepal Width')\nax2.set_title('2. + Geometry (add points)')\nax2.grid(True, alpha=0.3)\n\n# 3. + Color Aesthetic (color by species)\nax3 = axes[2]\nfor species in iris['species'].unique():\n    data = iris[iris['species'] == species]\n    ax3.scatter(data['sepal_length'], data['sepal_width'], \n               label=species, alpha=0.6, s=50)\nax3.set_xlabel('Sepal Length')\nax3.set_ylabel('Sepal Width')\nax3.set_title('3. + Color Aesthetic (by species)')\nax3.legend()\nax3.grid(True, alpha=0.3)\n\nplt.suptitle('Grammar of Graphics: Layer-by-Layer Construction', fontsize=16, y=1.02)\nplt.tight_layout()\nplt.show()\n\nprint(\"ğŸ’¡ Analysis Points:\")\nprint(\"- Visualization becomes richer by adding layers one by one\")\nprint(\"- Species clusters become clearly visible when color aesthetic is added\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Scales and Coordinate Transformations ğŸ“\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "- **Scale Transformations**: Make data patterns more visible through linear, log, square root, and other transformations\n",
    "- **Coordinate Systems**: Coordinate system transformations such as Cartesian and polar coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate exponential distribution data\nnp.random.seed(42)\nexponential_data = pd.DataFrame({\n    'x': np.linspace(1, 100, 100),\n    'y': np.exp(np.linspace(0, 5, 100)) + np.random.normal(0, 50, 100),\n    'category': np.repeat(['A', 'B', 'C', 'D', 'E'], 20)\n})\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# 1. Linear scale\naxes[0,0].scatter(exponential_data['x'], exponential_data['y'], alpha=0.6)\naxes[0,0].set_title('Linear Scale')\naxes[0,0].set_xlabel('X')\naxes[0,0].set_ylabel('Y')\naxes[0,0].grid(True, alpha=0.3)\n\n# 2. Y-axis log scale\naxes[0,1].scatter(exponential_data['x'], exponential_data['y'], alpha=0.6, color='orange')\naxes[0,1].set_yscale('log')\naxes[0,1].set_title('Log Scale Y-axis')\naxes[0,1].set_xlabel('X')\naxes[0,1].set_ylabel('Y (log scale)')\naxes[0,1].grid(True, alpha=0.3)\n\n# 3. Both axes log scale\naxes[1,0].scatter(exponential_data['x'], np.abs(exponential_data['y']), alpha=0.6, color='green')\naxes[1,0].set_xscale('log')\naxes[1,0].set_yscale('log')\naxes[1,0].set_title('Log-Log Scale')\naxes[1,0].set_xlabel('X (log scale)')\naxes[1,0].set_ylabel('Y (log scale)')\naxes[1,0].grid(True, alpha=0.3)\n\n# 4. Square root scale\naxes[1,1].scatter(exponential_data['x'], np.sqrt(np.abs(exponential_data['y'])), \n                 alpha=0.6, color='red')\naxes[1,1].set_title('Square Root Transform')\naxes[1,1].set_xlabel('X')\naxes[1,1].set_ylabel('sqrt(Y)')\naxes[1,1].grid(True, alpha=0.3)\n\nplt.suptitle('Effects of Scale Transformations', fontsize=16)\nplt.tight_layout()\nplt.show()\n\nprint(\"ğŸ’¡ When to use scale transformations:\")\nprint(\"- Log scale: Exponential growth/decay patterns, data spanning multiple orders of magnitude\")\nprint(\"- Square root transform: When variance is proportional to the mean\")\nprint(\"- Log-log: Identifying power law relationships\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3: Faceting and Small Multiples ğŸ”²\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Faceting is a technique of dividing one dataset into multiple subsets and displaying each in a separate panel.\n",
    "- **facet_wrap**: Arrange panels in a 1D array\n",
    "- **facet_grid**: Arrange panels in a 2D grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Faceting with Seaborn\ntips = sns.load_dataset('tips')\n\nprint(\"ğŸ½ï¸ Tips Dataset:\")\nprint(tips.head())\nprint(f\"\\nColumns: {tips.columns.tolist()}\")\nprint(f\"Data size: {tips.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Facet Grid: Visualize by day and time\ng = sns.FacetGrid(tips, col='time', row='day', height=3, aspect=1.2)\ng.map(sns.scatterplot, 'total_bill', 'tip', alpha=0.6)\ng.add_legend()\ng.fig.suptitle('Tips by Day and Time - Facet Grid', y=1.02, fontsize=14)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Faceting advantages:\")\nprint(\"- Easy comparison across multiple conditions\")\nprint(\"- Identify patterns in each subgroup\")\nprint(\"- Prevent overplotting\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# FacetGrid with different plots\ng = sns.FacetGrid(tips, col='day', col_wrap=2, height=4)\ng.map_dataframe(sns.histplot, x='total_bill', bins=15, kde=True)\ng.set_axis_labels('Total Bill', 'Count')\ng.fig.suptitle('Total Bill Distribution by Day of Week', y=1.02, fontsize=14)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Each day's distribution shows:\")\nfor day in tips['day'].unique():\n    avg_bill = tips[tips['day']==day]['total_bill'].mean()\n    print(f\"- {day}: Average bill ${avg_bill:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part B: Practical EDA Visualizations\n",
    "\n",
    "Exploratory Data Analysis (EDA) is the process of discovering patterns, anomalies, and insights in data through visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4: Univariate Analysis - Exploring Distributions ğŸ“ˆ\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Univariate analysis examines the characteristics of a single variable:\n",
    "- **Distribution shape**: Normal, skewed, bimodal\n",
    "- **Central tendency**: Mean, median, mode\n",
    "- **Spread**: Range, variance, standard deviation\n",
    "- **Outliers**: Extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate various distribution data\nnp.random.seed(42)\ndist_data = pd.DataFrame({\n    'normal': np.random.normal(100, 15, 1000),\n    'skewed': np.random.exponential(2, 1000),\n    'bimodal': np.concatenate([np.random.normal(50, 10, 500), \n                               np.random.normal(80, 10, 500)]),\n    'uniform': np.random.uniform(0, 100, 1000)\n})\n\nprint(\"ğŸ“Š Distribution Data Statistics:\")\nprint(dist_data.describe())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Distribution visualization: Multiple approaches\nfig, axes = plt.subplots(2, 4, figsize=(16, 8))\n\nfor idx, col in enumerate(dist_data.columns):\n    # Histogram + KDE\n    axes[0, idx].hist(dist_data[col], bins=30, alpha=0.7, edgecolor='black')\n    axes[0, idx].set_title(f'{col.capitalize()} - Histogram')\n    axes[0, idx].set_xlabel('Value')\n    axes[0, idx].set_ylabel('Frequency')\n    \n    # Box plot\n    axes[1, idx].boxplot(dist_data[col], vert=True)\n    axes[1, idx].set_title(f'{col.capitalize()} - Box Plot')\n    axes[1, idx].set_ylabel('Value')\n    axes[1, idx].grid(axis='y', alpha=0.3)\n\nplt.suptitle('Univariate Distribution Analysis - Multiple Views', fontsize=16, y=1.00)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Distribution characteristics:\")\nprint(\"- Normal: Symmetric bell curve\")\nprint(\"- Skewed: Long tail on one side\")\nprint(\"- Bimodal: Two distinct peaks\")\nprint(\"- Uniform: Evenly distributed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Violin plot: Combine box plot and distribution\nfig, ax = plt.subplots(figsize=(12, 6))\ndist_data_melted = dist_data.melt(var_name='Distribution', value_name='Value')\nsns.violinplot(data=dist_data_melted, x='Distribution', y='Value', ax=ax)\nax.set_title('Distribution Comparison - Violin Plot', fontsize=14)\nax.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Violin plot shows:\")\nprint(\"- Width represents frequency at each value\")\nprint(\"- Box plot information (quartiles) included\")\nprint(\"- Easy to compare multiple distributions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Bivariate Relationships - Discovering Correlations ğŸ”—\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Bivariate analysis examines the relationship between two variables:\n",
    "- **Correlation**: Strength and direction of linear relationships\n",
    "- **Patterns**: Linear, nonlinear, clustered\n",
    "- **Dependencies**: How one variable affects another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate bivariate relationship data\nnp.random.seed(42)\nn = 200\n\nbivar_data = pd.DataFrame({\n    'x': np.linspace(0, 10, n),\n    'linear_pos': np.linspace(0, 10, n) * 2 + np.random.normal(0, 2, n),\n    'linear_neg': -np.linspace(0, 10, n) * 1.5 + np.random.normal(0, 2, n),\n    'quadratic': (np.linspace(0, 10, n) - 5)**2 + np.random.normal(0, 3, n),\n    'no_correlation': np.random.normal(0, 5, n)\n})\n\nprint(\"ğŸ“Š Bivariate Data Correlations:\")\nprint(bivar_data.corr()[['linear_pos', 'linear_neg', 'quadratic', 'no_correlation']].loc['x'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Scatter plot matrix\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Positive correlation\naxes[0,0].scatter(bivar_data['x'], bivar_data['linear_pos'], alpha=0.6, color='blue')\naxes[0,0].set_title('Positive Linear Correlation')\naxes[0,0].set_xlabel('X')\naxes[0,0].set_ylabel('Y')\naxes[0,0].grid(True, alpha=0.3)\nr_pos = bivar_data[['x', 'linear_pos']].corr().iloc[0,1]\naxes[0,0].text(0.05, 0.95, f'r = {r_pos:.3f}', transform=axes[0,0].transAxes, \n              verticalalignment='top', fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# Negative correlation\naxes[0,1].scatter(bivar_data['x'], bivar_data['linear_neg'], alpha=0.6, color='red')\naxes[0,1].set_title('Negative Linear Correlation')\naxes[0,1].set_xlabel('X')\naxes[0,1].set_ylabel('Y')\naxes[0,1].grid(True, alpha=0.3)\nr_neg = bivar_data[['x', 'linear_neg']].corr().iloc[0,1]\naxes[0,1].text(0.05, 0.95, f'r = {r_neg:.3f}', transform=axes[0,1].transAxes,\n              verticalalignment='top', fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# Nonlinear relationship\naxes[1,0].scatter(bivar_data['x'], bivar_data['quadratic'], alpha=0.6, color='green')\naxes[1,0].set_title('Nonlinear Relationship (Quadratic)')\naxes[1,0].set_xlabel('X')\naxes[1,0].set_ylabel('Y')\naxes[1,0].grid(True, alpha=0.3)\nr_quad = bivar_data[['x', 'quadratic']].corr().iloc[0,1]\naxes[1,0].text(0.05, 0.95, f'r = {r_quad:.3f}\\n(Linear correlation low)', \n              transform=axes[1,0].transAxes, verticalalignment='top', fontsize=12,\n              bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# No correlation\naxes[1,1].scatter(bivar_data['x'], bivar_data['no_correlation'], alpha=0.6, color='purple')\naxes[1,1].set_title('No Correlation')\naxes[1,1].set_xlabel('X')\naxes[1,1].set_ylabel('Y')\naxes[1,1].grid(True, alpha=0.3)\nr_no = bivar_data[['x', 'no_correlation']].corr().iloc[0,1]\naxes[1,1].text(0.05, 0.95, f'r = {r_no:.3f}', transform=axes[1,1].transAxes,\n              verticalalignment='top', fontsize=12, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\nplt.suptitle('Types of Bivariate Relationships', fontsize=16)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Correlation coefficient interpretation:\")\nprint(\"- r = 1: Perfect positive correlation\")\nprint(\"- r = 0: No linear correlation\")\nprint(\"- r = -1: Perfect negative correlation\")\nprint(\"- Note: Correlation only measures LINEAR relationships!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Correlation heatmap\niris_numeric = iris.select_dtypes(include=[np.number])\ncorr_matrix = iris_numeric.corr()\n\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax)\nax.set_title('Iris Dataset - Correlation Matrix', fontsize=14, pad=20)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Strong correlations in Iris dataset:\")\nfor i in range(len(corr_matrix.columns)):\n    for j in range(i+1, len(corr_matrix.columns)):\n        if abs(corr_matrix.iloc[i,j]) > 0.8:\n            print(f\"- {corr_matrix.columns[i]} â†” {corr_matrix.columns[j]}: {corr_matrix.iloc[i,j]:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 6: Categorical Data - Comparisons and Compositions ğŸ“Š\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Categorical data visualization focuses on:\n",
    "- **Comparisons**: Comparing values across groups\n",
    "- **Distributions**: Distribution within each category\n",
    "- **Compositions**: Proportions and parts-to-whole relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use Tips dataset for categorical analysis\nprint(\"ğŸ“Š Categorical Variables in Tips Dataset:\")\nprint(f\"- day: {tips['day'].unique()}\")\nprint(f\"- time: {tips['time'].unique()}\")\nprint(f\"- sex: {tips['sex'].unique()}\")\nprint(f\"- smoker: {tips['smoker'].unique()}\")\nprint(f\"\\nCategory counts:\")\nprint(tips[['day', 'time', 'sex', 'smoker']].describe())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Bar charts: Compare categories\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Average tip by day\nday_avg = tips.groupby('day')['tip'].mean().sort_values()\naxes[0,0].barh(day_avg.index, day_avg.values, color='skyblue', edgecolor='black')\naxes[0,0].set_xlabel('Average Tip ($)')\naxes[0,0].set_title('Average Tip by Day of Week')\naxes[0,0].grid(axis='x', alpha=0.3)\n\n# 2. Number of customers by time and smoker status\ntime_smoker = tips.groupby(['time', 'smoker']).size().unstack()\ntime_smoker.plot(kind='bar', ax=axes[0,1], color=['salmon', 'lightgreen'])\naxes[0,1].set_title('Number of Customers by Time and Smoker Status')\naxes[0,1].set_xlabel('Time')\naxes[0,1].set_ylabel('Count')\naxes[0,1].legend(title='Smoker')\naxes[0,1].tick_params(axis='x', rotation=0)\n\n# 3. Box plot: Tip distribution by day\nsns.boxplot(data=tips, x='day', y='tip', ax=axes[1,0], palette='Set2')\naxes[1,0].set_title('Tip Distribution by Day')\naxes[1,0].set_ylabel('Tip ($)')\naxes[1,0].grid(axis='y', alpha=0.3)\n\n# 4. Stacked bar chart: Gender ratio by time\nsex_time = pd.crosstab(tips['time'], tips['sex'], normalize='index') * 100\nsex_time.plot(kind='bar', stacked=True, ax=axes[1,1], color=['#FF9999', '#66B2FF'])\naxes[1,1].set_title('Gender Ratio by Time (%)')\naxes[1,1].set_ylabel('Percentage')\naxes[1,1].set_xlabel('Time')\naxes[1,1].legend(title='Gender')\naxes[1,1].tick_params(axis='x', rotation=0)\n\nplt.suptitle('Categorical Data Analysis - Multiple Perspectives', fontsize=16, y=1.00)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Key insights:\")\nprint(f\"- Highest average tip day: {day_avg.idxmax()} (${day_avg.max():.2f})\")\nprint(f\"- Total dinner customers: {tips[tips['time']=='Dinner'].shape[0]}\")\nprint(f\"- Total lunch customers: {tips[tips['time']=='Lunch'].shape[0]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 7: Time Series Analysis - Trends and Patterns ğŸ“…\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Time series analysis identifies:\n",
    "- **Trend**: Long-term increase or decrease\n",
    "- **Seasonality**: Regular periodic patterns\n",
    "- **Volatility**: Degree of variation\n",
    "- **Anomalies**: Unusual deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate time series data\nnp.random.seed(42)\ndates = pd.date_range('2020-01-01', periods=365*3, freq='D')\n\n# Components\ntrend = np.linspace(100, 300, len(dates))\nseasonality = 50 * np.sin(np.arange(len(dates)) * 2 * np.pi / 365)\nnoise = np.random.normal(0, 10, len(dates))\n\nts_data = pd.DataFrame({\n    'date': dates,\n    'value': trend + seasonality + noise,\n    'trend': trend,\n    'seasonality': seasonality\n})\n\nprint(\"ğŸ“… Time Series Data:\")\nprint(ts_data.head())\nprint(f\"\\nDate range: {ts_data['date'].min()} to {ts_data['date'].max()}\")\nprint(f\"Data points: {len(ts_data)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Time series decomposition visualization\nfig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n\n# 1. Original series\naxes[0].plot(ts_data['date'], ts_data['value'], linewidth=1, alpha=0.8)\naxes[0].set_title('Original Time Series', fontsize=12)\naxes[0].set_ylabel('Value')\naxes[0].grid(True, alpha=0.3)\n\n# 2. Trend\naxes[1].plot(ts_data['date'], ts_data['trend'], color='red', linewidth=2)\naxes[1].set_title('Trend Component', fontsize=12)\naxes[1].set_ylabel('Trend')\naxes[1].grid(True, alpha=0.3)\n\n# 3. Seasonality\naxes[2].plot(ts_data['date'], ts_data['seasonality'], color='green', linewidth=1)\naxes[2].set_title('Seasonal Component', fontsize=12)\naxes[2].set_ylabel('Seasonality')\naxes[2].grid(True, alpha=0.3)\n\n# 4. Residuals\nresiduals = ts_data['value'] - ts_data['trend'] - ts_data['seasonality']\naxes[3].plot(ts_data['date'], residuals, color='gray', linewidth=0.5, alpha=0.7)\naxes[3].axhline(y=0, color='black', linestyle='--', linewidth=1)\naxes[3].set_title('Residual Component (Noise)', fontsize=12)\naxes[3].set_ylabel('Residuals')\naxes[3].set_xlabel('Date')\naxes[3].grid(True, alpha=0.3)\n\nplt.suptitle('Time Series Decomposition', fontsize=16, y=0.995)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Time series components:\")\nprint(f\"- Trend: Long-term direction ({ts_data['trend'].iloc[0]:.1f} â†’ {ts_data['trend'].iloc[-1]:.1f})\")\nprint(f\"- Seasonality: Yearly cycle (amplitude: {ts_data['seasonality'].max():.1f})\")\nprint(f\"- Residuals: Random variation (std: {residuals.std():.2f})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Rolling statistics\nts_data['MA_30'] = ts_data['value'].rolling(window=30).mean()\nts_data['MA_90'] = ts_data['value'].rolling(window=90).mean()\n\nfig, ax = plt.subplots(figsize=(14, 6))\nax.plot(ts_data['date'], ts_data['value'], label='Original', alpha=0.4, linewidth=1)\nax.plot(ts_data['date'], ts_data['MA_30'], label='30-day MA', linewidth=2)\nax.plot(ts_data['date'], ts_data['MA_90'], label='90-day MA', linewidth=2)\nax.set_title('Time Series with Moving Averages', fontsize=14)\nax.set_xlabel('Date')\nax.set_ylabel('Value')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ Moving averages:\")\nprint(\"- Smooth short-term fluctuations\")\nprint(\"- Highlight long-term trends\")\nprint(\"- Useful for forecasting\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part C: Advanced Visualization Techniques\n",
    "\n",
    "Advanced visualization techniques enable interactive exploration and complex data representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 8: Interactive Visualizations - Using Plotly ğŸ–±ï¸\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Interactive visualizations allow:\n",
    "- **Zooming and panning**: Detailed exploration of specific areas\n",
    "- **Hover information**: Display detailed data on mouse over\n",
    "- **Filtering**: Toggle data series on/off\n",
    "- **Animation**: Visualize changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Interactive scatter plot\nfig_scatter = px.scatter(iris, \n                        x='sepal_length', \n                        y='sepal_width',\n                        color='species',\n                        size='petal_length',\n                        hover_data=['petal_width'],\n                        title='Interactive Iris Dataset Exploration',\n                        labels={'sepal_length': 'Sepal Length (cm)',\n                               'sepal_width': 'Sepal Width (cm)',\n                               'petal_length': 'Petal Length (cm)'})\n\nfig_scatter.update_layout(\n    width=900,\n    height=600,\n    hovermode='closest'\n)\n\nfig_scatter.show()\n\nprint(\"\\nğŸ’¡ Interactive features:\")\nprint(\"â€¢ Hover over points for detailed information\")\nprint(\"â€¢ Click legend items to toggle species on/off\")\nprint(\"â€¢ Zoom by clicking and dragging\")\nprint(\"â€¢ Pan by clicking and holding\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Animated time series\nts_monthly = ts_data.copy()\nts_monthly['year'] = ts_monthly['date'].dt.year\nts_monthly['month'] = ts_monthly['date'].dt.month\nts_monthly_agg = ts_monthly.groupby(['year', 'month'])['value'].mean().reset_index()\nts_monthly_agg['date'] = pd.to_datetime(ts_monthly_agg[['year', 'month']].assign(day=1))\n\nfig_animated = px.line(ts_monthly_agg, \n                      x='date', \n                      y='value',\n                      title='Monthly Average Time Series',\n                      labels={'value': 'Average Value', 'date': 'Date'})\n\nfig_animated.update_traces(mode='lines+markers')\nfig_animated.update_layout(\n    width=900,\n    height=500,\n    xaxis_rangeslider_visible=True\n)\n\nfig_animated.show()\n\nprint(\"\\nğŸ’¡ Time series features:\")\nprint(\"â€¢ Range slider for period selection\")\nprint(\"â€¢ Zoom in to specific date ranges\")\nprint(\"â€¢ Hover for exact values\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 9: Geographic Data Visualization ğŸ—ºï¸\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Geographic visualizations help:\n",
    "- **Spatial patterns**: Identify regional trends\n",
    "- **Distributions**: Visualize geographic data spread\n",
    "- **Comparisons**: Compare regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate geographic data (US state data)\nus_states = ['California', 'Texas', 'Florida', 'New York', 'Pennsylvania',\n            'Illinois', 'Ohio', 'Georgia', 'North Carolina', 'Michigan']\n\ngeo_data = pd.DataFrame({\n    'state': us_states,\n    'code': ['CA', 'TX', 'FL', 'NY', 'PA', 'IL', 'OH', 'GA', 'NC', 'MI'],\n    'population': [39.5, 29.0, 21.5, 19.5, 12.8, 12.7, 11.7, 10.6, 10.5, 10.0],\n    'gdp_per_capita': [75000, 62000, 45000, 85000, 60000, 65000, 55000, 50000, 52000, 48000],\n    'unemployment': [4.2, 3.8, 3.5, 4.5, 4.0, 4.3, 3.9, 3.7, 3.8, 4.1]\n})\n\nprint(\"ğŸ—ºï¸ Geographic Data Sample:\")\nprint(geo_data.head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Choropleth Map\nfig_choropleth = px.choropleth(\n    geo_data,\n    locations='code',\n    locationmode='USA-states',\n    color='gdp_per_capita',\n    hover_name='state',\n    hover_data={'population': True, 'unemployment': True},\n    color_continuous_scale='Viridis',\n    title='US GDP per Capita by State',\n    labels={'gdp_per_capita': 'GDP per Capita ($)',\n           'population': 'Population (M)',\n           'unemployment': 'Unemployment (%)'}\n)\n\nfig_choropleth.update_geos(\n    scope='usa',\n    projection_type='albers usa',\n    showlakes=True,\n    lakecolor='rgb(255, 255, 255)'\n)\n\nfig_choropleth.update_layout(height=500)\nfig_choropleth.show()\n\nprint(\"\\nğŸ’¡ Geographic visualization applications:\")\nprint(\"â€¢ Regional comparisons and pattern discovery\")\nprint(\"â€¢ Spatial cluster identification\")\nprint(\"â€¢ Population/economic data representation\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10: Dashboard-Style Comprehensive Visualizations ğŸ“Š\n",
    "\n",
    "### ğŸ“š Concept Explanation\n",
    "Dashboards provide integrated insights by combining multiple charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate business KPI data\nnp.random.seed(42)\nmonths = pd.date_range('2023-01', periods=12, freq='M')\n\nkpi_data = pd.DataFrame({\n    'month': months,\n    'revenue': np.random.uniform(80, 120, 12) * 1000000,\n    'customers': np.random.uniform(8000, 12000, 12).astype(int),\n    'conversion_rate': np.random.uniform(2, 5, 12),\n    'churn_rate': np.random.uniform(5, 8, 12),\n    'nps_score': np.random.uniform(30, 70, 12)\n})\n\ndepartments = ['Sales', 'Marketing', 'Engineering', 'Support', 'Operations']\ndept_performance = pd.DataFrame({\n    'department': departments,\n    'headcount': [50, 30, 80, 25, 15],\n    'efficiency': [85, 78, 92, 88, 81],\n    'budget_used': [92, 88, 95, 78, 85]\n})\n\nprint(\"ğŸ“Š KPI Dashboard data prepared\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dashboard with Plotly Subplots\nfig = make_subplots(\n    rows=3, cols=3,\n    subplot_titles=('Monthly Revenue Trend', 'Customer Count Change', 'Conversion vs Churn',\n                   'NPS Score Trend', 'Headcount by Department', 'Department Efficiency',\n                   'YTD Performance Summary', 'Budget Utilization', 'KPI Correlation'),\n    row_heights=[0.35, 0.35, 0.3],\n    column_widths=[0.35, 0.35, 0.3],\n    specs=[[{'type': 'scatter'}, {'type': 'bar'}, {'type': 'scatter'}],\n           [{'type': 'scatter'}, {'type': 'pie'}, {'type': 'bar'}],\n           [{'type': 'indicator'}, {'type': 'bar'}, {'type': 'heatmap'}]],\n    vertical_spacing=0.12,\n    horizontal_spacing=0.10\n)\n\n# 1. Monthly revenue trend\nfig.add_trace(\n    go.Scatter(x=kpi_data['month'], y=kpi_data['revenue']/1000000,\n              mode='lines+markers', name='Revenue',\n              line=dict(color='#1f77b4', width=3),\n              marker=dict(size=8)),\n    row=1, col=1\n)\n\n# 2. Customer count change\nfig.add_trace(\n    go.Bar(x=kpi_data['month'], y=kpi_data['customers'],\n          name='Customers',\n          marker_color='#2ca02c'),\n    row=1, col=2\n)\n\n# 3. Conversion vs Churn\nfig.add_trace(\n    go.Scatter(x=kpi_data['month'], y=kpi_data['conversion_rate'],\n              mode='lines+markers', name='Conversion Rate',\n              line=dict(color='#4ECDC4', width=2)),\n    row=1, col=3\n)\nfig.add_trace(\n    go.Scatter(x=kpi_data['month'], y=kpi_data['churn_rate'],\n              mode='lines+markers', name='Churn Rate',\n              line=dict(color='#FF6B6B', width=2, dash='dash')),\n    row=1, col=3\n)\n\n# 4. NPS Score\nfig.add_trace(\n    go.Scatter(x=kpi_data['month'], y=kpi_data['nps_score'],\n              mode='lines+markers', name='NPS',\n              fill='tozeroy',\n              line=dict(color='#9467bd', width=2)),\n    row=2, col=1\n)\n\n# 5. Headcount by department (pie chart)\nfig.add_trace(\n    go.Pie(labels=dept_performance['department'],\n          values=dept_performance['headcount'],\n          hole=0.4),\n    row=2, col=2\n)\n\n# 6. Department efficiency\nfig.add_trace(\n    go.Bar(x=dept_performance['department'],\n          y=dept_performance['efficiency'],\n          marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']),\n    row=2, col=3\n)\n\n# 7. YTD performance indicator (Gauge)\nfig.add_trace(\n    go.Indicator(\n        mode = \"gauge+number+delta\",\n        value = kpi_data['revenue'].sum()/1000000,\n        title = {'text': \"YTD Revenue (M$)\"},\n        delta = {'reference': 1100},\n        gauge = {'axis': {'range': [None, 1500]},\n                'bar': {'color': \"#2ca02c\"},\n                'steps': [\n                    {'range': [0, 500], 'color': \"lightgray\"},\n                    {'range': [500, 1000], 'color': \"gray\"}],\n                'threshold': {'line': {'color': \"red\", 'width': 4},\n                            'thickness': 0.75, 'value': 1200}}),\n    row=3, col=1\n)\n\n# 8. Budget utilization\nfig.add_trace(\n    go.Bar(y=dept_performance['department'],\n          x=dept_performance['budget_used'],\n          orientation='h',\n          marker_color='#17becf'),\n    row=3, col=2\n)\n\n# 9. KPI correlation\nkpi_corr = kpi_data[['revenue', 'customers', 'conversion_rate', 'churn_rate', 'nps_score']].corr()\nfig.add_trace(\n    go.Heatmap(z=kpi_corr.values,\n              x=['Revenue', 'Customers', 'Conv Rate', 'Churn', 'NPS'],\n              y=['Revenue', 'Customers', 'Conv Rate', 'Churn', 'NPS'],\n              colorscale='RdBu',\n              zmid=0,\n              text=kpi_corr.values.round(2),\n              texttemplate='%{text}',\n              textfont={\"size\": 8}),\n    row=3, col=3\n)\n\n# Update layout\nfig.update_layout(\n    title_text=\"ğŸ“Š Business KPI Dashboard - 2023\",\n    title_font_size=20,\n    showlegend=False,\n    height=900,\n    plot_bgcolor='rgba(240,240,240,0.5)',\n    paper_bgcolor='white'\n)\n\n# Update axis labels\nfig.update_xaxes(title_text=\"Month\", row=1, col=1, tickformat='%b')\nfig.update_yaxes(title_text=\"Revenue (M$)\", row=1, col=1)\n\nfig.show()\n\nprint(\"\\nğŸ’¡ Dashboard design essentials:\")\nprint(\"â€¢ Key KPIs at a glance\")\nprint(\"â€¢ Consistent color theme and layout\")\nprint(\"â€¢ Appropriate combination of various chart types\")\nprint(\"â€¢ Interactive elements for detailed exploration\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ğŸ“ Practice Summary and Key Takeaways\n",
    "\n",
    "## What We Learned Today\n",
    "\n",
    "### Grammar of Graphics Essentials\n",
    "- Systematic approach to visualization by breaking it down into components\n",
    "- Building visualizations in a layered manner\n",
    "- Pattern discovery through scale and coordinate transformations\n",
    "- Multidimensional data exploration through faceting\n",
    "\n",
    "### Practical EDA Techniques\n",
    "- **Univariate Analysis**: Understanding distributions, outliers, and central tendencies\n",
    "- **Bivariate Analysis**: Discovering correlations and dependencies\n",
    "- **Categorical Data**: Group comparisons and compositions\n",
    "- **Time Series Analysis**: Trends, seasonality, and volatility\n",
    "\n",
    "### Advanced Visualizations\n",
    "- **Interactive Visualizations**: Dynamic exploration with Plotly\n",
    "- **Geographic Data**: Spatial pattern visualization\n",
    "- **Dashboards**: Providing integrated insights\n",
    "\n",
    "## ğŸ’ª Practice Assignments\n",
    "\n",
    "1. **Perform EDA with Your Own Data**\n",
    "   - Analyze in order: univariate â†’ bivariate â†’ multivariate\n",
    "   - Use at least 5 different visualization techniques\n",
    "\n",
    "2. **Create an Interactive Dashboard**\n",
    "   - Use real work data\n",
    "   - Add interactive elements with Plotly\n",
    "\n",
    "3. **Improve Visualizations**\n",
    "   - Reconstruct existing report charts from a Grammar of Graphics perspective\n",
    "   - Optimize color, layout, and information density\n",
    "\n",
    "## ğŸ“š Additional Learning Resources\n",
    "\n",
    "- **Book**: \"The Grammar of Graphics\" by Leland Wilkinson\n",
    "- **Online**: Plotly Official Documentation (https://plotly.com/python/)\n",
    "- **Course**: Coursera \"Applied Data Science with Python\"\n",
    "- **Practice**: Learn from EDA examples on Kaggle Notebooks\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Remember:\n",
    "> \"The purpose of visualization is insight, not pictures.\"\n",
    "> - Ben Shneiderman\n",
    "\n",
    "Good visualization tells the story hidden in data.\n",
    "Keep practicing and experimenting to develop your own style!\n",
    "\n",
    "---\n",
    "**Questions and feedback are always welcome!** ğŸ™‹â€â™‚ï¸ğŸ™‹â€â™€ï¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}