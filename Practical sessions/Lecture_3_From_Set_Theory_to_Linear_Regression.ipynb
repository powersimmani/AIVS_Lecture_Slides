{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎯 From Math to ML: 핵심 계산 실습\n\n",
    "## 목차\n",
    "1. [벡터와 내적 계산](#실습-1-벡터와-내적-계산)\n",
    "2. [행렬 연산과 변환](#실습-2-행렬-연산과-변환)\n",
    "3. [고유값과 고유벡터](#실습-3-고유값과-고유벡터)\n",
    "4. [확률분포와 샘플링](#실습-4-확률분포와-샘플링)\n",
    "5. [기댓값, 분산, 공분산 계산](#실습-5-기댓값-분산-공분산-계산)\n",
    "6. [최소제곱법 직접 구현](#실습-6-최소제곱법-직접-구현)\n",
    "7. [정규방정식 솔루션](#실습-7-정규방정식-솔루션)\n",
    "8. [단순 선형회귀 전체 구현](#실습-8-단순-선형회귀-전체-구현)\n",
    "9. [다중 선형회귀와 특성 공학](#실습-9-다중-선형회귀와-특성-공학)\n",
    "10. [모델 평가와 진단](#실습-10-모델-평가와-진단)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필수 라이브러리 설치 및 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✅ 모든 라이브러리가 성공적으로 로드되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 1: 벡터와 내적 계산\n\n",
    "### 🎯 학습 목표\n",
    "- 벡터 연산의 기초 이해\n",
    "- 내적의 기하학적 의미 파악\n",
    "- 코사인 유사도 계산 방법 학습\n\n",
    "### 📖 핵심 개념\n",
    "내적(Inner Product): $\\langle x, y \\rangle = x_1y_1 + x_2y_2 + ... + x_ny_n = ||x||||y||\\cos(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 벡터 생성 및 기본 연산\n",
    "def vector_operations():\n",
    "    \"\"\"벡터 기본 연산 실습\"\"\"\n",
    "    # 벡터 생성\n",
    "    v1 = np.array([3, 4])\n",
    "    v2 = np.array([1, 2])\n",
    "    \n",
    "    # 벡터 연산\n",
    "    addition = v1 + v2\n",
    "    scalar_mult = 2 * v1\n",
    "    \n",
    "    # 직접 내적 계산\n",
    "    dot_manual = sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "    \n",
    "    # NumPy 내적\n",
    "    dot_numpy = np.dot(v1, v2)\n",
    "    \n",
    "    print(\"벡터 v1:\", v1)\n",
    "    print(\"벡터 v2:\", v2)\n",
    "    print(\"\\n--- 연산 결과 ---\")\n",
    "    print(f\"덧셈: {addition}\")\n",
    "    print(f\"스칼라 곱: {scalar_mult}\")\n",
    "    print(f\"내적 (직접 계산): {dot_manual}\")\n",
    "    print(f\"내적 (NumPy): {dot_numpy}\")\n",
    "    print(f\"두 방법 일치: {dot_manual == dot_numpy}\")\n",
    "    \n",
    "    return v1, v2\n",
    "\n",
    "v1, v2 = vector_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 2: 행렬 연산과 변환\n\n",
    "### 🎯 학습 목표\n",
    "- 행렬 곱셈의 이해와 구현\n",
    "- 선형 변환의 시각화\n",
    "- 역행렬과 행렬식의 의미 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 행렬 곱셈 직접 구현\n",
    "def matrix_multiplication_comparison():\n",
    "    \"\"\"행렬 곱셈을 직접 구현하고 NumPy와 비교\"\"\"\n",
    "    \n",
    "    # 행렬 생성\n",
    "    A = np.array([[1, 2], [3, 4]])\n",
    "    B = np.array([[5, 6], [7, 8]])\n",
    "    \n",
    "    # 직접 구현\n",
    "    def manual_matmul(A, B):\n",
    "        rows_A, cols_A = A.shape\n",
    "        rows_B, cols_B = B.shape\n",
    "        \n",
    "        if cols_A != rows_B:\n",
    "            raise ValueError(\"행렬 크기가 맞지 않습니다\")\n",
    "        \n",
    "        C = np.zeros((rows_A, cols_B))\n",
    "        \n",
    "        for i in range(rows_A):\n",
    "            for j in range(cols_B):\n",
    "                for k in range(cols_A):\n",
    "                    C[i][j] += A[i][k] * B[k][j]\n",
    "        \n",
    "        return C\n",
    "    \n",
    "    # 계산\n",
    "    C_manual = manual_matmul(A, B)\n",
    "    C_numpy = A @ B  # NumPy 행렬 곱셈\n",
    "    \n",
    "    print(\"행렬 A:\")\n",
    "    print(A)\n",
    "    print(\"\\n행렬 B:\")\n",
    "    print(B)\n",
    "    print(\"\\n직접 구현한 A×B:\")\n",
    "    print(C_manual)\n",
    "    print(\"\\nNumPy A×B:\")\n",
    "    print(C_numpy)\n",
    "    print(f\"\\n결과 일치: {np.allclose(C_manual, C_numpy)}\")\n",
    "    \n",
    "    return A\n",
    "\n",
    "matrix_A = matrix_multiplication_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 실습 7: 정규방정식 솔루션 (핵심!)\n\n",
    "### 🎯 학습 목표\n",
    "- 정규방정식 (X^T X)^(-1) X^T y 직접 계산\n",
    "- NumPy로 효율적 구현\n",
    "- Scikit-learn과 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 정규방정식 유도 및 구현\n",
    "def normal_equation_implementation():\n",
    "    \"\"\"정규방정식을 단계별로 구현\"\"\"\n",
    "    \n",
    "    # 데이터 생성\n",
    "    np.random.seed(42)\n",
    "    n_samples = 100\n",
    "    X = np.random.randn(n_samples, 1) * 3\n",
    "    y = 2 + 3 * X + np.random.randn(n_samples, 1) * 0.5\n",
    "    \n",
    "    # Design matrix 생성 (절편 항 추가)\n",
    "    X_with_intercept = np.c_[np.ones((n_samples, 1)), X]\n",
    "    \n",
    "    print(\"정규방정식: β = (X^T X)^(-1) X^T y\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 단계별 계산\n",
    "    print(\"\\n1단계: X^T 계산\")\n",
    "    X_transpose = X_with_intercept.T\n",
    "    print(f\"   X shape: {X_with_intercept.shape}\")\n",
    "    print(f\"   X^T shape: {X_transpose.shape}\")\n",
    "    \n",
    "    print(\"\\n2단계: X^T X 계산\")\n",
    "    XtX = X_transpose @ X_with_intercept\n",
    "    print(f\"   X^T X shape: {XtX.shape}\")\n",
    "    print(f\"   X^T X:\\n{XtX}\")\n",
    "    \n",
    "    print(\"\\n3단계: (X^T X)^(-1) 계산\")\n",
    "    XtX_inv = np.linalg.inv(XtX)\n",
    "    print(f\"   (X^T X)^(-1):\\n{XtX_inv}\")\n",
    "    \n",
    "    print(\"\\n4단계: X^T y 계산\")\n",
    "    Xty = X_transpose @ y\n",
    "    print(f\"   X^T y shape: {Xty.shape}\")\n",
    "    \n",
    "    print(\"\\n5단계: β = (X^T X)^(-1) X^T y\")\n",
    "    beta = XtX_inv @ Xty\n",
    "    print(f\"   β:\\n{beta}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"최종 결과: β₀ = {beta[0, 0]:.4f}, β₁ = {beta[1, 0]:.4f}\")\n",
    "    \n",
    "    return X, y, beta\n",
    "\n",
    "X_data, y_data, beta_normal = normal_equation_implementation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 다양한 방법으로 계산 비교\n",
    "def compare_regression_methods():\n",
    "    \"\"\"정규방정식, NumPy, Scikit-learn 비교\"\"\"\n",
    "    \n",
    "    print(\"선형회귀 계산 방법 비교\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 방법 1: 정규방정식 직접 구현\n",
    "    X_with_intercept = np.c_[np.ones((len(X_data), 1)), X_data]\n",
    "    beta_manual = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ y_data\n",
    "    print(f\"\\n방법 1 - 정규방정식 직접 구현:\")\n",
    "    print(f\"  β₀ = {beta_manual[0, 0]:.6f}\")\n",
    "    print(f\"  β₁ = {beta_manual[1, 0]:.6f}\")\n",
    "    \n",
    "    # 방법 2: NumPy의 최소제곱법 (lstsq)\n",
    "    beta_numpy, residuals, rank, s = np.linalg.lstsq(X_with_intercept, y_data, rcond=None)\n",
    "    print(f\"\\n방법 2 - NumPy lstsq:\")\n",
    "    print(f\"  β₀ = {beta_numpy[0]:.6f}\")\n",
    "    print(f\"  β₁ = {beta_numpy[1]:.6f}\")\n",
    "    \n",
    "    # 방법 3: Scikit-learn\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_data, y_data)\n",
    "    print(f\"\\n방법 3 - Scikit-learn:\")\n",
    "    print(f\"  β₀ = {reg.intercept_[0]:.6f}\")\n",
    "    print(f\"  β₁ = {reg.coef_[0, 0]:.6f}\")\n",
    "    \n",
    "    # 결과 비교\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"결과 비교:\")\n",
    "    print(f\"  방법 1과 2의 차이: β₀={abs(beta_manual[0, 0] - beta_numpy[0]):.10f}, \"\n",
    "          f\"β₁={abs(beta_manual[1, 0] - beta_numpy[1]):.10f}\")\n",
    "    print(f\"  방법 1과 3의 차이: β₀={abs(beta_manual[0, 0] - reg.intercept_[0]):.10f}, \"\n",
    "          f\"β₁={abs(beta_manual[1, 0] - reg.coef_[0, 0]):.10f}\")\n",
    "    \n",
    "    print(\"\\n✅ 모든 방법이 동일한 결과를 산출합니다!\")\n",
    "    \n",
    "    return beta_manual, beta_numpy, reg\n",
    "\n",
    "beta1, beta2, sklearn_model = compare_regression_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 🎯 실습 완료!\n\n",
    "### 학습한 내용 정리:\n\n",
    "1. **벡터와 행렬 연산**: 내적, 행렬곱 등 기본 연산\n",
    "2. **정규방정식**: 해석적 해 구하기 - **(X^T X)^(-1) X^T y**\n",
    "3. **구현 vs 라이브러리**: 직접 구현과 Scikit-learn 비교\n\n",
    "### 핵심 통찰:\n",
    "- 수학적 개념이 어떻게 머신러닝으로 연결되는지 이해\n",
    "- 정규방정식은 모든 선형회귀의 기초\n",
    "- NumPy와 Scikit-learn 모두 내부적으로 같은 수학을 사용\n\n",
    "### 다음 단계:\n",
    "- 경사하강법 구현\n",
    "- 정규화 기법 (Ridge, Lasso)\n",
    "- 다중 선형회귀로 확장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}