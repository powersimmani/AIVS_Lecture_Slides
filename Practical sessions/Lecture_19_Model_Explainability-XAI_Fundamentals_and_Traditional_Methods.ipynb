{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ” Explainable AI (XAI) - Hands-on Learning Notebook\n",
        "\n",
        "## Course: Lecture 19 - Model Explainability\n",
        "\n",
        "### Learning Objectives\n",
        "\n",
        "- Understand complexity-interpretability trade-off\n",
        "- Implement intrinsically interpretable models\n",
        "- Apply feature importance methods\n",
        "- Use model-agnostic explanations (LIME, Surrogate Models)\n",
        "\n",
        "### Structure\n",
        "\n",
        "1. Setup & Data\n",
        "2. Exercise 1: Complexity vs Interpretability\n",
        "3. Exercise 2: Linear Model Interpretation\n",
        "4. Exercise 3: Decision Trees\n",
        "5. Exercise 4: Permutation Importance\n",
        "6. Exercise 5: Partial Dependence Plots\n",
        "7. Exercise 6: ICE Plots\n",
        "8. Exercise 7: Surrogate Models\n",
        "9. Exercise 8: LIME Explanations\n",
        "\n",
        "**Instructor:** Ho-min Park | homin.park@ghent.ac.kr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ”§ Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.inspection import (\n",
        "    permutation_importance,\n",
        "    PartialDependenceDisplay\n",
        ")\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "np.random.seed(42)\n",
        "print(\"âœ… Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“Š Data: Credit Risk Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create synthetic credit risk data\n",
        "np.random.seed(42)\n",
        "n = 1000\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'Age': np.random.randint(20, 71, n),\n",
        "    'Income': np.random.gamma(3, 15, n) + 20,\n",
        "    'Credit_Score': np.random.normal(650, 80, n).clip(300, 850),\n",
        "    'Debt_Ratio': np.random.beta(2, 5, n),\n",
        "    'Employment_Years': np.random.exponential(8, n).clip(0, 40),\n",
        "    'Education': np.random.choice([0, 1, 2, 3], n, p=[0.3, 0.4, 0.2, 0.1])\n",
        "})\n",
        "\n",
        "# Target: Loan approval (based on risk score)\n",
        "risk = (\n",
        "    0.3 * (data['Credit_Score'] - 300) / 550 + \n",
        "    0.2 * data['Income'] / 150 + \n",
        "    0.2 * (1 - data['Debt_Ratio']) +\n",
        "    0.15 * data['Employment_Years'] / 40 +\n",
        "    0.15 * data['Education'] / 3\n",
        ")\n",
        "\n",
        "prob = 1 / (1 + np.exp(-5 * (risk - 0.5)))\n",
        "data['Approved'] = (\n",
        "    prob + np.random.normal(0, 0.1, n) > 0.5\n",
        ").astype(int)\n",
        "\n",
        "print(f\"Dataset: {data.shape}\")\n",
        "print(f\"Approval rate: {data['Approved'].mean():.1%}\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X = data.drop('Approved', axis=1)\n",
        "y = data['Approved']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(\n",
        "    scaler.fit_transform(X_train),\n",
        "    columns=X.columns\n",
        ")\n",
        "X_test_scaled = pd.DataFrame(\n",
        "    scaler.transform(X_test),\n",
        "    columns=X.columns\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 1: Complexity vs Interpretability Trade-off\n",
        "\n",
        "### Concept\n",
        "\n",
        "- **Simple models**: High interpretability, may underfit\n",
        "- **Complex models**: High accuracy, \"black boxes\"\n",
        "\n",
        "### Task\n",
        "\n",
        "Train 4 models and visualize the trade-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Decision Tree (d=3)': DecisionTreeClassifier(max_depth=3),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
        "    'Neural Network': MLPClassifier(hidden_layer_sizes=(50,))\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    acc = accuracy_score(y_test, model.predict(X_test_scaled))\n",
        "    \n",
        "    interp = {\n",
        "        'Logistic Regression': 0.95,\n",
        "        'Decision Tree (d=3)': 0.90,\n",
        "        'Random Forest': 0.40,\n",
        "        'Neural Network': 0.20\n",
        "    }[name]\n",
        "    \n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': acc,\n",
        "        'Interpretability': interp\n",
        "    })\n",
        "    print(f\"{name}: Acc={acc:.3f}, Interp={interp:.2f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize trade-off\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i, row in results_df.iterrows():\n",
        "    plt.scatter(\n",
        "        row['Interpretability'],\n",
        "        row['Accuracy'],\n",
        "        s=200,\n",
        "        alpha=0.6\n",
        "    )\n",
        "    plt.annotate(\n",
        "        row['Model'],\n",
        "        (row['Interpretability'], row['Accuracy']),\n",
        "        xytext=(5, 5),\n",
        "        textcoords='offset points'\n",
        "    )\n",
        "\n",
        "plt.xlabel('Interpretability', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "plt.title(\n",
        "    'Model Complexity vs Interpretability Trade-off',\n",
        "    fontsize=14,\n",
        "    fontweight='bold'\n",
        ")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 2: Linear Model Interpretation\n",
        "\n",
        "### Concept\n",
        "\n",
        "Linear models: $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ...$\n",
        "\n",
        "**Interpretation**:\n",
        "\n",
        "- **Coefficient magnitude**: Feature importance\n",
        "- **Sign**: Positive/negative relationship"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train logistic regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Extract coefficients\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': lr.coef_[0]\n",
        "}).sort_values('Coefficient')\n",
        "\n",
        "print(coef_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize coefficients\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "colors = ['red' if c < 0 else 'green' for c in coef_df['Coefficient']]\n",
        "plt.barh(\n",
        "    coef_df['Feature'],\n",
        "    coef_df['Coefficient'],\n",
        "    color=colors,\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "plt.xlabel('Coefficient Value', fontweight='bold')\n",
        "plt.title('Feature Coefficients (Linear Model)', fontsize=14, fontweight='bold')\n",
        "plt.axvline(0, color='black', linestyle='--')\n",
        "plt.grid(alpha=0.3, axis='x')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3: Decision Tree Transparency\n",
        "\n",
        "### Concept\n",
        "\n",
        "Decision trees create **IF-THEN rules**:\n",
        "\n",
        "- Easy to follow logic path\n",
        "- Visualize entire tree structure\n",
        "- Extract feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train decision tree\n",
        "tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "acc = accuracy_score(y_test, tree.predict(X_test))\n",
        "print(f\"Accuracy: {acc:.3f}\")\n",
        "\n",
        "# Feature importance\n",
        "imp_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': tree.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(imp_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize tree\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "plot_tree(\n",
        "    tree,\n",
        "    feature_names=X.columns,\n",
        "    class_names=['Reject', 'Approve'],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=10\n",
        ")\n",
        "\n",
        "plt.title('Decision Tree (depth=3)', fontsize=16, fontweight='bold')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 4: Permutation Importance\n",
        "\n",
        "### Concept\n",
        "\n",
        "Measure feature importance by:\n",
        "\n",
        "1. Train model\n",
        "2. Shuffle one feature\n",
        "3. Measure performance drop\n",
        "4. Importance = baseline - shuffled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Compute permutation importance\n",
        "perm_imp = permutation_importance(\n",
        "    rf,\n",
        "    X_test,\n",
        "    y_test,\n",
        "    n_repeats=30,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "perm_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': perm_imp.importances_mean,\n",
        "    'Std': perm_imp.importances_std\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(perm_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize with error bars\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.barh(\n",
        "    perm_df['Feature'],\n",
        "    perm_df['Importance'],\n",
        "    xerr=perm_df['Std'],\n",
        "    color='steelblue',\n",
        "    alpha=0.7\n",
        ")\n",
        "\n",
        "plt.xlabel('Importance (Performance Drop)', fontweight='bold')\n",
        "plt.title('Permutation Importance', fontsize=14, fontweight='bold')\n",
        "plt.grid(alpha=0.3, axis='x')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 5: Partial Dependence Plots (PDP)\n",
        "\n",
        "### Concept\n",
        "\n",
        "PDP shows **marginal effect** of a feature:\n",
        "\n",
        "- How does prediction change as we vary the feature?\n",
        "- Reveals non-linear relationships\n",
        "- Model-agnostic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create PDP for key features\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "PartialDependenceDisplay.from_estimator(\n",
        "    rf,\n",
        "    X_train,\n",
        "    features=['Credit_Score', 'Income', 'Debt_Ratio', 'Age'],\n",
        "    kind='average',\n",
        "    n_cols=2,\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "plt.suptitle('Partial Dependence Plots', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 6: ICE (Individual Conditional Expectation) Plots\n",
        "\n",
        "### Concept\n",
        "\n",
        "ICE = PDP for **each instance separately**\n",
        "\n",
        "- Shows heterogeneity\n",
        "- Reveals subgroups\n",
        "- PDP = Average of ICE curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ICE plots\n",
        "n_samples = 50\n",
        "ice_idx = np.random.choice(X_train.index, size=n_samples, replace=False)\n",
        "X_ice = X_train.loc[ice_idx]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "PartialDependenceDisplay.from_estimator(\n",
        "    rf,\n",
        "    X_ice,\n",
        "    features=['Credit_Score', 'Income', 'Debt_Ratio', 'Age'],\n",
        "    kind='both',  # Shows both ICE and PDP\n",
        "    n_cols=2,\n",
        "    ax=ax,\n",
        "    line_kw={'alpha': 0.3},\n",
        "    pd_line_kw={'color': 'red', 'linewidth': 3}\n",
        ")\n",
        "\n",
        "plt.suptitle(\n",
        "    f'ICE Plots ({n_samples} instances) + PDP (red)',\n",
        "    fontsize=16,\n",
        "    fontweight='bold'\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 7: Surrogate Models\n",
        "\n",
        "### Concept\n",
        "\n",
        "Approximate **black-box** with **interpretable model**:\n",
        "\n",
        "**Process:**\n",
        "\n",
        "1. Train complex model (RF)\n",
        "2. Get predictions\n",
        "3. Train simple model (DT) on those predictions\n",
        "4. Interpret surrogate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train complex model\n",
        "complex_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None\n",
        ")\n",
        "complex_model.fit(X_train, y_train)\n",
        "complex_acc = accuracy_score(y_test, complex_model.predict(X_test))\n",
        "\n",
        "# Generate predictions\n",
        "y_train_pred = complex_model.predict(X_train)\n",
        "y_test_pred = complex_model.predict(X_test)\n",
        "\n",
        "# Train surrogate\n",
        "surrogate = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "surrogate.fit(X_train, y_train_pred)  # Train on complex model predictions!\n",
        "\n",
        "# Measure fidelity\n",
        "fidelity = accuracy_score(y_test_pred, surrogate.predict(X_test))\n",
        "surr_acc = accuracy_score(y_test, surrogate.predict(X_test))\n",
        "\n",
        "print(f\"Complex model accuracy: {complex_acc:.3f}\")\n",
        "print(f\"Surrogate fidelity: {fidelity:.3f} (matches black-box {fidelity*100:.0f}% of time)\")\n",
        "print(f\"Surrogate accuracy: {surr_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize surrogate\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "plot_tree(\n",
        "    surrogate,\n",
        "    feature_names=X.columns,\n",
        "    class_names=['Reject', 'Approve'],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    fontsize=10\n",
        ")\n",
        "\n",
        "plt.title(\n",
        "    f'Surrogate Model (depth=5, fidelity={fidelity:.2f})',\n",
        "    fontsize=16,\n",
        "    fontweight='bold'\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 8: LIME (Local Interpretable Model-agnostic Explanations)\n",
        "\n",
        "### Concept\n",
        "\n",
        "Explain **individual predictions**:\n",
        "\n",
        "1. Perturb instance\n",
        "2. Get black-box predictions\n",
        "3. Fit local linear model\n",
        "4. Interpret coefficients\n",
        "\n",
        "**Key**: Explains this specific instance (not global behavior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install LIME\n",
        "try:\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "except:\n",
        "    import sys\n",
        "    !{sys.executable} -m pip install lime --quiet\n",
        "    import lime\n",
        "    import lime.lime_tabular\n",
        "\n",
        "print(\"âœ… LIME ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create LIME explainer\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    np.array(X_train),\n",
        "    feature_names=X.columns.tolist(),\n",
        "    class_names=['Rejected', 'Approved'],\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "# Select instance to explain\n",
        "idx = 0\n",
        "instance = X_test.iloc[idx].values\n",
        "pred = rf.predict([instance])[0]\n",
        "prob = rf.predict_proba([instance])[0]\n",
        "\n",
        "print(f\"Instance {idx}:\")\n",
        "print(f\"Prediction: {'Approved' if pred==1 else 'Rejected'} ({prob[pred]:.1%} confidence)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate LIME explanation\n",
        "explanation = explainer.explain_instance(\n",
        "    instance,\n",
        "    rf.predict_proba,\n",
        "    num_features=6,\n",
        "    num_samples=5000\n",
        ")\n",
        "\n",
        "# Extract explanation\n",
        "exp_list = explanation.as_list()\n",
        "\n",
        "# Visualize\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "features = [e[0].split()[0] for e in exp_list]\n",
        "contrib = [e[1] for e in exp_list]\n",
        "colors = ['green' if c > 0 else 'red' for c in contrib]\n",
        "\n",
        "plt.barh(features, contrib, color=colors, alpha=0.7)\n",
        "plt.xlabel('Feature Contribution', fontweight='bold')\n",
        "plt.title(\n",
        "    f'LIME Explanation: Instance {idx}',\n",
        "    fontsize=14,\n",
        "    fontweight='bold'\n",
        ")\n",
        "plt.axvline(0, color='black', linestyle='--')\n",
        "plt.grid(alpha=0.3, axis='x')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFeature Contributions:\")\n",
        "for feat, cont in exp_list:\n",
        "    print(f\"  {feat}: {cont:+.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“š Summary\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. âœ… **Trade-off**: Complexity vs Interpretability\n",
        "2. âœ… **Linear Models**: Coefficient interpretation\n",
        "3. âœ… **Decision Trees**: IF-THEN rules, visualization\n",
        "4. âœ… **Permutation Importance**: Model-agnostic feature ranking\n",
        "5. âœ… **PDP**: Marginal feature effects\n",
        "6. âœ… **ICE**: Instance-level heterogeneity\n",
        "7. âœ… **Surrogate Models**: Approximate black-box\n",
        "8. âœ… **LIME**: Local instance explanations\n",
        "\n",
        "### Method Selection Guide\n",
        "\n",
        "- **Global explanation** â†’ Permutation Importance, PDP\n",
        "- **Local explanation** â†’ LIME, ICE\n",
        "- **Interpretable model** â†’ Linear, Decision Tree\n",
        "- **Black-box approximation** â†’ Surrogate Model\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "- Use **multiple methods**\n",
        "- Validate with **domain experts**\n",
        "- Document **limitations**\n",
        "- Match method to **audience**\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ“ Congratulations!\n",
        "\n",
        "You completed the XAI Hands-on Notebook!\n",
        "\n",
        "**Next**: Apply to your own datasets\n",
        "\n",
        "**Contact**: homin.park@ghent.ac.kr"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
