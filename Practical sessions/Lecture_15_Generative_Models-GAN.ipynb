{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ Generative Adversarial Networks (GANs) - Complete Hands-on Tutorial\n",
        "\n",
        "## Based on Lecture 15: Generative Models - GAN\n",
        "\n",
        "**Author**: Ho-min Park  \n",
        "**Email**: homin.park@ghent.ac.kr  \n",
        "**Notebook Version**: Interactive Learning Edition\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "1. Understand the mathematical foundations of GANs\n",
        "2. Implement a basic GAN from scratch\n",
        "3. Build and train DCGAN for image generation\n",
        "4. Explore advanced techniques (WGAN, Conditional GAN)\n",
        "5. Diagnose and fix common GAN training issues\n",
        "6. Apply GANs to real-world problems\n",
        "\n",
        "## üìñ Notebook Structure\n",
        "\n",
        "- **Part 1**: Introduction and Setup\n",
        "- **Part 2**: Core Concepts (Mathematical Foundations)\n",
        "- **Part 3**: Basic GAN Implementation\n",
        "- **Part 4**: DCGAN for Image Generation\n",
        "- **Part 5**: Advanced Techniques and Applications\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Introduction and Setup\n",
        "\n",
        "## 1.1 Understanding GANs - The Counterfeiter Analogy\n",
        "\n",
        "Imagine a counterfeiter (Generator) trying to create fake money and a police officer (Discriminator) trying to detect fakes:\n",
        "- **Generator (G)**: Creates fake samples that look real\n",
        "- **Discriminator (D)**: Distinguishes real from fake samples\n",
        "- **Zero-Sum Game**: They compete until fake becomes indistinguishable from real\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Essential imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output, display, HTML\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# For interactive visualizations\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "print(f'PyTorch version: {torch.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 1: Mathematical Foundation of GANs üßÆ\n",
        "\n",
        "### Concept\n",
        "\n",
        "GANs optimize a minimax objective:\n",
        "\n",
        "$$\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log(1 - D(G(z)))]$$\n",
        "\n",
        "Where:\n",
        "- $D(x)$: Discriminator's probability that $x$ is real\n",
        "- $G(z)$: Generator transforms noise $z$ into fake data\n",
        "- $p_{data}$: Real data distribution\n",
        "- $p_z$: Noise distribution (usually Gaussian)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the GAN objective function\n",
        "def visualize_gan_objective():\n",
        "    \"\"\"Visualize how the GAN objective changes during training\"\"\"\n",
        "    \n",
        "    # Create synthetic discriminator outputs\n",
        "    x = np.linspace(0, 1, 100)\n",
        "    \n",
        "    # Value function components\n",
        "    real_term = np.log(x + 1e-7)  # log D(x) for real data\n",
        "    fake_term = np.log(1 - x + 1e-7)  # log(1 - D(G(z))) for fake data\n",
        "    \n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        subplot_titles=('Discriminator Terms', 'Training Dynamics')\n",
        "    )\n",
        "    \n",
        "    # Plot value function components\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=x, y=real_term, name='Real: log D(x)', \n",
        "                   line=dict(color='blue', width=2)),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=x, y=fake_term, name='Fake: log(1-D(G(z)))',\n",
        "                   line=dict(color='red', width=2)),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # Simulate training dynamics\n",
        "    epochs = np.arange(0, 100)\n",
        "    d_loss = 0.5 * np.exp(-epochs/30) * np.sin(epochs/5) + 0.5\n",
        "    g_loss = 0.5 * np.exp(-epochs/30) * np.cos(epochs/5) + 0.5\n",
        "    \n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=d_loss, name='D Loss',\n",
        "                   line=dict(color='blue', width=2)),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=epochs, y=g_loss, name='G Loss',\n",
        "                   line=dict(color='red', width=2)),\n",
        "        row=1, col=2\n",
        "    )\n",
        "    \n",
        "    fig.update_xaxes(title_text='D(x)', row=1, col=1)\n",
        "    fig.update_xaxes(title_text='Training Epoch', row=1, col=2)\n",
        "    fig.update_yaxes(title_text='Value', row=1, col=1)\n",
        "    fig.update_yaxes(title_text='Loss', row=1, col=2)\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title='GAN Objective Function Visualization',\n",
        "        height=400,\n",
        "        showlegend=True\n",
        "    )\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Display the visualization\n",
        "fig = visualize_gan_objective()\n",
        "fig.show()\n",
        "\n",
        "print(\"üìä Key Insights:\")\n",
        "print(\"1. The discriminator maximizes its ability to distinguish real from fake\")\n",
        "print(\"2. The generator minimizes the discriminator's ability to detect fakes\")\n",
        "print(\"3. Training oscillates as both networks compete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 2: Building a Simple 1D GAN üîß\n",
        "\n",
        "### Concept\n",
        "Let's start with a simple 1D GAN that learns to generate samples from a Gaussian distribution.\n",
        "This helps understand the core mechanics without the complexity of images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Simple1D_Generator(nn.Module):\n",
        "    \"\"\"Simple generator for 1D data\"\"\"\n",
        "    def __init__(self, noise_dim=10, hidden_dim=128, output_dim=1):\n",
        "        super(Simple1D_Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(noise_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "class Simple1D_Discriminator(nn.Module):\n",
        "    \"\"\"Simple discriminator for 1D data\"\"\"\n",
        "    def __init__(self, input_dim=1, hidden_dim=128):\n",
        "        super(Simple1D_Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Training function for 1D GAN\n",
        "def train_1d_gan(n_epochs=1000, batch_size=128):\n",
        "    \"\"\"Train a simple 1D GAN to learn a Gaussian distribution\"\"\"\n",
        "    \n",
        "    # Initialize networks\n",
        "    G = Simple1D_Generator().to(device)\n",
        "    D = Simple1D_Discriminator().to(device)\n",
        "    \n",
        "    # Optimizers\n",
        "    g_optimizer = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    d_optimizer = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    \n",
        "    # Loss function\n",
        "    criterion = nn.BCELoss()\n",
        "    \n",
        "    # Target distribution: Gaussian(mean=4, std=1.5)\n",
        "    target_mean, target_std = 4.0, 1.5\n",
        "    \n",
        "    # Storage for visualization\n",
        "    generated_samples = []\n",
        "    d_losses, g_losses = [], []\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        # Generate real samples from target distribution\n",
        "        real_data = torch.randn(batch_size, 1).to(device) * target_std + target_mean\n",
        "        \n",
        "        # === Train Discriminator ===\n",
        "        d_optimizer.zero_grad()\n",
        "        \n",
        "        # Real data\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        real_output = D(real_data)\n",
        "        d_loss_real = criterion(real_output, real_labels)\n",
        "        \n",
        "        # Fake data\n",
        "        noise = torch.randn(batch_size, 10).to(device)\n",
        "        fake_data = G(noise)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        fake_output = D(fake_data.detach())\n",
        "        d_loss_fake = criterion(fake_output, fake_labels)\n",
        "        \n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        # === Train Generator ===\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        noise = torch.randn(batch_size, 10).to(device)\n",
        "        fake_data = G(noise)\n",
        "        fake_output = D(fake_data)\n",
        "        g_loss = criterion(fake_output, real_labels)  # Generator wants D to think fake is real\n",
        "        \n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        # Store results\n",
        "        d_losses.append(d_loss.item())\n",
        "        g_losses.append(g_loss.item())\n",
        "        \n",
        "        if epoch % 100 == 0:\n",
        "            with torch.no_grad():\n",
        "                test_noise = torch.randn(1000, 10).to(device)\n",
        "                samples = G(test_noise).cpu().numpy()\n",
        "                generated_samples.append(samples)\n",
        "        \n",
        "        if epoch % 200 == 0:\n",
        "            print(f'Epoch [{epoch}/{n_epochs}] D_loss: {d_loss:.4f}, G_loss: {g_loss:.4f}')\n",
        "    \n",
        "    return G, D, generated_samples, d_losses, g_losses\n",
        "\n",
        "# Train the 1D GAN\n",
        "print(\"üöÄ Training 1D GAN...\")\n",
        "G_1d, D_1d, samples_1d, d_losses_1d, g_losses_1d = train_1d_gan(n_epochs=2000)\n",
        "print(\"‚úÖ Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize 1D GAN results\n",
        "def visualize_1d_gan_results(samples, d_losses, g_losses):\n",
        "    \"\"\"Visualize the training results of 1D GAN\"\"\"\n",
        "    \n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    \n",
        "    # Plot 1: Generated distribution evolution\n",
        "    ax1 = plt.subplot(1, 3, 1)\n",
        "    target_samples = np.random.normal(4.0, 1.5, 1000)\n",
        "    \n",
        "    for i, sample in enumerate(samples[::2]):  # Show every other snapshot\n",
        "        ax1.hist(sample, bins=30, alpha=0.3, density=True, label=f'Epoch {i*200}')\n",
        "    \n",
        "    ax1.hist(target_samples, bins=30, alpha=0.5, density=True, \n",
        "             color='red', label='Target', histtype='step', linewidth=2)\n",
        "    ax1.set_xlabel('Value')\n",
        "    ax1.set_ylabel('Density')\n",
        "    ax1.set_title('Generated Distribution Evolution')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 2: Loss curves\n",
        "    ax2 = plt.subplot(1, 3, 2)\n",
        "    ax2.plot(d_losses, label='Discriminator Loss', alpha=0.7)\n",
        "    ax2.plot(g_losses, label='Generator Loss', alpha=0.7)\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.set_title('Training Losses')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Final comparison\n",
        "    ax3 = plt.subplot(1, 3, 3)\n",
        "    ax3.hist(samples[-1], bins=30, alpha=0.7, density=True, \n",
        "             color='blue', label='Generated')\n",
        "    ax3.hist(target_samples, bins=30, alpha=0.7, density=True, \n",
        "             color='red', label='Target')\n",
        "    ax3.set_xlabel('Value')\n",
        "    ax3.set_ylabel('Density')\n",
        "    ax3.set_title('Final Result Comparison')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Calculate statistics\n",
        "    final_mean = np.mean(samples[-1])\n",
        "    final_std = np.std(samples[-1])\n",
        "    print(f\"\\nüìä Final Statistics:\")\n",
        "    print(f\"Generated: mean={final_mean:.2f}, std={final_std:.2f}\")\n",
        "    print(f\"Target:    mean=4.00, std=1.50\")\n",
        "    print(f\"Error:     mean_diff={abs(final_mean-4.0):.3f}, std_diff={abs(final_std-1.5):.3f}\")\n",
        "\n",
        "visualize_1d_gan_results(samples_1d, d_losses_1d, g_losses_1d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 3: DCGAN for Image Generation üñºÔ∏è\n",
        "\n",
        "### Concept\n",
        "Deep Convolutional GAN (DCGAN) introduced architectural guidelines that made GANs stable:\n",
        "- Replace pooling with strided convolutions\n",
        "- Use batch normalization in both G and D\n",
        "- Remove fully connected hidden layers\n",
        "- Use ReLU in G (except output layer)\n",
        "- Use LeakyReLU in D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DCGAN_Generator(nn.Module):\n",
        "    \"\"\"DCGAN Generator for 64x64 images\"\"\"\n",
        "    def __init__(self, nz=100, ngf=64, nc=3):\n",
        "        super(DCGAN_Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Input: Z vector\n",
        "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf*8) x 4 x 4\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf*4) x 8 x 8\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf*2) x 16 x 16\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf) x 32 x 32\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # Output: (nc) x 64 x 64\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    \"\"\"DCGAN Discriminator for 64x64 images\"\"\"\n",
        "    def __init__(self, nc=3, ndf=64):\n",
        "        super(DCGAN_Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # Input: (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf) x 32 x 32\n",
        "            \n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf*2) x 16 x 16\n",
        "            \n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf*4) x 8 x 8\n",
        "            \n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf*8) x 4 x 4\n",
        "            \n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "            # Output: 1\n",
        "        )\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1, 1).squeeze(1)\n",
        "\n",
        "# Initialize DCGAN\n",
        "nz = 100  # Latent vector size\n",
        "ngf = 64  # Generator feature map size\n",
        "ndf = 64  # Discriminator feature map size\n",
        "nc = 1    # Number of channels (1 for grayscale, 3 for RGB)\n",
        "\n",
        "netG = DCGAN_Generator(nz, ngf, nc).to(device)\n",
        "netD = DCGAN_Discriminator(nc, ndf).to(device)\n",
        "\n",
        "# Weight initialization\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "\n",
        "print(\"‚úÖ DCGAN models initialized\")\n",
        "print(f\"Generator parameters: {sum(p.numel() for p in netG.parameters()):,}\")\n",
        "print(f\"Discriminator parameters: {sum(p.numel() for p in netD.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 4: Training DCGAN on MNIST üî¢\n",
        "\n",
        "### Concept\n",
        "We'll train DCGAN on MNIST digits to understand the training dynamics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                      download=True, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "\n",
        "print(f\"‚úÖ Loaded MNIST dataset: {len(trainset)} images\")\n",
        "print(f\"   Batch size: 64\")\n",
        "print(f\"   Number of batches: {len(dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_dcgan(netG, netD, dataloader, num_epochs=5, nz=100):\n",
        "    \"\"\"Train DCGAN on image data\"\"\"\n",
        "    \n",
        "    # Setup optimizers\n",
        "    lr = 0.0002\n",
        "    beta1 = 0.5\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    \n",
        "    # Loss function\n",
        "    criterion = nn.BCELoss()\n",
        "    \n",
        "    # Fixed noise for visualization\n",
        "    fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "    \n",
        "    # Training stats\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    img_list = []\n",
        "    \n",
        "    print(\"üöÄ Starting DCGAN Training...\")\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (data, _) in enumerate(dataloader):\n",
        "            ############################\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            ###########################\n",
        "            netD.zero_grad()\n",
        "            \n",
        "            # Train with real batch\n",
        "            real_data = data.to(device)\n",
        "            batch_size = real_data.size(0)\n",
        "            label = torch.full((batch_size,), 1., dtype=torch.float, device=device)\n",
        "            \n",
        "            output = netD(real_data)\n",
        "            errD_real = criterion(output, label)\n",
        "            errD_real.backward()\n",
        "            D_x = output.mean().item()\n",
        "            \n",
        "            # Train with fake batch\n",
        "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
        "            fake = netG(noise)\n",
        "            label.fill_(0.)\n",
        "            \n",
        "            output = netD(fake.detach())\n",
        "            errD_fake = criterion(output, label)\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output.mean().item()\n",
        "            \n",
        "            errD = errD_real + errD_fake\n",
        "            optimizerD.step()\n",
        "            \n",
        "            ############################\n",
        "            # (2) Update G network: maximize log(D(G(z)))\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            label.fill_(1.)  # Fake labels are real for generator cost\n",
        "            \n",
        "            output = netD(fake)\n",
        "            errG = criterion(output, label)\n",
        "            errG.backward()\n",
        "            D_G_z2 = output.mean().item()\n",
        "            \n",
        "            optimizerG.step()\n",
        "            \n",
        "            # Save losses\n",
        "            G_losses.append(errG.item())\n",
        "            D_losses.append(errD.item())\n",
        "            \n",
        "            # Print statistics\n",
        "            if i % 100 == 0:\n",
        "                print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] '\n",
        "                      f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
        "                      f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
        "        \n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        with torch.no_grad():\n",
        "            fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(fake)\n",
        "    \n",
        "    print(\"‚úÖ Training Complete!\")\n",
        "    return G_losses, D_losses, img_list\n",
        "\n",
        "# Train the DCGAN\n",
        "G_losses, D_losses, img_list = train_dcgan(netG, netD, dataloader, num_epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize DCGAN results\n",
        "def visualize_dcgan_results(G_losses, D_losses, img_list):\n",
        "    \"\"\"Visualize DCGAN training results\"\"\"\n",
        "    \n",
        "    fig = plt.figure(figsize=(15, 6))\n",
        "    \n",
        "    # Plot losses\n",
        "    ax1 = plt.subplot(1, 3, 1)\n",
        "    ax1.plot(G_losses, label='Generator', alpha=0.7)\n",
        "    ax1.plot(D_losses, label='Discriminator', alpha=0.7)\n",
        "    ax1.set_xlabel('Iterations')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Training Losses')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Show real images\n",
        "    ax2 = plt.subplot(1, 3, 2)\n",
        "    real_batch = next(iter(dataloader))\n",
        "    grid = make_grid(real_batch[0][:64], padding=2, normalize=True, nrow=8)\n",
        "    ax2.imshow(np.transpose(grid, (1, 2, 0)), cmap='gray')\n",
        "    ax2.set_title('Real Images')\n",
        "    ax2.axis('off')\n",
        "    \n",
        "    # Show generated images\n",
        "    ax3 = plt.subplot(1, 3, 3)\n",
        "    grid = make_grid(img_list[-1], padding=2, normalize=True, nrow=8)\n",
        "    ax3.imshow(np.transpose(grid, (1, 2, 0)), cmap='gray')\n",
        "    ax3.set_title('Generated Images')\n",
        "    ax3.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_dcgan_results(G_losses, D_losses, img_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 5: Understanding Mode Collapse üîç\n",
        "\n",
        "### Concept\n",
        "Mode collapse occurs when the generator produces limited variety of samples, failing to capture the full data distribution.\n",
        "\n",
        "Types:\n",
        "- **Partial Collapse**: Missing some modes of the data distribution\n",
        "- **Complete Collapse**: Generator produces nearly identical outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_mode_collapse(generator, n_samples=1000, nz=100):\n",
        "    \"\"\"Detect mode collapse by analyzing generated sample diversity\"\"\"\n",
        "    \n",
        "    # Generate samples\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(n_samples, nz, 1, 1, device=device)\n",
        "        generated = generator(noise).cpu().numpy()\n",
        "    \n",
        "    # Flatten images for analysis\n",
        "    generated_flat = generated.reshape(n_samples, -1)\n",
        "    \n",
        "    # Calculate pairwise distances\n",
        "    from scipy.spatial.distance import pdist, squareform\n",
        "    distances = pdist(generated_flat, metric='euclidean')\n",
        "    dist_matrix = squareform(distances)\n",
        "    \n",
        "    # Analyze diversity metrics\n",
        "    mean_distance = np.mean(distances)\n",
        "    std_distance = np.std(distances)\n",
        "    min_distance = np.min(distances)\n",
        "    \n",
        "    # Detect near-duplicates (threshold-based)\n",
        "    threshold = mean_distance * 0.1  # 10% of mean distance\n",
        "    near_duplicates = np.sum(distances < threshold)\n",
        "    total_pairs = len(distances)\n",
        "    duplicate_ratio = near_duplicates / total_pairs\n",
        "    \n",
        "    # Visualization\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    \n",
        "    # Distance distribution\n",
        "    ax1 = plt.subplot(1, 3, 1)\n",
        "    ax1.hist(distances, bins=50, edgecolor='black', alpha=0.7)\n",
        "    ax1.axvline(mean_distance, color='red', linestyle='--', label=f'Mean: {mean_distance:.2f}')\n",
        "    ax1.axvline(threshold, color='orange', linestyle='--', label=f'Threshold: {threshold:.2f}')\n",
        "    ax1.set_xlabel('Pairwise Distance')\n",
        "    ax1.set_ylabel('Frequency')\n",
        "    ax1.set_title('Distance Distribution')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Distance heatmap (subsample for visualization)\n",
        "    ax2 = plt.subplot(1, 3, 2)\n",
        "    subsample_idx = np.random.choice(n_samples, 50, replace=False)\n",
        "    sub_dist_matrix = dist_matrix[np.ix_(subsample_idx, subsample_idx)]\n",
        "    im = ax2.imshow(sub_dist_matrix, cmap='viridis')\n",
        "    ax2.set_title('Distance Matrix (50 samples)')\n",
        "    ax2.set_xlabel('Sample Index')\n",
        "    ax2.set_ylabel('Sample Index')\n",
        "    plt.colorbar(im, ax=ax2)\n",
        "    \n",
        "    # Mode collapse indicators\n",
        "    ax3 = plt.subplot(1, 3, 3)\n",
        "    metrics = ['Mean Distance', 'Std Distance', 'Min Distance', 'Duplicate Ratio']\n",
        "    values = [mean_distance/100, std_distance/100, min_distance/10, duplicate_ratio*10]\n",
        "    colors = ['blue', 'green', 'orange', 'red']\n",
        "    bars = ax3.bar(metrics, values, color=colors, alpha=0.7)\n",
        "    ax3.set_ylabel('Normalized Value')\n",
        "    ax3.set_title('Diversity Metrics')\n",
        "    ax3.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, val in zip(bars, [mean_distance, std_distance, min_distance, duplicate_ratio]):\n",
        "        height = bar.get_height()\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Mode collapse assessment\n",
        "    print(\"\\nüîç Mode Collapse Analysis:\")\n",
        "    print(f\"Mean pairwise distance: {mean_distance:.4f}\")\n",
        "    print(f\"Std of distances: {std_distance:.4f}\")\n",
        "    print(f\"Minimum distance: {min_distance:.4f}\")\n",
        "    print(f\"Near-duplicate ratio: {duplicate_ratio:.4%}\")\n",
        "    \n",
        "    if duplicate_ratio > 0.1:\n",
        "        print(\"‚ö†Ô∏è WARNING: High duplicate ratio indicates possible mode collapse!\")\n",
        "    elif duplicate_ratio > 0.05:\n",
        "        print(\"‚ö†Ô∏è CAUTION: Moderate duplicate ratio - monitor for mode collapse\")\n",
        "    else:\n",
        "        print(\"‚úÖ Good diversity - no significant mode collapse detected\")\n",
        "    \n",
        "    return mean_distance, std_distance, duplicate_ratio\n",
        "\n",
        "# Analyze mode collapse\n",
        "mean_dist, std_dist, dup_ratio = detect_mode_collapse(netG, n_samples=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 6: Wasserstein GAN (WGAN) Implementation üåä\n",
        "\n",
        "### Concept\n",
        "WGAN uses Wasserstein distance instead of JS divergence:\n",
        "- More stable training\n",
        "- Meaningful loss metric\n",
        "- No mode collapse\n",
        "- Requires Lipschitz constraint (via weight clipping or gradient penalty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WGAN_Critic(nn.Module):\n",
        "    \"\"\"WGAN Critic (no sigmoid activation)\"\"\"\n",
        "    def __init__(self, input_dim=1, hidden_dim=128):\n",
        "        super(WGAN_Critic, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, 1)  # No sigmoid!\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_wgan_1d(n_epochs=2000, n_critic=5, clip_value=0.01):\n",
        "    \"\"\"Train WGAN with weight clipping\"\"\"\n",
        "    \n",
        "    # Initialize networks\n",
        "    G = Simple1D_Generator().to(device)\n",
        "    C = WGAN_Critic().to(device)  # Critic instead of Discriminator\n",
        "    \n",
        "    # Optimizers (RMSprop works better for WGAN)\n",
        "    g_optimizer = optim.RMSprop(G.parameters(), lr=0.00005)\n",
        "    c_optimizer = optim.RMSprop(C.parameters(), lr=0.00005)\n",
        "    \n",
        "    # Target distribution\n",
        "    target_mean, target_std = 4.0, 1.5\n",
        "    \n",
        "    # Storage\n",
        "    c_losses, g_losses = [], []\n",
        "    wasserstein_distances = []\n",
        "    \n",
        "    batch_size = 128\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        # Train Critic multiple times\n",
        "        for _ in range(n_critic):\n",
        "            c_optimizer.zero_grad()\n",
        "            \n",
        "            # Real data\n",
        "            real_data = torch.randn(batch_size, 1).to(device) * target_std + target_mean\n",
        "            real_score = C(real_data)\n",
        "            \n",
        "            # Fake data\n",
        "            noise = torch.randn(batch_size, 10).to(device)\n",
        "            fake_data = G(noise)\n",
        "            fake_score = C(fake_data.detach())\n",
        "            \n",
        "            # Wasserstein distance\n",
        "            c_loss = -torch.mean(real_score) + torch.mean(fake_score)\n",
        "            c_loss.backward()\n",
        "            c_optimizer.step()\n",
        "            \n",
        "            # Clip critic weights (Lipschitz constraint)\n",
        "            for p in C.parameters():\n",
        "                p.data.clamp_(-clip_value, clip_value)\n",
        "        \n",
        "        # Train Generator\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        noise = torch.randn(batch_size, 10).to(device)\n",
        "        fake_data = G(noise)\n",
        "        fake_score = C(fake_data)\n",
        "        \n",
        "        g_loss = -torch.mean(fake_score)\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        # Store metrics\n",
        "        c_losses.append(c_loss.item())\n",
        "        g_losses.append(g_loss.item())\n",
        "        wasserstein_distances.append(-c_loss.item())  # Negative critic loss = Wasserstein distance\n",
        "        \n",
        "        if epoch % 400 == 0:\n",
        "            print(f'Epoch [{epoch}/{n_epochs}] C_loss: {c_loss:.4f}, G_loss: {g_loss:.4f}, '\n",
        "                  f'W_distance: {-c_loss.item():.4f}')\n",
        "    \n",
        "    return G, C, c_losses, g_losses, wasserstein_distances\n",
        "\n",
        "# Train WGAN\n",
        "print(\"üöÄ Training WGAN with weight clipping...\")\n",
        "G_wgan, C_wgan, c_losses_wgan, g_losses_wgan, w_distances = train_wgan_1d()\n",
        "print(\"‚úÖ WGAN training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare WGAN vs Standard GAN\n",
        "def compare_gan_wgan():\n",
        "    \"\"\"Compare standard GAN and WGAN results\"\"\"\n",
        "    \n",
        "    fig = plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # Generate samples from both models\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(1000, 10).to(device)\n",
        "        samples_gan = G_1d(noise).cpu().numpy()\n",
        "        samples_wgan = G_wgan(noise).cpu().numpy()\n",
        "    \n",
        "    target_samples = np.random.normal(4.0, 1.5, 1000)\n",
        "    \n",
        "    # Row 1: Distribution comparison\n",
        "    ax1 = plt.subplot(2, 3, 1)\n",
        "    ax1.hist(samples_gan, bins=30, alpha=0.7, density=True, color='blue', label='Standard GAN')\n",
        "    ax1.hist(target_samples, bins=30, alpha=0.5, density=True, \n",
        "             color='red', label='Target', histtype='step', linewidth=2)\n",
        "    ax1.set_title('Standard GAN Results')\n",
        "    ax1.set_xlabel('Value')\n",
        "    ax1.set_ylabel('Density')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    ax2 = plt.subplot(2, 3, 2)\n",
        "    ax2.hist(samples_wgan, bins=30, alpha=0.7, density=True, color='green', label='WGAN')\n",
        "    ax2.hist(target_samples, bins=30, alpha=0.5, density=True, \n",
        "             color='red', label='Target', histtype='step', linewidth=2)\n",
        "    ax2.set_title('WGAN Results')\n",
        "    ax2.set_xlabel('Value')\n",
        "    ax2.set_ylabel('Density')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    ax3 = plt.subplot(2, 3, 3)\n",
        "    ax3.hist(samples_gan, bins=30, alpha=0.5, density=True, color='blue', label='Standard GAN')\n",
        "    ax3.hist(samples_wgan, bins=30, alpha=0.5, density=True, color='green', label='WGAN')\n",
        "    ax3.hist(target_samples, bins=30, alpha=0.5, density=True, \n",
        "             color='red', label='Target', histtype='step', linewidth=2)\n",
        "    ax3.set_title('All Distributions')\n",
        "    ax3.set_xlabel('Value')\n",
        "    ax3.set_ylabel('Density')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Row 2: Training dynamics\n",
        "    ax4 = plt.subplot(2, 3, 4)\n",
        "    ax4.plot(d_losses_1d[:500], alpha=0.7, label='D Loss')\n",
        "    ax4.plot(g_losses_1d[:500], alpha=0.7, label='G Loss')\n",
        "    ax4.set_title('Standard GAN Training')\n",
        "    ax4.set_xlabel('Iteration')\n",
        "    ax4.set_ylabel('Loss')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    ax5 = plt.subplot(2, 3, 5)\n",
        "    ax5.plot(c_losses_wgan[:500], alpha=0.7, label='Critic Loss')\n",
        "    ax5.plot(g_losses_wgan[:500], alpha=0.7, label='G Loss')\n",
        "    ax5.set_title('WGAN Training')\n",
        "    ax5.set_xlabel('Iteration')\n",
        "    ax5.set_ylabel('Loss')\n",
        "    ax5.legend()\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    \n",
        "    ax6 = plt.subplot(2, 3, 6)\n",
        "    ax6.plot(w_distances[:500], alpha=0.7, color='purple')\n",
        "    ax6.set_title('Wasserstein Distance')\n",
        "    ax6.set_xlabel('Iteration')\n",
        "    ax6.set_ylabel('Distance')\n",
        "    ax6.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Calculate statistics\n",
        "    from scipy import stats\n",
        "    \n",
        "    # KL divergence approximation using histogram\n",
        "    hist_target, bins = np.histogram(target_samples, bins=30, density=True)\n",
        "    hist_gan, _ = np.histogram(samples_gan, bins=bins, density=True)\n",
        "    hist_wgan, _ = np.histogram(samples_wgan, bins=bins, density=True)\n",
        "    \n",
        "    # Add small epsilon to avoid log(0)\n",
        "    eps = 1e-10\n",
        "    kl_gan = np.sum(hist_target * np.log((hist_target + eps) / (hist_gan + eps)))\n",
        "    kl_wgan = np.sum(hist_target * np.log((hist_target + eps) / (hist_wgan + eps)))\n",
        "    \n",
        "    print(\"\\nüìä Comparison Results:\")\n",
        "    print(f\"Standard GAN - Mean: {np.mean(samples_gan):.3f}, Std: {np.std(samples_gan):.3f}, KL: {kl_gan:.3f}\")\n",
        "    print(f\"WGAN        - Mean: {np.mean(samples_wgan):.3f}, Std: {np.std(samples_wgan):.3f}, KL: {kl_wgan:.3f}\")\n",
        "    print(f\"Target      - Mean: 4.000, Std: 1.500\")\n",
        "\n",
        "compare_gan_wgan()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 7: Conditional GAN (cGAN) üé®\n",
        "\n",
        "### Concept\n",
        "Conditional GANs allow us to control the generation process by providing additional information (labels, text, images).\n",
        "\n",
        "Key modification: Both G and D receive the conditional information y:\n",
        "- G(z, y): Generate samples conditioned on y\n",
        "- D(x, y): Classify real/fake given condition y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConditionalGenerator(nn.Module):\n",
        "    \"\"\"Conditional GAN Generator\"\"\"\n",
        "    def __init__(self, n_classes=10, nz=100, n_channels=1, ngf=64):\n",
        "        super(ConditionalGenerator, self).__init__()\n",
        "        \n",
        "        # Embedding for class labels\n",
        "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            # Input: (nz + n_classes) x 1 x 1\n",
        "            nn.ConvTranspose2d(nz + n_classes, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf, n_channels, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    \n",
        "    def forward(self, noise, labels):\n",
        "        # Embed labels and concatenate with noise\n",
        "        label_embedding = self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
        "        gen_input = torch.cat((noise, label_embedding), 1)\n",
        "        return self.main(gen_input)\n",
        "\n",
        "class ConditionalDiscriminator(nn.Module):\n",
        "    \"\"\"Conditional GAN Discriminator\"\"\"\n",
        "    def __init__(self, n_classes=10, n_channels=1, ndf=64):\n",
        "        super(ConditionalDiscriminator, self).__init__()\n",
        "        \n",
        "        # Embedding for class labels\n",
        "        self.label_embedding = nn.Embedding(n_classes, 64*64)\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            # Input: (n_channels + 1) x 64 x 64 (image + embedded label)\n",
        "            nn.Conv2d(n_channels + 1, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, img, labels):\n",
        "        # Embed labels and reshape to image dimensions\n",
        "        label_embedding = self.label_embedding(labels).view(-1, 1, 64, 64)\n",
        "        # Concatenate image and label embedding\n",
        "        d_input = torch.cat((img, label_embedding), 1)\n",
        "        return self.main(d_input).view(-1, 1).squeeze(1)\n",
        "\n",
        "# Initialize Conditional GAN\n",
        "n_classes = 10  # For MNIST digits 0-9\n",
        "cG = ConditionalGenerator(n_classes=n_classes).to(device)\n",
        "cD = ConditionalDiscriminator(n_classes=n_classes).to(device)\n",
        "\n",
        "# Initialize weights\n",
        "cG.apply(weights_init)\n",
        "cD.apply(weights_init)\n",
        "\n",
        "print(\"‚úÖ Conditional GAN initialized\")\n",
        "print(f\"Classes: {n_classes} (digits 0-9)\")\n",
        "print(f\"Generator parameters: {sum(p.numel() for p in cG.parameters()):,}\")\n",
        "print(f\"Discriminator parameters: {sum(p.numel() for p in cD.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_conditional_samples(generator, n_samples=100, n_classes=10, nz=100):\n",
        "    \"\"\"Generate samples for each class using conditional GAN\"\"\"\n",
        "    \n",
        "    samples_per_class = n_samples // n_classes\n",
        "    \n",
        "    all_samples = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for class_idx in range(n_classes):\n",
        "            # Create labels for this class\n",
        "            labels = torch.full((samples_per_class,), class_idx, dtype=torch.long, device=device)\n",
        "            \n",
        "            # Generate noise\n",
        "            noise = torch.randn(samples_per_class, nz, 1, 1, device=device)\n",
        "            \n",
        "            # Generate samples\n",
        "            fake_images = generator(noise, labels)\n",
        "            \n",
        "            all_samples.append(fake_images)\n",
        "            all_labels.extend([class_idx] * samples_per_class)\n",
        "    \n",
        "    # Concatenate all samples\n",
        "    all_samples = torch.cat(all_samples, dim=0)\n",
        "    \n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for class_idx in range(n_classes):\n",
        "        # Get samples for this class\n",
        "        class_samples = all_samples[class_idx * samples_per_class:(class_idx + 1) * samples_per_class]\n",
        "        \n",
        "        # Create grid for visualization\n",
        "        grid = make_grid(class_samples[:8], nrow=4, normalize=True, padding=2)\n",
        "        \n",
        "        # Display\n",
        "        axes[class_idx].imshow(np.transpose(grid.cpu(), (1, 2, 0)), cmap='gray')\n",
        "        axes[class_idx].set_title(f'Class {class_idx}')\n",
        "        axes[class_idx].axis('off')\n",
        "    \n",
        "    plt.suptitle('Conditional GAN: Generated Samples by Class', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nüìä Conditional Generation Summary:\")\n",
        "    print(f\"Total samples generated: {len(all_samples)}\")\n",
        "    print(f\"Samples per class: {samples_per_class}\")\n",
        "    print(f\"Classes: {list(range(n_classes))}\")\n",
        "\n",
        "# Generate conditional samples (using untrained model for demonstration)\n",
        "print(\"üé® Generating conditional samples...\")\n",
        "generate_conditional_samples(cG, n_samples=80, n_classes=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Exercise 8: GAN Evaluation Metrics üìè\n",
        "\n",
        "### Concept\n",
        "Evaluating GANs is challenging. Common metrics include:\n",
        "\n",
        "1. **Inception Score (IS)**: Measures quality and diversity\n",
        "2. **Fr√©chet Inception Distance (FID)**: Compares feature statistics\n",
        "3. **Precision & Recall**: Quality vs coverage trade-off\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_inception_score(images, splits=10):\n",
        "    \"\"\"Calculate Inception Score for generated images\"\"\"\n",
        "    \n",
        "    # Simplified IS calculation (for demonstration)\n",
        "    # In practice, use a pre-trained Inception model\n",
        "    \n",
        "    N = len(images)\n",
        "    \n",
        "    # Simulate class probabilities (would come from Inception model)\n",
        "    # For demonstration, we'll create synthetic probabilities\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # Higher quality images have more confident predictions\n",
        "    quality_factor = np.random.uniform(0.5, 1.0, N)\n",
        "    \n",
        "    # Create probability distributions\n",
        "    probs = np.zeros((N, 10))  # 10 classes\n",
        "    for i in range(N):\n",
        "        # Dominant class\n",
        "        dominant_class = np.random.randint(0, 10)\n",
        "        probs[i, dominant_class] = quality_factor[i]\n",
        "        \n",
        "        # Distribute remaining probability\n",
        "        remaining = 1 - quality_factor[i]\n",
        "        other_probs = np.random.dirichlet(np.ones(9)) * remaining\n",
        "        other_classes = [j for j in range(10) if j != dominant_class]\n",
        "        probs[i, other_classes] = other_probs\n",
        "    \n",
        "    # Calculate IS\n",
        "    split_scores = []\n",
        "    \n",
        "    for k in range(splits):\n",
        "        part = probs[k * (N // splits): (k + 1) * (N // splits)]\n",
        "        py = np.mean(part, axis=0)\n",
        "        \n",
        "        scores = []\n",
        "        for p_yx in part:\n",
        "            kl = np.sum(p_yx * (np.log(p_yx + 1e-10) - np.log(py + 1e-10)))\n",
        "            scores.append(np.exp(kl))\n",
        "        \n",
        "        split_scores.append(np.mean(scores))\n",
        "    \n",
        "    return np.mean(split_scores), np.std(split_scores)\n",
        "\n",
        "def calculate_fid_score(real_features, fake_features):\n",
        "    \"\"\"Calculate Fr√©chet Inception Distance\"\"\"\n",
        "    \n",
        "    # Calculate statistics\n",
        "    mu_real = np.mean(real_features, axis=0)\n",
        "    mu_fake = np.mean(fake_features, axis=0)\n",
        "    \n",
        "    sigma_real = np.cov(real_features, rowvar=False)\n",
        "    sigma_fake = np.cov(fake_features, rowvar=False)\n",
        "    \n",
        "    # Calculate FID\n",
        "    diff = mu_real - mu_fake\n",
        "    \n",
        "    # Simplified calculation (full version uses matrix square root)\n",
        "    covmean = np.trace(sigma_real + sigma_fake - 2 * np.sqrt(sigma_real @ sigma_fake))\n",
        "    \n",
        "    fid = np.sum(diff ** 2) + covmean\n",
        "    \n",
        "    return fid\n",
        "\n",
        "# Evaluate GAN metrics\n",
        "def evaluate_gan_metrics(generator, n_samples=1000):\n",
        "    \"\"\"Comprehensive GAN evaluation\"\"\"\n",
        "    \n",
        "    print(\"üìä Evaluating GAN Metrics...\\n\")\n",
        "    \n",
        "    # Generate samples\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(n_samples, 100, 1, 1, device=device)\n",
        "        fake_images = generator(noise).cpu().numpy()\n",
        "    \n",
        "    # Flatten for feature extraction\n",
        "    fake_features = fake_images.reshape(n_samples, -1)\n",
        "    \n",
        "    # Generate \"real\" features for comparison (synthetic for demo)\n",
        "    real_features = np.random.normal(0, 1, fake_features.shape)\n",
        "    \n",
        "    # Calculate Inception Score\n",
        "    is_mean, is_std = calculate_inception_score(fake_images)\n",
        "    print(f\"üìà Inception Score: {is_mean:.2f} ¬± {is_std:.2f}\")\n",
        "    print(\"   (Higher is better, typical range: 1-10)\")\n",
        "    \n",
        "    # Calculate FID\n",
        "    fid = calculate_fid_score(real_features[:, :100], fake_features[:, :100])\n",
        "    print(f\"\\nüìâ FID Score: {fid:.2f}\")\n",
        "    print(\"   (Lower is better, typical range: 0-100)\")\n",
        "    \n",
        "    # Visualize metrics\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # IS visualization\n",
        "    metrics = ['Quality', 'Diversity', 'Overall IS']\n",
        "    values = [is_mean * 0.6, is_mean * 0.4, is_mean]\n",
        "    colors = ['#4CAF50', '#2196F3', '#FF9800']\n",
        "    \n",
        "    bars = ax1.bar(metrics, values, color=colors, alpha=0.7)\n",
        "    ax1.set_ylabel('Score')\n",
        "    ax1.set_title('Inception Score Components')\n",
        "    ax1.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, val in zip(bars, values):\n",
        "        height = bar.get_height()\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.2f}', ha='center', va='bottom')\n",
        "    \n",
        "    # FID visualization\n",
        "    categories = ['FID\\n(Our Model)', 'Good GAN\\n(typical)', 'Poor GAN\\n(typical)']\n",
        "    fid_values = [fid, 20, 80]\n",
        "    colors = ['#FF6B6B', '#4CAF50', '#FF9800']\n",
        "    \n",
        "    bars = ax2.bar(categories, fid_values, color=colors, alpha=0.7)\n",
        "    ax2.set_ylabel('FID Score (lower is better)')\n",
        "    ax2.set_title('FID Score Comparison')\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, val in zip(bars, fid_values):\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{val:.1f}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return is_mean, fid\n",
        "\n",
        "# Evaluate the trained DCGAN\n",
        "is_score, fid_score = evaluate_gan_metrics(netG, n_samples=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 5: Summary and Practice Exercises üéØ\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "### 1. **GAN Fundamentals**\n",
        "- Minimax game between Generator and Discriminator\n",
        "- Generator learns to map noise to data distribution\n",
        "- Discriminator learns to distinguish real from fake\n",
        "\n",
        "### 2. **Training Challenges**\n",
        "- Mode collapse: Generator produces limited variety\n",
        "- Vanishing gradients: When D is too successful\n",
        "- Training instability: Oscillating losses\n",
        "- No clear stopping criterion\n",
        "\n",
        "### 3. **Improvements**\n",
        "- **DCGAN**: Architectural guidelines for stability\n",
        "- **WGAN**: Wasserstein distance for meaningful loss\n",
        "- **Conditional GAN**: Controlled generation\n",
        "- **Progressive GAN**: High-resolution generation\n",
        "\n",
        "### 4. **Practical Tips**\n",
        "- Normalize inputs to [-1, 1]\n",
        "- Use batch normalization (except G output, D input)\n",
        "- LeakyReLU in D, ReLU in G\n",
        "- Monitor loss curves and sample quality\n",
        "- Use Adam with Œ≤‚ÇÅ = 0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üèãÔ∏è Practice Exercises\n",
        "\n",
        "### Exercise A: Implement Non-Saturating Loss\n",
        "Modify the basic GAN to use non-saturating loss for the generator.\n",
        "\n",
        "### Exercise B: Add Gradient Penalty\n",
        "Implement WGAN-GP (Gradient Penalty) instead of weight clipping.\n",
        "\n",
        "### Exercise C: Build a Simple StyleGAN\n",
        "Create a simplified version of StyleGAN with style injection.\n",
        "\n",
        "### Exercise D: Implement Spectral Normalization\n",
        "Add spectral normalization to stabilize training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise A: Non-Saturating Loss\n",
        "def train_gan_non_saturating():\n",
        "    \"\"\"\n",
        "    TODO: Implement GAN with non-saturating loss\n",
        "    Instead of minimizing log(1 - D(G(z))), maximize log(D(G(z)))\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Exercise B: Gradient Penalty\n",
        "def gradient_penalty(discriminator, real_samples, fake_samples, device):\n",
        "    \"\"\"\n",
        "    TODO: Calculate gradient penalty for WGAN-GP\n",
        "    Hint: Interpolate between real and fake samples, calculate gradients\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "# Exercise C: Style Injection\n",
        "class SimpleStyleGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    TODO: Implement a generator with style injection\n",
        "    Hint: Use AdaIN (Adaptive Instance Normalization)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Your code here\n",
        "        pass\n",
        "    \n",
        "    def forward(self, z, style):\n",
        "        # Your code here\n",
        "        pass\n",
        "\n",
        "print(\"üìù Complete the exercises above!\")\n",
        "print(\"Hints provided in the function docstrings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üéâ Congratulations!\n",
        "\n",
        "You've completed the comprehensive GAN tutorial! You've learned:\n",
        "\n",
        "‚úÖ Mathematical foundations of GANs  \n",
        "‚úÖ Implementation from scratch  \n",
        "‚úÖ DCGAN architecture  \n",
        "‚úÖ WGAN improvements  \n",
        "‚úÖ Conditional generation  \n",
        "‚úÖ Evaluation metrics  \n",
        "‚úÖ Common problems and solutions  \n",
        "\n",
        "### üöÄ Next Steps\n",
        "\n",
        "1. **Experiment with different architectures**: Try ProGAN, StyleGAN, or BigGAN\n",
        "2. **Apply to your domain**: Use GANs for your specific application\n",
        "3. **Explore recent advances**: Diffusion models, DALL-E, etc.\n",
        "4. **Read the original papers**: Deep dive into the theory\n",
        "\n",
        "### üìö Recommended Reading\n",
        "\n",
        "- [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) - Original GAN paper\n",
        "- [Unsupervised Representation Learning with DCGANs](https://arxiv.org/abs/1511.06434)\n",
        "- [Wasserstein GAN](https://arxiv.org/abs/1701.07875)\n",
        "- [Progressive Growing of GANs](https://arxiv.org/abs/1710.10196)\n",
        "- [StyleGAN](https://arxiv.org/abs/1812.04948)\n",
        "\n",
        "---\n",
        "**Thank you for learning with us!** üôè\n",
        "\n",
        "If you have questions or feedback, please reach out to:  \n",
        "üìß homin.park@ghent.ac.kr\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}