# Lecture 19: Model Explainability - XAI Fundamentals

## ğŸ“‹ Overview

**Instructor:** Ho-min Park  
**Email:** homin.park@ghent.ac.kr | powersimmani@gmail.com

This lecture covers the necessity of AI explainability and traditional interpretation methods.

---

## ğŸ¯ Learning Objectives

1. Understand importance and motivation for XAI
2. Distinguish Interpretability vs Explainability
3. Calculate Feature Importance
4. Implement and apply LIME
5. Evaluate model interpretability

---

## ğŸ“š Key Topics

**XAI motivation**: Trust, debugging, regulatory compliance, fairness
**Concepts**: Interpretability, Explainability, Transparency
**Feature Importance**: Permutation, SHAP, Gain
**LIME**: Local approximation, interpretable models
**Global vs Local**: Entire model vs individual predictions

---

## ğŸ’¡ Key Concepts

- Black-box models can be explained
- Feature Importance is fundamental tool
- LIME provides local interpretation
- Perturbation-based methods
- Explanations enhance trust and adoption

---

## ğŸ› ï¸ Prerequisites

- Basic Python programming
- Understanding of previous lecture content
- Basic machine learning concepts

---

## ğŸ“– Additional Resources

For detailed code examples, practice materials, and slides, please refer to the original lecture files.
Lecture materials: HTML-based interactive slides provided
