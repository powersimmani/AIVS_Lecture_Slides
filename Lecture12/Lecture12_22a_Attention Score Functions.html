<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Attention Score Functions</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: Aptos, 'Segoe UI', sans-serif; background: #FFFFFF; display: flex; justify-content: center; align-items: center; min-height: 100vh; padding: 20px; }
        .container { width: 960px; height: 540px; padding: 25px 35px; display: flex; flex-direction: column; }
        .title-section { text-align: center; margin-bottom: 12px; }
        .main-title { font-size: 24px; font-weight: 600; color: #1E64C8; margin-bottom: 4px; }
        .subtitle { font-size: 14px; color: #666; }
        .content-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 14px; flex: 1; }
        .left-col { display: flex; flex-direction: column; gap: 10px; }
        .attn-card { background: white; border: 2px solid #1E64C8; border-radius: 10px; padding: 10px; }
        .attn-card.additive { border-color: #9C27B0; }
        .attn-card.dot { border-color: #4CAF50; }
        .attn-card.scaled { border-color: #FF9800; }
        .attn-card.general { border-color: #2196F3; }
        .card-title { font-size: 13px; font-weight: 700; margin-bottom: 6px; }
        .additive .card-title { color: #9C27B0; }
        .dot .card-title { color: #4CAF50; }
        .scaled .card-title { color: #FF9800; }
        .general .card-title { color: #2196F3; }
        .formula-box { background: #f8f8f8; border-radius: 6px; padding: 8px; margin-bottom: 6px; text-align: center; }
        .formula-main { font-size: 13px; font-weight: 600; color: #333; font-family: 'Times New Roman', serif; }
        .feature-text { font-size: 11px; color: #333; line-height: 1.4; }
        .right-col { display: flex; flex-direction: column; gap: 10px; }
        .compare-card { background: white; border: 2.5px solid #1E64C8; border-radius: 12px; padding: 12px; flex: 1; }
        .compare-title { font-size: 15px; font-weight: 700; color: #1E64C8; margin-bottom: 10px; text-align: center; }
        .comparison-table { width: 100%; font-size: 10px; border-collapse: collapse; }
        .comparison-table th { background: #1E64C8; color: white; padding: 5px; text-align: center; }
        .comparison-table td { padding: 5px; text-align: center; border-bottom: 1px solid #e0e0e0; }
        .highlight { background: #E8F5E9; font-weight: 600; }
        .summary-box { background: #E3F2FD; border-radius: 8px; padding: 10px; }
        .summary-title { font-size: 12px; font-weight: 700; color: #1565C0; margin-bottom: 6px; }
        .summary-content { font-size: 11px; color: #333; line-height: 1.5; }
    </style>
</head>
<body>
    <div class="container">
        <div class="title-section">
            <div class="main-title">Attention Score Functions</div>
            <div class="subtitle">Different ways to compute attention alignment scores</div>
        </div>
        <div class="content-grid">
            <div class="left-col">
                <div class="attn-card additive">
                    <div class="card-title">1. Additive (Bahdanau) Attention</div>
                    <div class="formula-box">
                        <div class="formula-main">score(s, h) = v<sup>T</sup> tanh(W<sub>s</sub>s + W<sub>h</sub>h)</div>
                    </div>
                    <div class="feature-text">
                        <strong>Params:</strong> W<sub>s</sub>, W<sub>h</sub>, v (O(d²))<br>
                        <strong>Use:</strong> Original Seq2Seq attention (2014)
                    </div>
                </div>
                <div class="attn-card dot">
                    <div class="card-title">2. Dot-Product Attention</div>
                    <div class="formula-box">
                        <div class="formula-main">score(s, h) = s<sup>T</sup>h</div>
                    </div>
                    <div class="feature-text">
                        <strong>Params:</strong> None (0)<br>
                        <strong>Issue:</strong> Large values when d<sub>k</sub> is large
                    </div>
                </div>
                <div class="attn-card scaled">
                    <div class="card-title">3. Scaled Dot-Product (Transformer)</div>
                    <div class="formula-box">
                        <div class="formula-main">score(Q, K) = QK<sup>T</sup> / √d<sub>k</sub></div>
                    </div>
                    <div class="feature-text">
                        <strong>Params:</strong> None (0)<br>
                        <strong>Use:</strong> Transformer standard (2017)
                    </div>
                </div>
                <div class="attn-card general">
                    <div class="card-title">4. General (Luong) Attention</div>
                    <div class="formula-box">
                        <div class="formula-main">score(s, h) = s<sup>T</sup>Wh</div>
                    </div>
                    <div class="feature-text">
                        <strong>Params:</strong> W (O(d²))<br>
                        <strong>Use:</strong> Efficient learnable attention
                    </div>
                </div>
            </div>
            <div class="right-col">
                <div class="compare-card">
                    <div class="compare-title">Comparison</div>
                    <table class="comparison-table">
                        <tr><th>Method</th><th>Params</th><th>Speed</th><th>Expressiveness</th><th>Use Case</th></tr>
                        <tr><td>Additive</td><td>O(d²)</td><td>Slow</td><td>High</td><td>Original Seq2Seq</td></tr>
                        <tr><td>Dot-Product</td><td>0</td><td class="highlight">Fast</td><td>Medium</td><td>Small d<sub>k</sub></td></tr>
                        <tr><td>Scaled Dot</td><td>0</td><td class="highlight">Fast</td><td>Medium</td><td class="highlight">Transformer</td></tr>
                        <tr><td>General</td><td>O(d²)</td><td>Medium</td><td>High</td><td>General use</td></tr>
                    </table>
                </div>
                <div class="summary-box">
                    <div class="summary-title">Why Scaling Matters</div>
                    <div class="summary-content">
                        When d<sub>k</sub> is large, dot products grow large → softmax has extremely small gradients.<br><br>
                        <strong>Solution:</strong> Divide by √d<sub>k</sub> to keep variance ≈ 1<br><br>
                        <strong>Modern Standard:</strong> Scaled Dot-Product is used in virtually all Transformer-based models (BERT, GPT, etc.)
                    </div>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
