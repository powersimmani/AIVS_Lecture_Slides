# Lecture 17: Clustering and Unsupervised Learning Fundamentals

## ğŸ“‹ Overview

**Instructor:** Ho-min Park  
**Email:** homin.park@ghent.ac.kr | powersimmani@gmail.com

This lecture covers unsupervised learning fundamentals: clustering algorithms and evaluation metrics.

---

## ğŸ¯ Learning Objectives

1. Distinguish supervised/unsupervised/semi-supervised learning
2. Implement clustering algorithms (K-Means, DBSCAN)
3. Apply cluster evaluation metrics
4. Understand dimensionality reduction (PCA, t-SNE)
5. Determine appropriate number of clusters

---

## ğŸ“š Key Topics

**K-Means**: Centroid-based, Elbow method, K-Means++
**DBSCAN**: Density-based, arbitrary shapes, noise handling
**Hierarchical**: Agglomerative/Divisive, Dendrogram
**GMM**: Probabilistic, EM algorithm, Soft clustering
**Evaluation**: Silhouette, Davies-Bouldin, Calinski-Harabasz

---

## ğŸ’¡ Key Concepts

- K-Means is fast and simple
- DBSCAN handles arbitrary shapes
- GMM provides probabilistic assignment
- Silhouette measures cluster quality
- PCA for linear, t-SNE for nonlinear dimensionality reduction

---

## ğŸ› ï¸ Prerequisites

- Basic Python programming
- Understanding of previous lecture content
- Basic machine learning concepts

---

## ğŸ“– Additional Resources

For detailed code examples, practice materials, and slides, please refer to the original lecture files.
Lecture materials: HTML-based interactive slides provided
